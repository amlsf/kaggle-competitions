{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "\n",
    "# Multiclass SVM!!\n",
    "\n",
    "# Try Random Forest and SVM (only) on combo of Gioia and Ken's features. (Try to add some of my own features.) \n",
    "\n",
    "# write-up\n",
    "\n",
    "# FEATURES: start looking at the XML tree and play with this XML parsing? See sample text file\n",
    "# EDA & VIZ: \n",
    "# - TP/FP rate for each class (ROC, Confusion matrix?). Visualization\n",
    "# - visualizations? Take stuff from data science - ROC curve, confusion matrix? \n",
    "\n",
    "\n",
    "# LATER\n",
    "# MODELS: Try neural network? \n",
    "# Tune model\n",
    "# (See Osprey security stuff? NSecurity? OneNote)\n",
    "\n",
    "# but i was thinking i am really only going tweak this model (if it performs decently), and MAYBE \n",
    "# combine it with your stuff.  Or maybe we should consider “Stacking” whatever that is.  I keep hearing that works well.\n",
    "# But I’m thinking other than maybe Amy’s SVM, my sequence stuff, and maybe stacking 1/2 of those with G’s stuff, \n",
    "# I doubt were going to have time to do any more modeling.  So maybe we should start cleaning up the report and just \n",
    "# leave blanks for that stuff.\n",
    "\n",
    "# Majority Classifier: All None. input into report and write up - see Data Science for words on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE \n",
    "# do random train-test split\n",
    "# try out the same process of creating predictions with the features given \n",
    "# Majority Classifier: create baseline for all None's and validate\n",
    "# Try running on VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sys_path = list(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amlsf/CS181_practicals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/home/anaconda2/anaconda2/lib/python27.zip',\n",
       " '/home/anaconda2/anaconda2/lib/python2.7',\n",
       " '/home/anaconda2/anaconda2/lib/python2.7/plat-linux2',\n",
       " '/home/anaconda2/anaconda2/lib/python2.7/lib-tk',\n",
       " '/home/anaconda2/anaconda2/lib/python2.7/lib-old',\n",
       " '/home/anaconda2/anaconda2/lib/python2.7/lib-dynload',\n",
       " '/home/anaconda2/anaconda2/lib/python2.7/site-packages/Sphinx-1.3.5-py2.7.egg',\n",
       " '/home/anaconda2/anaconda2/lib/python2.7/site-packages/setuptools-19.6.2-py2.7.egg',\n",
       " '/home/anaconda2/anaconda2/lib/python2.7/site-packages',\n",
       " '/home/anaconda2/anaconda2/lib/python2.7/site-packages/cryptography-1.0.2-py2.7-linux-x86_64.egg',\n",
       " '/home/anaconda2/anaconda2/lib/python2.7/site-packages/IPython/extensions',\n",
       " '/home/amlsf/.ipython',\n",
       " '/home/amlsf/CS181_practicals']"
      ]
     },
     "execution_count": 5,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "project_root = cwd[:cwd.index('/CS181_practicals')] + '/CS181_practicals'\n",
    "print project_root\n",
    "sys.path.append(project_root)\n",
    "sys.path # print sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "from gakutility import practical2_amy as p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gakutility.practical2_amy' from '/home/amlsf/CS181_practicals/gakutility/practical2_amy.pyc'>"
      ]
     },
     "execution_count": 7,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "reload(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agent',\n",
       " 'AutoRun',\n",
       " 'FraudLoad',\n",
       " 'FraudPack',\n",
       " 'Hupigon',\n",
       " 'Krap',\n",
       " 'Lipler',\n",
       " 'Magania',\n",
       " 'None',\n",
       " 'Poison',\n",
       " 'Swizzor',\n",
       " 'Tdss',\n",
       " 'VB',\n",
       " 'Virut',\n",
       " 'Zbot']"
      ]
     },
     "execution_count": 8,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "p2.MALWARE_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "len(p2.MALWARE_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record performance of different models\n",
    "tracker = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-11b59a4d7911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Classification Distribution in Training Data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train_all' is not defined"
     ]
    }
   ],
   "source": [
    "plt.hist(Y_train_all, normed=True, bins=15)\n",
    "plt.title(\"Classification Distribution in Training Data\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(os.path.join('/home/shared/practical2/data/train', '699ee544c70e89893dd700a2Dd156b303f8e99c6e.VB.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processes\n",
      "process\n",
      "thread\n",
      "all_section\n",
      "load_image\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "load_dll\n",
      "check_for_debugger\n",
      "load_dll\n",
      "get_system_directory\n",
      "open_key\n",
      "open_key\n",
      "query_value\n",
      "create_mutex\n",
      "create_mutex\n",
      "create_mutex\n",
      "create_mutex\n",
      "create_mutex\n",
      "open_key\n",
      "query_value\n",
      "query_value\n",
      "get_system_directory\n",
      "open_key\n",
      "query_value\n",
      "create_mutex\n",
      "set_windows_hook\n",
      "set_windows_hook\n",
      "create_window\n",
      "load_dll\n",
      "open_key\n",
      "load_dll\n",
      "open_key\n",
      "query_value\n",
      "load_dll\n",
      "get_system_directory\n",
      "load_dll\n",
      "get_system_directory\n",
      "load_dll\n",
      "load_dll\n",
      "get_system_directory\n",
      "create_window\n",
      "open_key\n",
      "query_value\n",
      "open_key\n",
      "query_value\n",
      "get_system_directory\n",
      "load_dll\n",
      "create_window\n",
      "show_window\n",
      "open_key\n",
      "set_windows_hook\n",
      "create_window\n",
      "open_key\n",
      "create_open_file\n",
      "enum_window\n",
      "create_window\n",
      "create_window\n",
      "find_window\n",
      "enum_window\n",
      "create_window\n",
      "show_window\n",
      "enum_window\n",
      "show_window\n",
      "get_system_directory\n",
      "enum_window\n",
      "open_key\n",
      "open_key\n",
      "read_value\n",
      "open_key\n",
      "open_key\n",
      "read_value\n",
      "get_file_attributes\n",
      "get_windows_directory\n",
      "get_file_attributes\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "destroy_window\n",
      "enum_window\n",
      "sleep\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "enum_window\n",
      "destroy_window\n",
      "kill_process\n",
      "get_system_directory\n",
      "load_dll\n",
      "enum_window\n"
     ]
    }
   ],
   "source": [
    "for item in tree.iter():\n",
    "    print item.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Just two calls (From CS181 Course Staff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate Features & Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't need train_ids_all\n",
    "X_train_all, Y_train_all, train_ids_all = p2.create_data_matrix(p2.call_feats_given, direc='/home/shared/practical2/data/train')\n",
    "#  start_index=0, end_index=5\n",
    "\n",
    "# split out randomly into train_test_split 80-20\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_all, Y_train_all, train_size=0.7, random_state=1004)\n",
    "\n",
    "# don't need the Y_test\n",
    "X_test, Y_test, test_ids = p2.create_data_matrix(p2.call_feats_given, direc='/home/shared/practical2/data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Provided by CS181 Course staff\n",
    "# def call_feats_given(tree):\n",
    "#     good_calls = ['sleep', 'dump_line']\n",
    "\n",
    "#     call_counter = {}\n",
    "#     for el in tree.iter():\n",
    "#         call = el.tag\n",
    "#         if call not in call_counter:\n",
    "#             call_counter[call] = 0\n",
    "#         else:\n",
    "#             call_counter[call] += 1\n",
    "\n",
    "#     call_feat_array = np.zeros(len(good_calls))\n",
    "#     for i in range(len(good_calls)):\n",
    "#         call = good_calls[i]\n",
    "#         call_feat_array[i] = 0\n",
    "#         if call in call_counter:\n",
    "#             call_feat_array[i] = call_counter[call]\n",
    "\n",
    "#     return call_feat_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Count number and percentage of all calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to run p2.call_feats_given first to get this to populate\n",
    "num_calls = len(p2.CALL_SET)\n",
    "num_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_feats_all_count_perc(tree):\n",
    "    '''\n",
    "    Sample feature engineering function.\n",
    "    Returns the number of system specific calls made by the programs.\n",
    "    '''\n",
    "\n",
    "    # keep track of calls\n",
    "    call_counter = {}\n",
    "    \n",
    "    # loop through all calls/tags in the XML file\n",
    "    for el in tree.iter():\n",
    "        \n",
    "        # extract the call/tag name\n",
    "        call = el.tag\n",
    "        \n",
    "        # count the number of calls to each tag\n",
    "        if call not in call_counter:\n",
    "            call_counter[call] = 0\n",
    "        else:\n",
    "            call_counter[call] += 1\n",
    "            \n",
    "    # initialize the feature array (1 x 2D)        \n",
    "    call_feat_array = np.zeros(2 * num_calls)\n",
    "    \n",
    "    # loop through the calls we are looking for\n",
    "    for i, call in enumerate(p2.CALL_SET):\n",
    "        \n",
    "        # update counter with the number of times the call was seen\n",
    "        if call in call_counter:\n",
    "            call_feat_array[i] = call_counter[call]\n",
    "        else:\n",
    "            call_feat_array[i] = 0\n",
    "            \n",
    "    # add percentages\n",
    "    call_feat_array[num_calls:] = (call_feat_array[:num_calls] / call_feat_array[:num_calls].sum()).copy()\n",
    "\n",
    "    # return feature array (1 x D)\n",
    "    return call_feat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpcall_X_train_all, cpcall_Y_train_all, cpcall_train_ids_all = p2.create_data_matrix(call_feats_all_count_perc, \n",
    "                                                                                     direc='/home/shared/practical2/data/train')\n",
    "cpcall_X_test, cpcall_Y_test, cpcall_test_ids = p2.create_data_matrix(call_feats_all_count_perc, \n",
    "                                                                      direc='/home/shared/practical2/data/test')\n",
    "\n",
    "# split out randomly into train_test_split 80-20\n",
    "cpcall_X_train, cpcall_X_valid, cpcall_Y_train, cpcall_Y_valid = train_test_split(cpcall_X_train_all, cpcall_Y_train_all, \n",
    "                                                                                  train_size=0.7, random_state=1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 220)"
      ]
     },
     "execution_count": 19,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "pd.DataFrame(cpcall_X_train_all).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3724, 220)"
      ]
     },
     "execution_count": 20,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# makes sense there would be 2 * 110 call feats\n",
    "pd.DataFrame(cpcall_X_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. N-grams of System Call Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from K-Lo\n",
    "\n",
    "ngrams_X_train_all = pd.read_csv('/home/shared/practical2/data/features/bigtrain.csv').drop('Unnamed: 0', axis=1)\n",
    "# turn into numpy matrix\n",
    "ngrams_X_train_all = ngrams_X_train_all.as_matrix()\n",
    "\n",
    "ngrams_X_test = pd.read_csv('/home/shared/practical2/data/features/bigtest.csv').drop('Unnamed: 0', axis=1)\n",
    "# turn into numpy matrix\n",
    "ngrams_X_test = ngrams_X_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_Y_train_all = pd.read_csv('/home/shared/practical2/data/features/train_yvals.csv').drop('Unnamed: 0', axis=1)\n",
    "# turn Y_train into array\n",
    "ngrams_Y_train_all = np.array(ngrams_Y_train_all['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3086"
      ]
     },
     "execution_count": 14,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "len(ngrams_Y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 191855)"
      ]
     },
     "execution_count": 15,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "pd.DataFrame(ngrams_X_train_all).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3724, 191855)"
      ]
     },
     "execution_count": 16,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "pd.DataFrame(ngrams_X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>...</th>\n",
       "      <th>191755</th>\n",
       "      <th>191756</th>\n",
       "      <th>191757</th>\n",
       "      <th>191758</th>\n",
       "      <th>191759</th>\n",
       "      <th>191760</th>\n",
       "      <th>191761</th>\n",
       "      <th>191762</th>\n",
       "      <th>191763</th>\n",
       "      <th>191764</th>\n",
       "      <th>191765</th>\n",
       "      <th>191766</th>\n",
       "      <th>191767</th>\n",
       "      <th>191768</th>\n",
       "      <th>191769</th>\n",
       "      <th>191770</th>\n",
       "      <th>191771</th>\n",
       "      <th>191772</th>\n",
       "      <th>191773</th>\n",
       "      <th>191774</th>\n",
       "      <th>191775</th>\n",
       "      <th>191776</th>\n",
       "      <th>191777</th>\n",
       "      <th>191778</th>\n",
       "      <th>191779</th>\n",
       "      <th>191780</th>\n",
       "      <th>191781</th>\n",
       "      <th>191782</th>\n",
       "      <th>191783</th>\n",
       "      <th>191784</th>\n",
       "      <th>191785</th>\n",
       "      <th>191786</th>\n",
       "      <th>191787</th>\n",
       "      <th>191788</th>\n",
       "      <th>191789</th>\n",
       "      <th>191790</th>\n",
       "      <th>191791</th>\n",
       "      <th>191792</th>\n",
       "      <th>191793</th>\n",
       "      <th>191794</th>\n",
       "      <th>191795</th>\n",
       "      <th>191796</th>\n",
       "      <th>191797</th>\n",
       "      <th>191798</th>\n",
       "      <th>191799</th>\n",
       "      <th>191800</th>\n",
       "      <th>191801</th>\n",
       "      <th>191802</th>\n",
       "      <th>191803</th>\n",
       "      <th>191804</th>\n",
       "      <th>191805</th>\n",
       "      <th>191806</th>\n",
       "      <th>191807</th>\n",
       "      <th>191808</th>\n",
       "      <th>191809</th>\n",
       "      <th>191810</th>\n",
       "      <th>191811</th>\n",
       "      <th>191812</th>\n",
       "      <th>191813</th>\n",
       "      <th>191814</th>\n",
       "      <th>191815</th>\n",
       "      <th>191816</th>\n",
       "      <th>191817</th>\n",
       "      <th>191818</th>\n",
       "      <th>191819</th>\n",
       "      <th>191820</th>\n",
       "      <th>191821</th>\n",
       "      <th>191822</th>\n",
       "      <th>191823</th>\n",
       "      <th>191824</th>\n",
       "      <th>191825</th>\n",
       "      <th>191826</th>\n",
       "      <th>191827</th>\n",
       "      <th>191828</th>\n",
       "      <th>191829</th>\n",
       "      <th>191830</th>\n",
       "      <th>191831</th>\n",
       "      <th>191832</th>\n",
       "      <th>191833</th>\n",
       "      <th>191834</th>\n",
       "      <th>191835</th>\n",
       "      <th>191836</th>\n",
       "      <th>191837</th>\n",
       "      <th>191838</th>\n",
       "      <th>191839</th>\n",
       "      <th>191840</th>\n",
       "      <th>191841</th>\n",
       "      <th>191842</th>\n",
       "      <th>191843</th>\n",
       "      <th>191844</th>\n",
       "      <th>191845</th>\n",
       "      <th>191846</th>\n",
       "      <th>191847</th>\n",
       "      <th>191848</th>\n",
       "      <th>191849</th>\n",
       "      <th>191850</th>\n",
       "      <th>191851</th>\n",
       "      <th>191852</th>\n",
       "      <th>191853</th>\n",
       "      <th>191854</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 191855 columns</p>\n",
       "</div>"
      ]
     },
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "pd.DataFrame(ngrams_X_train_all).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>...</th>\n",
       "      <th>191755</th>\n",
       "      <th>191756</th>\n",
       "      <th>191757</th>\n",
       "      <th>191758</th>\n",
       "      <th>191759</th>\n",
       "      <th>191760</th>\n",
       "      <th>191761</th>\n",
       "      <th>191762</th>\n",
       "      <th>191763</th>\n",
       "      <th>191764</th>\n",
       "      <th>191765</th>\n",
       "      <th>191766</th>\n",
       "      <th>191767</th>\n",
       "      <th>191768</th>\n",
       "      <th>191769</th>\n",
       "      <th>191770</th>\n",
       "      <th>191771</th>\n",
       "      <th>191772</th>\n",
       "      <th>191773</th>\n",
       "      <th>191774</th>\n",
       "      <th>191775</th>\n",
       "      <th>191776</th>\n",
       "      <th>191777</th>\n",
       "      <th>191778</th>\n",
       "      <th>191779</th>\n",
       "      <th>191780</th>\n",
       "      <th>191781</th>\n",
       "      <th>191782</th>\n",
       "      <th>191783</th>\n",
       "      <th>191784</th>\n",
       "      <th>191785</th>\n",
       "      <th>191786</th>\n",
       "      <th>191787</th>\n",
       "      <th>191788</th>\n",
       "      <th>191789</th>\n",
       "      <th>191790</th>\n",
       "      <th>191791</th>\n",
       "      <th>191792</th>\n",
       "      <th>191793</th>\n",
       "      <th>191794</th>\n",
       "      <th>191795</th>\n",
       "      <th>191796</th>\n",
       "      <th>191797</th>\n",
       "      <th>191798</th>\n",
       "      <th>191799</th>\n",
       "      <th>191800</th>\n",
       "      <th>191801</th>\n",
       "      <th>191802</th>\n",
       "      <th>191803</th>\n",
       "      <th>191804</th>\n",
       "      <th>191805</th>\n",
       "      <th>191806</th>\n",
       "      <th>191807</th>\n",
       "      <th>191808</th>\n",
       "      <th>191809</th>\n",
       "      <th>191810</th>\n",
       "      <th>191811</th>\n",
       "      <th>191812</th>\n",
       "      <th>191813</th>\n",
       "      <th>191814</th>\n",
       "      <th>191815</th>\n",
       "      <th>191816</th>\n",
       "      <th>191817</th>\n",
       "      <th>191818</th>\n",
       "      <th>191819</th>\n",
       "      <th>191820</th>\n",
       "      <th>191821</th>\n",
       "      <th>191822</th>\n",
       "      <th>191823</th>\n",
       "      <th>191824</th>\n",
       "      <th>191825</th>\n",
       "      <th>191826</th>\n",
       "      <th>191827</th>\n",
       "      <th>191828</th>\n",
       "      <th>191829</th>\n",
       "      <th>191830</th>\n",
       "      <th>191831</th>\n",
       "      <th>191832</th>\n",
       "      <th>191833</th>\n",
       "      <th>191834</th>\n",
       "      <th>191835</th>\n",
       "      <th>191836</th>\n",
       "      <th>191837</th>\n",
       "      <th>191838</th>\n",
       "      <th>191839</th>\n",
       "      <th>191840</th>\n",
       "      <th>191841</th>\n",
       "      <th>191842</th>\n",
       "      <th>191843</th>\n",
       "      <th>191844</th>\n",
       "      <th>191845</th>\n",
       "      <th>191846</th>\n",
       "      <th>191847</th>\n",
       "      <th>191848</th>\n",
       "      <th>191849</th>\n",
       "      <th>191850</th>\n",
       "      <th>191851</th>\n",
       "      <th>191852</th>\n",
       "      <th>191853</th>\n",
       "      <th>191854</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 191855 columns</p>\n",
       "</div>"
      ]
     },
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "pd.DataFrame(ngrams_X_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191855"
      ]
     },
     "execution_count": 19,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "len(ngrams_X_train_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break out into train_test_split\n",
    "# ngrams_Y_train already in numpy array form\n",
    "ngrams_X_train, ngrams_X_valid, ngrams_Y_train, ngrams_Y_valid = train_test_split(\n",
    "    ngrams_X_train_all, ngrams_Y_train_all, train_size=0.7, random_state=1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Combine N-grams with counts and percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-92f0d506630e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mngcp_X_train_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcpcall_X_train_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngrams_X_train_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mngcp_X_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcpcall_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngrams_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anaconda2/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[0;32m    811\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m                        copy=copy)\n\u001b[1;32m--> 813\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anaconda2/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m--> 995\u001b[1;33m                 mgrs_indexers, self.new_axes, concat_axis=self.axis, copy=self.copy)\n\u001b[0m\u001b[0;32m    996\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anaconda2/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   4454\u001b[0m                                                 copy=copy),\n\u001b[0;32m   4455\u001b[0m                          placement=placement)\n\u001b[1;32m-> 4456\u001b[1;33m               for placement, join_units in concat_plan]\n\u001b[0m\u001b[0;32m   4457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4458\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anaconda2/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m   4551\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[0;32m   4552\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[1;32m-> 4553\u001b[1;33m                  for ju in join_units]\n\u001b[0m\u001b[0;32m   4554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4555\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anaconda2/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[1;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[0;32m   4799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4800\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_null\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'is_categorical'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4801\u001b[1;33m                 \u001b[0mmissing_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4802\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4803\u001b[0m                     \u001b[1;31m# NumPy 1.6 workaround: this statement gets strange if all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ngcp_X_train_all = pd.concat((pd.DataFrame(cpcall_X_train_all), pd.DataFrame(ngrams_X_train_all)), axis=0)    \n",
    "ngcp_X_test = pd.concat((pd.DataFrame(cpcall_X_test), pd.DataFrame(ngrams_X_test)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ngcp_X_train_all.shape\n",
    "print ngcp_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngcp_X_train_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngcp_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn  back into matrix\n",
    "ngcp_X_train_all = ngcp_X_train_all.as_matrix()\n",
    "ngcp_X_test = ngcp_X_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  6, 12, ...,  8,  8,  3])"
      ]
     },
     "execution_count": 43,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "ngrams_Y_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  8,  8, ...,  8,  8,  3])"
      ]
     },
     "execution_count": 44,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "cpcall_Y_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# Check that these are the same\n",
    "np.array_equal(Y_train_all, ngrams_Y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "np.array_equal(Y_train_all, cpcall_Y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO WARNING Y_train_all may not be the same\n",
    "ngcp_X_train, ngcp_X_valid, ngcp_Y_train, ngcp_Y_valid = train_test_split(\n",
    "    ngcp_X_train_all, Y_train_all, train_size=0.7, random_state=1004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. DLL Library Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Count of Successful and Failed DLL Load System Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scaling / Normalization\n",
    "\n",
    "# Resampling / Rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Baseline Model - All Not Malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2.MALWARE_CLASSES.index('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_train_pred = np.ones([len(X_train)])*8\n",
    "baseline_valid_pred = np.ones([len(X_valid)])*8\n",
    "baseline_test_pred = np.ones([len(X_test)])*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(baseline_train_pred)\n",
    "print len(baseline_valid_pred)\n",
    "print len(baseline_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52222222222222225"
      ]
     },
     "execution_count": 26,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# training set\n",
    "accuracy_score(Y_train, baseline_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51943844492440605"
      ]
     },
     "execution_count": 27,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# validation set\n",
    "accuracy_score(Y_valid, baseline_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2.write_predictions(baseline_test_pred, test_ids, 'predictions/baseline_allNone.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Features Provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST {'penalty': 'l2', 'C': 1e-05} 0.653703703704 [mean: 0.03657, std: 0.00077, params: {'penalty': 'l1', 'C': 1e-06}, mean: 0.59120, std: 0.13042, params: {'penalty': 'l2', 'C': 1e-06}, mean: 0.19537, std: 0.00477, params: {'penalty': 'l1', 'C': 1e-05}, mean: 0.65370, std: 0.01983, params: {'penalty': 'l2', 'C': 1e-05}, mean: 0.45648, std: 0.15508, params: {'penalty': 'l1', 'C': 0.0001}, mean: 0.61435, std: 0.01474, params: {'penalty': 'l2', 'C': 0.0001}, mean: 0.46528, std: 0.15409, params: {'penalty': 'l1', 'C': 0.001}, mean: 0.59398, std: 0.01052, params: {'penalty': 'l2', 'C': 0.001}, mean: 0.55741, std: 0.01041, params: {'penalty': 'l1', 'C': 0.01}, mean: 0.55926, std: 0.01016, params: {'penalty': 'l2', 'C': 0.01}, mean: 0.54583, std: 0.01236, params: {'penalty': 'l1', 'C': 0.1}, mean: 0.54630, std: 0.01205, params: {'penalty': 'l2', 'C': 0.1}, mean: 0.54398, std: 0.01350, params: {'penalty': 'l1', 'C': 1.0}, mean: 0.54398, std: 0.01350, params: {'penalty': 'l2', 'C': 1.0}, mean: 0.54398, std: 0.01350, params: {'penalty': 'l1', 'C': 10.0}, mean: 0.54398, std: 0.01350, params: {'penalty': 'l2', 'C': 10.0}, mean: 0.54398, std: 0.01350, params: {'penalty': 'l1', 'C': 100.0}, mean: 0.54398, std: 0.01350, params: {'penalty': 'l2', 'C': 100.0}, mean: 0.54398, std: 0.01350, params: {'penalty': 'l1', 'C': 1000.0}, mean: 0.54398, std: 0.01350, params: {'penalty': 'l2', 'C': 1000.0}, mean: 0.54398, std: 0.01350, params: {'penalty': 'l1', 'C': 10000.0}, mean: 0.54398, std: 0.01350, params: {'penalty': 'l2', 'C': 10000.0}]\n",
      "############\n",
      "LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "----------\n",
      "Training set accuracy = 0.6583\n",
      "Validation set accuracy = 0.6609\n",
      "----------\n",
      "############\n",
      "############\n",
      "LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "----------\n",
      "Training set accuracy = 0.6196\n",
      "----------\n",
      "############\n",
      "7.7 seconds runtime\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "# parameters\n",
    "penalties = ['l1', 'l2']\n",
    "cs = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0] # default = 1.0\n",
    "\n",
    "# cross-validation\n",
    "model = p2.cv_optimize(model, {'penalty': penalties, 'C': cs}, X_train, Y_train)\n",
    "\n",
    "# fit model on training set with optimal parameters\n",
    "# check out-of-sample performance using validation set\n",
    "model = p2.fit_model(model, X_train, Y_train, test_x=X_valid, test_y=Y_valid, title='LR Features provided',\n",
    "                     tracker=tracker)\n",
    "\n",
    "# fit model on entire training set with optimal parameters and make predictions\n",
    "model = p2.fit_model(model, X_train_all, Y_train_all)\n",
    "# Y_test_pred = model.predict(X_test)\n",
    "# p2.write_predictions(Y_test_pred, test_ids, 'predictions/baseline_logistic.csv')\n",
    "\n",
    "print '%0.1f seconds runtime' % (time.time() - start)\n",
    "\n",
    "# option to save fitted model\n",
    "# joblib.dump(model, 'models/baseline_logistic.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR Features provided': [LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False),\n",
       "  0.65833333333333333,\n",
       "  0.66090712742980562]}"
      ]
     },
     "execution_count": 35,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model.predict(X_test)\n",
    "p2.write_predictions(Y_test_pred, test_ids, 'predictions/baseline_logistic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Features Provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1} 0.741203703704 [mean: 0.73981, std: 0.01306, params: {'max_features': 0.1, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74028, std: 0.01221, params: {'max_features': 0.1, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74028, std: 0.01445, params: {'max_features': 0.1, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74074, std: 0.01360, params: {'max_features': 0.1, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74028, std: 0.01222, params: {'max_features': 0.1, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73935, std: 0.01288, params: {'max_features': 0.1, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.72593, std: 0.01524, params: {'max_features': 0.1, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72407, std: 0.01281, params: {'max_features': 0.1, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72685, std: 0.01166, params: {'max_features': 0.1, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72593, std: 0.01500, params: {'max_features': 0.1, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72778, std: 0.01312, params: {'max_features': 0.1, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72778, std: 0.01407, params: {'max_features': 0.1, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.71481, std: 0.01219, params: {'max_features': 0.1, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71435, std: 0.01034, params: {'max_features': 0.1, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71389, std: 0.01004, params: {'max_features': 0.1, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71713, std: 0.01136, params: {'max_features': 0.1, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71389, std: 0.01101, params: {'max_features': 0.1, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71574, std: 0.01138, params: {'max_features': 0.1, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.69537, std: 0.00855, params: {'max_features': 0.1, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70278, std: 0.00838, params: {'max_features': 0.1, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70694, std: 0.01313, params: {'max_features': 0.1, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70694, std: 0.01276, params: {'max_features': 0.1, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70602, std: 0.01223, params: {'max_features': 0.1, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70509, std: 0.00968, params: {'max_features': 0.1, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.68889, std: 0.02023, params: {'max_features': 0.1, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68333, std: 0.00760, params: {'max_features': 0.1, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68935, std: 0.00946, params: {'max_features': 0.1, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69259, std: 0.00736, params: {'max_features': 0.1, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68889, std: 0.00982, params: {'max_features': 0.1, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68889, std: 0.00982, params: {'max_features': 0.1, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.67963, std: 0.01371, params: {'max_features': 0.1, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.68056, std: 0.00353, params: {'max_features': 0.1, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67454, std: 0.00709, params: {'max_features': 0.1, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67778, std: 0.00744, params: {'max_features': 0.1, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67454, std: 0.00709, params: {'max_features': 0.1, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67454, std: 0.00709, params: {'max_features': 0.1, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.73981, std: 0.01325, params: {'max_features': 0.25, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73750, std: 0.01168, params: {'max_features': 0.25, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74028, std: 0.01222, params: {'max_features': 0.25, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73981, std: 0.01381, params: {'max_features': 0.25, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74028, std: 0.01389, params: {'max_features': 0.25, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74028, std: 0.01235, params: {'max_features': 0.25, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.71806, std: 0.01393, params: {'max_features': 0.25, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72917, std: 0.01283, params: {'max_features': 0.25, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72824, std: 0.01286, params: {'max_features': 0.25, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72824, std: 0.01164, params: {'max_features': 0.25, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72731, std: 0.01288, params: {'max_features': 0.25, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72731, std: 0.01480, params: {'max_features': 0.25, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.70139, std: 0.00872, params: {'max_features': 0.25, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71435, std: 0.01251, params: {'max_features': 0.25, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71528, std: 0.00960, params: {'max_features': 0.25, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71481, std: 0.01031, params: {'max_features': 0.25, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71389, std: 0.01045, params: {'max_features': 0.25, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71389, std: 0.01022, params: {'max_features': 0.25, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.70694, std: 0.01027, params: {'max_features': 0.25, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70324, std: 0.00815, params: {'max_features': 0.25, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70741, std: 0.01246, params: {'max_features': 0.25, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70694, std: 0.01232, params: {'max_features': 0.25, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70463, std: 0.01147, params: {'max_features': 0.25, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70741, std: 0.01169, params: {'max_features': 0.25, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.68426, std: 0.00720, params: {'max_features': 0.25, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69167, std: 0.00797, params: {'max_features': 0.25, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68565, std: 0.00962, params: {'max_features': 0.25, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68796, std: 0.00995, params: {'max_features': 0.25, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68843, std: 0.01025, params: {'max_features': 0.25, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68843, std: 0.01025, params: {'max_features': 0.25, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.67593, std: 0.01188, params: {'max_features': 0.25, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67778, std: 0.01125, params: {'max_features': 0.25, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67454, std: 0.00709, params: {'max_features': 0.25, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67639, std: 0.00657, params: {'max_features': 0.25, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67454, std: 0.00709, params: {'max_features': 0.25, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67639, std: 0.00657, params: {'max_features': 0.25, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.73981, std: 0.01247, params: {'max_features': 0.5, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73889, std: 0.01190, params: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73935, std: 0.01128, params: {'max_features': 0.5, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74028, std: 0.01255, params: {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73935, std: 0.01365, params: {'max_features': 0.5, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73796, std: 0.01172, params: {'max_features': 0.5, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.72407, std: 0.01146, params: {'max_features': 0.5, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72917, std: 0.01126, params: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72778, std: 0.01450, params: {'max_features': 0.5, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72917, std: 0.01301, params: {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72731, std: 0.01675, params: {'max_features': 0.5, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72685, std: 0.01442, params: {'max_features': 0.5, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.71250, std: 0.01204, params: {'max_features': 0.5, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71481, std: 0.00948, params: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71574, std: 0.01175, params: {'max_features': 0.5, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71389, std: 0.00952, params: {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71481, std: 0.01260, params: {'max_features': 0.5, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71574, std: 0.01159, params: {'max_features': 0.5, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.70648, std: 0.01368, params: {'max_features': 0.5, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70231, std: 0.00849, params: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70648, std: 0.01025, params: {'max_features': 0.5, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70509, std: 0.00968, params: {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70694, std: 0.01276, params: {'max_features': 0.5, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70694, std: 0.01177, params: {'max_features': 0.5, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.68796, std: 0.00946, params: {'max_features': 0.5, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68843, std: 0.01025, params: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69259, std: 0.01798, params: {'max_features': 0.5, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68472, std: 0.00748, params: {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68843, std: 0.00826, params: {'max_features': 0.5, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68843, std: 0.01025, params: {'max_features': 0.5, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.67639, std: 0.00657, params: {'max_features': 0.5, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67454, std: 0.00709, params: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67731, std: 0.01051, params: {'max_features': 0.5, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.68333, std: 0.01384, params: {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67870, std: 0.01280, params: {'max_features': 0.5, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67593, std: 0.00651, params: {'max_features': 0.5, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.73981, std: 0.01125, params: {'max_features': 0.75, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74074, std: 0.01175, params: {'max_features': 0.75, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73843, std: 0.01180, params: {'max_features': 0.75, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73981, std: 0.01350, params: {'max_features': 0.75, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74028, std: 0.01354, params: {'max_features': 0.75, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74074, std: 0.01380, params: {'max_features': 0.75, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73102, std: 0.01718, params: {'max_features': 0.75, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72685, std: 0.01147, params: {'max_features': 0.75, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72639, std: 0.01470, params: {'max_features': 0.75, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72639, std: 0.01698, params: {'max_features': 0.75, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72963, std: 0.01450, params: {'max_features': 0.75, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72731, std: 0.01480, params: {'max_features': 0.75, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.71574, std: 0.01213, params: {'max_features': 0.75, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71389, std: 0.01140, params: {'max_features': 0.75, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71528, std: 0.01157, params: {'max_features': 0.75, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71528, std: 0.00960, params: {'max_features': 0.75, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71574, std: 0.00902, params: {'max_features': 0.75, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71481, std: 0.00866, params: {'max_features': 0.75, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.70602, std: 0.00991, params: {'max_features': 0.75, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70139, std: 0.00784, params: {'max_features': 0.75, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70556, std: 0.01332, params: {'max_features': 0.75, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70509, std: 0.00845, params: {'max_features': 0.75, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70787, std: 0.01182, params: {'max_features': 0.75, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70694, std: 0.01313, params: {'max_features': 0.75, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.68565, std: 0.00962, params: {'max_features': 0.75, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69306, std: 0.00662, params: {'max_features': 0.75, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68843, std: 0.01025, params: {'max_features': 0.75, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68981, std: 0.01063, params: {'max_features': 0.75, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68889, std: 0.00917, params: {'max_features': 0.75, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68796, std: 0.00995, params: {'max_features': 0.75, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.67269, std: 0.00668, params: {'max_features': 0.75, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67500, std: 0.00678, params: {'max_features': 0.75, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67824, std: 0.01202, params: {'max_features': 0.75, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67870, std: 0.01280, params: {'max_features': 0.75, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67731, std: 0.00704, params: {'max_features': 0.75, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67731, std: 0.00704, params: {'max_features': 0.75, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.73611, std: 0.01079, params: {'max_features': 1.0, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73981, std: 0.01273, params: {'max_features': 1.0, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73935, std: 0.01321, params: {'max_features': 1.0, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74028, std: 0.01132, params: {'max_features': 1.0, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74120, std: 0.01329, params: {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73889, std: 0.01297, params: {'max_features': 1.0, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.72917, std: 0.01543, params: {'max_features': 1.0, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.73102, std: 0.01633, params: {'max_features': 1.0, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72963, std: 0.01643, params: {'max_features': 1.0, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72917, std: 0.01567, params: {'max_features': 1.0, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.73009, std: 0.01712, params: {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.73148, std: 0.01526, params: {'max_features': 1.0, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72731, std: 0.01930, params: {'max_features': 1.0, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.72963, std: 0.02127, params: {'max_features': 1.0, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.72778, std: 0.02064, params: {'max_features': 1.0, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.72454, std: 0.01702, params: {'max_features': 1.0, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.72731, std: 0.01834, params: {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.72731, std: 0.02000, params: {'max_features': 1.0, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.72593, std: 0.01452, params: {'max_features': 1.0, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.72639, std: 0.01534, params: {'max_features': 1.0, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.72546, std: 0.01573, params: {'max_features': 1.0, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.72546, std: 0.01644, params: {'max_features': 1.0, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.72593, std: 0.01516, params: {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.72546, std: 0.01573, params: {'max_features': 1.0, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.69583, std: 0.01321, params: {'max_features': 1.0, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69676, std: 0.01303, params: {'max_features': 1.0, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69630, std: 0.01309, params: {'max_features': 1.0, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69630, std: 0.01309, params: {'max_features': 1.0, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69630, std: 0.01309, params: {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69630, std: 0.01309, params: {'max_features': 1.0, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69630, std: 0.01304, params: {'max_features': 1.0, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.69630, std: 0.01304, params: {'max_features': 1.0, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.69630, std: 0.01304, params: {'max_features': 1.0, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.69630, std: 0.01304, params: {'max_features': 1.0, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.69676, std: 0.01378, params: {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.69676, std: 0.01378, params: {'max_features': 1.0, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.74028, std: 0.01319, params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73981, std: 0.01350, params: {'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73981, std: 0.01204, params: {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73889, std: 0.01157, params: {'max_features': 'sqrt', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73935, std: 0.01242, params: {'max_features': 'sqrt', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74074, std: 0.01321, params: {'max_features': 'sqrt', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73009, std: 0.01204, params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72593, std: 0.01494, params: {'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72870, std: 0.01409, params: {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72685, std: 0.01472, params: {'max_features': 'sqrt', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72824, std: 0.01457, params: {'max_features': 'sqrt', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72639, std: 0.01540, params: {'max_features': 'sqrt', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.71574, std: 0.01236, params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71019, std: 0.00858, params: {'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71481, std: 0.00946, params: {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71620, std: 0.00690, params: {'max_features': 'sqrt', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71528, std: 0.00991, params: {'max_features': 'sqrt', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71528, std: 0.01073, params: {'max_features': 'sqrt', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.69815, std: 0.00924, params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70278, std: 0.00849, params: {'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70648, std: 0.01161, params: {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70602, std: 0.01229, params: {'max_features': 'sqrt', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70278, std: 0.00769, params: {'max_features': 'sqrt', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70463, std: 0.00869, params: {'max_features': 'sqrt', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.68472, std: 0.00974, params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69259, std: 0.01365, params: {'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68889, std: 0.00917, params: {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68935, std: 0.00946, params: {'max_features': 'sqrt', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68843, std: 0.01025, params: {'max_features': 'sqrt', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68843, std: 0.01025, params: {'max_features': 'sqrt', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68380, std: 0.01435, params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67685, std: 0.01213, params: {'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67824, std: 0.01202, params: {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67454, std: 0.00709, params: {'max_features': 'sqrt', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67454, std: 0.00709, params: {'max_features': 'sqrt', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67454, std: 0.00709, params: {'max_features': 'sqrt', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.74028, std: 0.01790, params: {'max_features': 'log2', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73889, std: 0.01106, params: {'max_features': 'log2', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73750, std: 0.01418, params: {'max_features': 'log2', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73750, std: 0.01083, params: {'max_features': 'log2', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.74074, std: 0.01380, params: {'max_features': 'log2', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.73981, std: 0.01294, params: {'max_features': 'log2', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.72500, std: 0.01751, params: {'max_features': 'log2', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72593, std: 0.01527, params: {'max_features': 'log2', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72593, std: 0.01500, params: {'max_features': 'log2', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72685, std: 0.01459, params: {'max_features': 'log2', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72824, std: 0.01405, params: {'max_features': 'log2', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.72870, std: 0.01290, params: {'max_features': 'log2', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.71111, std: 0.01391, params: {'max_features': 'log2', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71435, std: 0.01015, params: {'max_features': 'log2', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71343, std: 0.01039, params: {'max_features': 'log2', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71481, std: 0.00912, params: {'max_features': 'log2', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71528, std: 0.00881, params: {'max_features': 'log2', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.71481, std: 0.00962, params: {'max_features': 'log2', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.70787, std: 0.01280, params: {'max_features': 'log2', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70694, std: 0.01315, params: {'max_features': 'log2', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70602, std: 0.01368, params: {'max_features': 'log2', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70833, std: 0.01118, params: {'max_features': 'log2', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70694, std: 0.01232, params: {'max_features': 'log2', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.70463, std: 0.01147, params: {'max_features': 'log2', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.68472, std: 0.00589, params: {'max_features': 'log2', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69306, std: 0.00580, params: {'max_features': 'log2', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68750, std: 0.00990, params: {'max_features': 'log2', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68796, std: 0.00978, params: {'max_features': 'log2', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69306, std: 0.00662, params: {'max_features': 'log2', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.69259, std: 0.00736, params: {'max_features': 'log2', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.68380, std: 0.01288, params: {'max_features': 'log2', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.68380, std: 0.01513, params: {'max_features': 'log2', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67454, std: 0.00709, params: {'max_features': 'log2', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67917, std: 0.00966, params: {'max_features': 'log2', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67454, std: 0.00709, params: {'max_features': 'log2', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.67454, std: 0.00709, params: {'max_features': 'log2', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}]\n",
      "############\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=1.0, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "----------\n",
      "Training set accuracy = 0.7986\n",
      "Validation set accuracy = 0.7527\n",
      "----------\n",
      "############\n",
      "############\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=1.0, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "----------\n",
      "Training set accuracy = 0.8001\n",
      "----------\n",
      "############\n",
      "381.0 seconds runtime\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# update model class and/or parameters to search over here\n",
    "model = RandomForestClassifier()\n",
    "estimators = [10, 50, 100, 150, 200, 250] # default = 10\n",
    "features = [0.1, 0.25, 0.5, 0.75, 1.0, 'sqrt', 'log2'] # default = 'sqrt'\n",
    "depths = [None] # default = None (i.e. ignored)\n",
    "samples = [1, 5, 10, 25, 50, 100] # default = 1\n",
    "\n",
    "# cross-validation on training set to identify optimal parameters\n",
    "model = p2.cv_optimize(model, {'n_estimators': estimators, 'max_features': features,\n",
    "                            'max_depth': depths, 'min_samples_leaf': samples}, X_train, Y_train)\n",
    "\n",
    "# fit model on training set with optimal parameters\n",
    "# check out-of-sample performance using validation set\n",
    "model = p2.fit_model(model, X_train, Y_train, test_x=X_valid, test_y=Y_valid, title='Random Forest Features provided',\n",
    "                     tracker=tracker)\n",
    "\n",
    "# fit model on entire training set with optimal parameters and make predictions\n",
    "model = p2.fit_model(model, X_train_all, Y_train_all)\n",
    "# Y_test_pred = model.predict(X_test)\n",
    "# p2.write_predictions(Y_test_pred, test_ids, 'predictions/f02_random_forest.csv')\n",
    "\n",
    "print '%0.1f seconds runtime' % (time.time() - start)\n",
    "\n",
    "# option to save fitted model\n",
    "# joblib.dump(model, 'models/f02_random_forest.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR Features provided': [LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False),\n",
       "  0.65833333333333333,\n",
       "  0.66090712742980562],\n",
       " 'Random Forest Features provided': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.7949074074074074, 0.74838012958963285]}"
      ]
     },
     "execution_count": 36,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model.predict(X_test)\n",
    "p2.write_predictions(Y_test_pred, test_ids, 'predictions/f02_random_forest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Counts & Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1} 0.889814814815 [mean: 0.87269, std: 0.01161, params: {'max_features': 0.1, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88241, std: 0.00742, params: {'max_features': 0.1, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88611, std: 0.01427, params: {'max_features': 0.1, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88657, std: 0.00986, params: {'max_features': 0.1, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88704, std: 0.01027, params: {'max_features': 0.1, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88657, std: 0.01291, params: {'max_features': 0.1, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.86759, std: 0.01081, params: {'max_features': 0.1, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87315, std: 0.01185, params: {'max_features': 0.1, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87593, std: 0.00889, params: {'max_features': 0.1, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87593, std: 0.01092, params: {'max_features': 0.1, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87546, std: 0.00664, params: {'max_features': 0.1, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87593, std: 0.00735, params: {'max_features': 0.1, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.85602, std: 0.00731, params: {'max_features': 0.1, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86111, std: 0.00918, params: {'max_features': 0.1, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.85833, std: 0.01032, params: {'max_features': 0.1, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.85787, std: 0.00965, params: {'max_features': 0.1, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.85880, std: 0.01005, params: {'max_features': 0.1, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.85741, std: 0.01056, params: {'max_features': 0.1, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.82731, std: 0.00993, params: {'max_features': 0.1, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.82315, std: 0.00963, params: {'max_features': 0.1, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.82546, std: 0.00769, params: {'max_features': 0.1, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.82917, std: 0.00945, params: {'max_features': 0.1, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.82500, std: 0.00676, params: {'max_features': 0.1, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.82361, std: 0.00701, params: {'max_features': 0.1, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.79213, std: 0.00911, params: {'max_features': 0.1, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79213, std: 0.00863, params: {'max_features': 0.1, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79167, std: 0.00732, params: {'max_features': 0.1, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79028, std: 0.00943, params: {'max_features': 0.1, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79213, std: 0.00750, params: {'max_features': 0.1, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79167, std: 0.00832, params: {'max_features': 0.1, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.78935, std: 0.00553, params: {'max_features': 0.1, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.79120, std: 0.00871, params: {'max_features': 0.1, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78981, std: 0.00911, params: {'max_features': 0.1, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.79167, std: 0.00795, params: {'max_features': 0.1, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.79028, std: 0.01122, params: {'max_features': 0.1, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.79120, std: 0.01016, params: {'max_features': 0.1, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.87546, std: 0.00937, params: {'max_features': 0.25, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88750, std: 0.01242, params: {'max_features': 0.25, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88750, std: 0.01173, params: {'max_features': 0.25, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88889, std: 0.01104, params: {'max_features': 0.25, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88704, std: 0.01363, params: {'max_features': 0.25, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88935, std: 0.01270, params: {'max_features': 0.25, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.86898, std: 0.02074, params: {'max_features': 0.25, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87917, std: 0.01036, params: {'max_features': 0.25, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87778, std: 0.01231, params: {'max_features': 0.25, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87963, std: 0.01342, params: {'max_features': 0.25, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87870, std: 0.01208, params: {'max_features': 0.25, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.88102, std: 0.00982, params: {'max_features': 0.25, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.85556, std: 0.01109, params: {'max_features': 0.25, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86019, std: 0.01049, params: {'max_features': 0.25, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86250, std: 0.00584, params: {'max_features': 0.25, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86019, std: 0.00738, params: {'max_features': 0.25, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86065, std: 0.00648, params: {'max_features': 0.25, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86157, std: 0.00811, params: {'max_features': 0.25, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.82778, std: 0.01138, params: {'max_features': 0.25, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83333, std: 0.01371, params: {'max_features': 0.25, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83565, std: 0.01026, params: {'max_features': 0.25, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83472, std: 0.01326, params: {'max_features': 0.25, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83380, std: 0.01023, params: {'max_features': 0.25, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83657, std: 0.00969, params: {'max_features': 0.25, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.79352, std: 0.00873, params: {'max_features': 0.25, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79907, std: 0.00599, params: {'max_features': 0.25, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79815, std: 0.01171, params: {'max_features': 0.25, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79907, std: 0.01225, params: {'max_features': 0.25, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79722, std: 0.01409, params: {'max_features': 0.25, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80000, std: 0.01123, params: {'max_features': 0.25, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.78565, std: 0.01175, params: {'max_features': 0.25, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78657, std: 0.01282, params: {'max_features': 0.25, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78981, std: 0.01377, params: {'max_features': 0.25, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78565, std: 0.01257, params: {'max_features': 0.25, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78935, std: 0.01488, params: {'max_features': 0.25, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78657, std: 0.01074, params: {'max_features': 0.25, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.87824, std: 0.01227, params: {'max_features': 0.5, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88148, std: 0.00923, params: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88750, std: 0.01221, params: {'max_features': 0.5, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88981, std: 0.01225, params: {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88704, std: 0.01192, params: {'max_features': 0.5, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88796, std: 0.01254, params: {'max_features': 0.5, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.86898, std: 0.01729, params: {'max_features': 0.5, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87639, std: 0.01208, params: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87917, std: 0.01279, params: {'max_features': 0.5, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.88194, std: 0.01670, params: {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87685, std: 0.01494, params: {'max_features': 0.5, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.88009, std: 0.01438, params: {'max_features': 0.5, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.85556, std: 0.01127, params: {'max_features': 0.5, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86157, std: 0.01011, params: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86389, std: 0.01014, params: {'max_features': 0.5, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86157, std: 0.01089, params: {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86389, std: 0.01079, params: {'max_features': 0.5, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86343, std: 0.01146, params: {'max_features': 0.5, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.83241, std: 0.01648, params: {'max_features': 0.5, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83935, std: 0.01068, params: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83796, std: 0.01452, params: {'max_features': 0.5, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83704, std: 0.01391, params: {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83750, std: 0.01397, params: {'max_features': 0.5, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83750, std: 0.01618, params: {'max_features': 0.5, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.79861, std: 0.01200, params: {'max_features': 0.5, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80139, std: 0.01376, params: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80370, std: 0.01350, params: {'max_features': 0.5, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80417, std: 0.01292, params: {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80139, std: 0.01112, params: {'max_features': 0.5, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80185, std: 0.01457, params: {'max_features': 0.5, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.78426, std: 0.01096, params: {'max_features': 0.5, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78750, std: 0.01474, params: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78380, std: 0.01245, params: {'max_features': 0.5, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78426, std: 0.01156, params: {'max_features': 0.5, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78472, std: 0.01287, params: {'max_features': 0.5, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78426, std: 0.01224, params: {'max_features': 0.5, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.87130, std: 0.01087, params: {'max_features': 0.75, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88009, std: 0.01369, params: {'max_features': 0.75, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88750, std: 0.01386, params: {'max_features': 0.75, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88796, std: 0.00960, params: {'max_features': 0.75, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88750, std: 0.01053, params: {'max_features': 0.75, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88750, std: 0.01034, params: {'max_features': 0.75, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.87222, std: 0.01733, params: {'max_features': 0.75, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87500, std: 0.01713, params: {'max_features': 0.75, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87639, std: 0.01632, params: {'max_features': 0.75, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87500, std: 0.01758, params: {'max_features': 0.75, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87824, std: 0.01691, params: {'max_features': 0.75, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87407, std: 0.01583, params: {'max_features': 0.75, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.85926, std: 0.01725, params: {'max_features': 0.75, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86019, std: 0.01235, params: {'max_features': 0.75, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86435, std: 0.01031, params: {'max_features': 0.75, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86343, std: 0.01263, params: {'max_features': 0.75, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86157, std: 0.01055, params: {'max_features': 0.75, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86250, std: 0.00764, params: {'max_features': 0.75, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.83611, std: 0.01254, params: {'max_features': 0.75, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83889, std: 0.01521, params: {'max_features': 0.75, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.84074, std: 0.01608, params: {'max_features': 0.75, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.84167, std: 0.01220, params: {'max_features': 0.75, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83889, std: 0.01693, params: {'max_features': 0.75, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.84028, std: 0.01488, params: {'max_features': 0.75, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.80000, std: 0.01584, params: {'max_features': 0.75, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80046, std: 0.01248, params: {'max_features': 0.75, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79954, std: 0.01471, params: {'max_features': 0.75, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80185, std: 0.01669, params: {'max_features': 0.75, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80278, std: 0.01537, params: {'max_features': 0.75, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80370, std: 0.01625, params: {'max_features': 0.75, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.78426, std: 0.01337, params: {'max_features': 0.75, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78102, std: 0.01238, params: {'max_features': 0.75, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78194, std: 0.01255, params: {'max_features': 0.75, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78287, std: 0.01206, params: {'max_features': 0.75, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78333, std: 0.01269, params: {'max_features': 0.75, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78287, std: 0.01223, params: {'max_features': 0.75, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.86852, std: 0.01285, params: {'max_features': 1.0, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.87731, std: 0.01057, params: {'max_features': 1.0, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88148, std: 0.01136, params: {'max_features': 1.0, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88194, std: 0.01197, params: {'max_features': 1.0, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88102, std: 0.01021, params: {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88472, std: 0.01320, params: {'max_features': 1.0, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.86528, std: 0.02000, params: {'max_features': 1.0, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87176, std: 0.01711, params: {'max_features': 1.0, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87731, std: 0.01675, params: {'max_features': 1.0, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87407, std: 0.01512, params: {'max_features': 1.0, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87407, std: 0.01426, params: {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87685, std: 0.01541, params: {'max_features': 1.0, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.85185, std: 0.01311, params: {'max_features': 1.0, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86065, std: 0.01361, params: {'max_features': 1.0, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86204, std: 0.01283, params: {'max_features': 1.0, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86065, std: 0.01158, params: {'max_features': 1.0, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86435, std: 0.01316, params: {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.86204, std: 0.01261, params: {'max_features': 1.0, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.83657, std: 0.01577, params: {'max_features': 1.0, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.84028, std: 0.01645, params: {'max_features': 1.0, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83843, std: 0.01658, params: {'max_features': 1.0, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.83750, std: 0.01625, params: {'max_features': 1.0, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.84074, std: 0.01924, params: {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.84028, std: 0.01747, params: {'max_features': 1.0, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.79907, std: 0.01183, params: {'max_features': 1.0, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80093, std: 0.01371, params: {'max_features': 1.0, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80278, std: 0.01750, params: {'max_features': 1.0, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80185, std: 0.01504, params: {'max_features': 1.0, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80093, std: 0.01657, params: {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.80093, std: 0.01572, params: {'max_features': 1.0, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.78056, std: 0.01242, params: {'max_features': 1.0, 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78102, std: 0.01071, params: {'max_features': 1.0, 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78333, std: 0.01344, params: {'max_features': 1.0, 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78148, std: 0.01228, params: {'max_features': 1.0, 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78241, std: 0.01196, params: {'max_features': 1.0, 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78287, std: 0.01485, params: {'max_features': 1.0, 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.87639, std: 0.00872, params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88472, std: 0.01104, params: {'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88426, std: 0.01065, params: {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88657, std: 0.00833, params: {'max_features': 'sqrt', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88796, std: 0.00937, params: {'max_features': 'sqrt', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88611, std: 0.00908, params: {'max_features': 'sqrt', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.86713, std: 0.01133, params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87222, std: 0.00994, params: {'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87222, std: 0.01154, params: {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87176, std: 0.00972, params: {'max_features': 'sqrt', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87269, std: 0.00860, params: {'max_features': 'sqrt', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.87315, std: 0.00880, params: {'max_features': 'sqrt', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.84769, std: 0.01521, params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.85556, std: 0.00749, params: {'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.85648, std: 0.01062, params: {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.85972, std: 0.01004, params: {'max_features': 'sqrt', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.85741, std: 0.00875, params: {'max_features': 'sqrt', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.85694, std: 0.00861, params: {'max_features': 'sqrt', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.81898, std: 0.01040, params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.81944, std: 0.00691, params: {'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.82269, std: 0.00734, params: {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.82222, std: 0.00753, params: {'max_features': 'sqrt', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.82083, std: 0.00943, params: {'max_features': 'sqrt', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.82176, std: 0.00762, params: {'max_features': 'sqrt', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.78981, std: 0.01468, params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79352, std: 0.00562, params: {'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79167, std: 0.00912, params: {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79120, std: 0.01016, params: {'max_features': 'sqrt', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.78981, std: 0.00971, params: {'max_features': 'sqrt', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79120, std: 0.00871, params: {'max_features': 'sqrt', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.77917, std: 0.01724, params: {'max_features': 'sqrt', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78426, std: 0.01055, params: {'max_features': 'sqrt', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78380, std: 0.01049, params: {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78935, std: 0.00949, params: {'max_features': 'sqrt', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78796, std: 0.00880, params: {'max_features': 'sqrt', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.78796, std: 0.00910, params: {'max_features': 'sqrt', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.87593, std: 0.00924, params: {'max_features': 'log2', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88519, std: 0.01315, params: {'max_features': 'log2', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88472, std: 0.01075, params: {'max_features': 'log2', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88565, std: 0.01058, params: {'max_features': 'log2', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88704, std: 0.00738, params: {'max_features': 'log2', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.88194, std: 0.01142, params: {'max_features': 'log2', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 1}, mean: 0.86250, std: 0.01257, params: {'max_features': 'log2', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.86759, std: 0.00771, params: {'max_features': 'log2', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.86806, std: 0.00595, params: {'max_features': 'log2', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.86528, std: 0.01032, params: {'max_features': 'log2', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.86852, std: 0.01037, params: {'max_features': 'log2', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.86806, std: 0.00671, params: {'max_features': 'log2', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 5}, mean: 0.84352, std: 0.00718, params: {'max_features': 'log2', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.85046, std: 0.00381, params: {'max_features': 'log2', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.84769, std: 0.01058, params: {'max_features': 'log2', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.84769, std: 0.00893, params: {'max_features': 'log2', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.84861, std: 0.00654, params: {'max_features': 'log2', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.84907, std: 0.00739, params: {'max_features': 'log2', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 10}, mean: 0.81204, std: 0.00964, params: {'max_features': 'log2', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.81389, std: 0.00756, params: {'max_features': 'log2', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.81620, std: 0.00829, params: {'max_features': 'log2', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.80972, std: 0.00966, params: {'max_features': 'log2', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.81296, std: 0.01347, params: {'max_features': 'log2', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.81528, std: 0.00868, params: {'max_features': 'log2', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 25}, mean: 0.78472, std: 0.00997, params: {'max_features': 'log2', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.79306, std: 0.01037, params: {'max_features': 'log2', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.78565, std: 0.01391, params: {'max_features': 'log2', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.78796, std: 0.01019, params: {'max_features': 'log2', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.78796, std: 0.01071, params: {'max_features': 'log2', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.78981, std: 0.00976, params: {'max_features': 'log2', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 50}, mean: 0.77315, std: 0.01093, params: {'max_features': 'log2', 'n_estimators': 10, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.76574, std: 0.01582, params: {'max_features': 'log2', 'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.76296, std: 0.01082, params: {'max_features': 'log2', 'n_estimators': 100, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.76389, std: 0.01396, params: {'max_features': 'log2', 'n_estimators': 150, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.76528, std: 0.01215, params: {'max_features': 'log2', 'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 100}, mean: 0.76111, std: 0.00915, params: {'max_features': 'log2', 'n_estimators': 250, 'max_depth': None, 'min_samples_leaf': 100}]\n",
      "############\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "----------\n",
      "Training set accuracy = 0.9856\n",
      "Validation set accuracy = 0.8866\n",
      "----------\n",
      "############\n",
      "############\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "----------\n",
      "Training set accuracy = 0.9844\n",
      "----------\n",
      "############\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must  match the input. Model n_features is 220 and  input n_features is 2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-766901910ac4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# fit model on entire training set with optimal parameters and make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcpcall_X_train_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcpcall_Y_train_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mY_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predictions/random_forest_callcountperc.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anaconda2/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \"\"\"\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anaconda2/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    535\u001b[0m         \"\"\"\n\u001b[0;32m    536\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anaconda2/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    317\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anaconda2/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    374\u001b[0m                              \u001b[1;34m\" match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                              \u001b[1;34m\" input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must  match the input. Model n_features is 220 and  input n_features is 2 "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# update model class and/or parameters to search over here\n",
    "model = RandomForestClassifier()\n",
    "estimators = [10, 50, 100, 150, 200, 250] # default = 10\n",
    "features = [0.1, 0.25, 0.5, 0.75, 1.0, 'sqrt', 'log2'] # default = 'sqrt'\n",
    "depths = [None] # default = None (i.e. ignored)\n",
    "samples = [1, 5, 10, 25, 50, 100] # default = 1\n",
    "\n",
    "# cross-validation on training set to identify optimal parameters\n",
    "model = p2.cv_optimize(model, {'n_estimators': estimators, 'max_features': features,\n",
    "                            'max_depth': depths, 'min_samples_leaf': samples}, cpcall_X_train, cpcall_Y_train)\n",
    "\n",
    "# fit model on training set with optimal parameters\n",
    "# check out-of-sample performance using validation set\n",
    "model = p2.fit_model(model, cpcall_X_train, cpcall_Y_train, test_x=cpcall_X_valid, test_y=cpcall_Y_valid, \n",
    "                     title='Random Forest Features provided', tracker=tracker)\n",
    "\n",
    "# fit model on entire training set with optimal parameters and make predictions\n",
    "model = p2.fit_model(model, cpcall_X_train_all, cpcall_Y_train_all)\n",
    "Y_test_pred = model.predict(X_test)\n",
    "p2.write_predictions(Y_test_pred, test_ids, 'predictions/random_forest_callcountperc.csv')\n",
    "\n",
    "print '%0.1f seconds runtime' % (time.time() - start)\n",
    "\n",
    "# option to save fitted model\n",
    "# joblib.dump(model, 'models/f02_random_forest.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngrams Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "----------\n",
      "Training set accuracy = 0.9931\n",
      "Validation set accuracy = 0.9006\n",
      "----------\n",
      "############\n",
      "5803.4 seconds runtime\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "t = 250\n",
    "f = 0.5\n",
    "s = 1\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=t, max_features=f, min_samples_leaf=s)\n",
    "\n",
    "# cross-validation on training set to identify optimal parameters\n",
    "# model = p2.cv_optimize(model, {'n_estimators': estimators, 'max_features': features,\n",
    "#                                 'min_samples_leaf': samples}, ngrams_X_train_all, ngrams_Y_train_all)\n",
    "\n",
    "\n",
    "\n",
    "# fit model on training set with optimal parameters\n",
    "# check out-of-sample performance using validation set\n",
    "model = p2.fit_model(model, ngrams_X_train, ngrams_Y_train, test_x=ngrams_X_valid, test_y=ngrams_Y_valid, \n",
    "                     title='Random Forest ngram %r trees, %r features, %r samples' % (t, f, s), tracker=tracker)\n",
    "\n",
    "print '%0.1f seconds runtime' % (time.time() - start)\n",
    "\n",
    "# option to save fitted model\n",
    "# joblib.dump(model, 'models/f02_random_forest.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "----------\n",
      "Training set accuracy = 0.9922\n",
      "----------\n",
      "############\n"
     ]
    }
   ],
   "source": [
    "# fit model on entire training set with optimal parameters and make predictions\n",
    "# pick best model from tracker\n",
    "model = p2.fit_model(model, ngrams_X_train_all, ngrams_Y_train_all)\n",
    "Y_test_pred = model.predict(ngrams_X_test)\n",
    "# change to 250 filename\n",
    "p2.write_predictions(Y_test_pred, ngram_X_test_ids, 'predictions/randomforest_ngram_250_point5features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "----------\n",
      "Training set accuracy = 0.9931\n",
      "Validation set accuracy = 0.8952\n",
      "----------\n",
      "############\n",
      "6540.7 seconds runtime\n",
      "############\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "----------\n",
      "Training set accuracy = 0.9931\n",
      "Validation set accuracy = 0.8963\n",
      "----------\n",
      "############\n",
      "5658.4 seconds runtime\n"
     ]
    }
   ],
   "source": [
    "estimators = [300] # try 500\n",
    "features = [0.5, 0.4] # try 0.5, 0.4\n",
    "samples = [1]\n",
    "\n",
    "for t in estimators: \n",
    "    for f in features: \n",
    "        for s in samples: \n",
    "            start = time.time()\n",
    "            \n",
    "            model = RandomForestClassifier(n_estimators=t, max_features=f, min_samples_leaf=s)\n",
    "\n",
    "            # cross-validation on training set to identify optimal parameters\n",
    "            # model = p2.cv_optimize(model, {'n_estimators': estimators, 'max_features': features,\n",
    "            #                                 'min_samples_leaf': samples}, ngrams_X_train_all, ngrams_Y_train_all)\n",
    "\n",
    "            # fit model on training set with optimal parameters\n",
    "            # check out-of-sample performance using validation set\n",
    "            model = p2.fit_model(model, ngrams_X_train, ngrams_Y_train, test_x=ngrams_X_valid, test_y=ngrams_Y_valid, \n",
    "                                 title='Random Forest ngram %r trees, %r features, %r samples' % (t, f, s), tracker=tracker)\n",
    "\n",
    "            print '%0.1f seconds runtime' % (time.time() - start)\n",
    "\n",
    "# option to save fitted model\n",
    "# joblib.dump(model, 'models/f02_random_forest.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest Features provided': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89416846652267823],\n",
       " 'Random Forest ngram 150 trees': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89308855291576672],\n",
       " 'Random Forest ngram 200 trees, 0.5 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89308855291576672],\n",
       " 'Random Forest ngram 250 trees, 0.4 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89632829373650103],\n",
       " 'Random Forest ngram 250 trees, 0.4 features, 10 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
       "              min_samples_leaf=10, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.91388888888888886, 0.87365010799136067],\n",
       " 'Random Forest ngram 250 trees, 0.5 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.90064794816414684],\n",
       " 'Random Forest ngram 250 trees, 0.6 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89740820734341253],\n",
       " 'Random Forest ngram 250 trees, 0.8 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89848812095032393],\n",
       " 'Random Forest ngram 300 trees, 0.4 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89632829373650103],\n",
       " 'Random Forest ngram 300 trees, 0.5 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89524838012958963],\n",
       " 'Random Forest ngram 300 trees, 0.6 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89632829373650103],\n",
       " 'Random Forest ngram 300 trees, 0.8 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89740820734341253]}"
      ]
     },
     "execution_count": 95,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest ngram 250 trees, 0.4 features, 1 samples\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "models/Random Forest ngram 250 trees, 0.4 features, 1 samples.pkl\n",
      "Random Forest ngram 250 trees, 0.4 features, 10 samples\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=10, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "models/Random Forest ngram 250 trees, 0.4 features, 10 samples.pkl\n",
      "Random Forest ngram 250 trees, 0.8 features, 1 samples\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "models/Random Forest ngram 250 trees, 0.8 features, 1 samples.pkl\n",
      "Random Forest ngram 300 trees, 0.5 features, 1 samples\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "models/Random Forest ngram 300 trees, 0.5 features, 1 samples.pkl\n",
      "Random Forest ngram 300 trees, 0.8 features, 1 samples\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "models/Random Forest ngram 300 trees, 0.8 features, 1 samples.pkl\n",
      "Random Forest ngram 300 trees, 0.6 features, 1 samples\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "models/Random Forest ngram 300 trees, 0.6 features, 1 samples.pkl\n",
      "Random Forest ngram 300 trees, 0.4 features, 1 samples\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "models/Random Forest ngram 300 trees, 0.4 features, 1 samples.pkl\n",
      "Random Forest ngram 250 trees, 0.5 features, 1 samples\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "models/Random Forest ngram 250 trees, 0.5 features, 1 samples.pkl\n",
      "Random Forest ngram 250 trees, 0.6 features, 1 samples\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "models/Random Forest ngram 250 trees, 0.6 features, 1 samples.pkl\n",
      "Random Forest ngram 150 trees\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "models/Random Forest ngram 150 trees.pkl\n",
      "Random Forest ngram 200 trees, 0.5 features, 1 samples\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "models/Random Forest ngram 200 trees, 0.5 features, 1 samples.pkl\n",
      "Random Forest Features provided\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "models/Random Forest Features provided.pkl\n"
     ]
    }
   ],
   "source": [
    "for model, items in tracker.iteritems():\n",
    "    print model\n",
    "    print items[0]\n",
    "    print 'models/%s.pkl' % model\n",
    "    joblib.dump(model, 'models/%s.pkl' % model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'Random Forest Features provided': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.99305555555555558, 0.89416846652267823],\n",
    " 'Random Forest ngram 150 trees': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.99305555555555558, 0.89308855291576672],\n",
    " 'Random Forest ngram 200 trees, 0.5 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.99305555555555558, 0.89308855291576672],\n",
    " 'Random Forest ngram 250 trees, 0.4 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.99305555555555558, 0.89632829373650103],\n",
    " 'Random Forest ngram 250 trees, 0.4 features, 10 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
    "              min_samples_leaf=10, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.91388888888888886, 0.87365010799136067],\n",
    " 'Random Forest ngram 250 trees, 0.5 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.99305555555555558, 0.90064794816414684],\n",
    " 'Random Forest ngram 250 trees, 0.6 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.99305555555555558, 0.89740820734341253],\n",
    " 'Random Forest ngram 250 trees, 0.8 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.99305555555555558, 0.89848812095032393],\n",
    " 'Random Forest ngram 300 trees, 0.6 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.99305555555555558, 0.89632829373650103],\n",
    " 'Random Forest ngram 300 trees, 0.8 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.99305555555555558, 0.89740820734341253]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 97,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "model = tracker['Random Forest ngram 300 trees, 0.8 features, 1 samples'][0]\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "----------\n",
      "Training set accuracy = 0.9922\n",
      "----------\n",
      "############\n"
     ]
    }
   ],
   "source": [
    "# TODO HERE NOW\n",
    "# fit model on entire training set with optimal parameters and make predictions\n",
    "model = p2.fit_model(model, ngrams_X_train_all, ngrams_Y_train_all)\n",
    "Y_test_pred = model.predict(ngrams_X_test)\n",
    "p2.write_predictions(Y_test_pred, ngram_X_test_ids, 'predictions/randomforest_ngram_300_point8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "#  Kaggle 0.82947 \n",
    "{'Random Forest Features provided': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.99305555555555558, 0.89416846652267823]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'Random Forest Features provided': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.99305555555555558, 0.89416846652267823],\n",
    " 'Random Forest ngram 150 trees': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "              max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\n",
    "              oob_score=False, random_state=None, verbose=0,\n",
    "              warm_start=False), 0.99305555555555558, 0.89632829373650103]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "----------\n",
    "Training set accuracy = 0.9931\n",
    "Validation set accuracy = 0.8931\n",
    "----------\n",
    "############\n",
    "############\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "----------\n",
    "Training set accuracy = 0.9922\n",
    "----------\n",
    "############\n",
    "8310.6 seconds runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle 0.83737 - #1 team\n",
    "############\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "----------\n",
    "Training set accuracy = 0.9931\n",
    "Validation set accuracy = 0.8996\n",
    "----------\n",
    "############\n",
    "4535.7 seconds runtime\n",
    "\n",
    "\n",
    "############\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "----------\n",
    "Training set accuracy = 0.9922\n",
    "----------\n",
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle 0.83579\n",
    "\n",
    "############\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "----------\n",
    "Training set accuracy = 0.9931\n",
    "Validation set accuracy = 0.9006\n",
    "----------\n",
    "############\n",
    "5803.4 seconds runtime\n",
    "\n",
    "############\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "----------\n",
    "Training set accuracy = 0.9922\n",
    "----------\n",
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "----------\n",
    "Training set accuracy = 0.9931\n",
    "Validation set accuracy = 0.8963\n",
    "----------\n",
    "############\n",
    "############\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
    "            min_samples_leaf=10, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "----------\n",
    "Training set accuracy = 0.9139\n",
    "Validation set accuracy = 0.8737\n",
    "----------\n",
    "############\n",
    "############\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "----------\n",
    "Training set accuracy = 0.9931\n",
    "Validation set accuracy = 0.8974\n",
    "----------\n",
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "----------\n",
    "Training set accuracy = 0.9931\n",
    "Validation set accuracy = 0.8974\n",
    "----------\n",
    "############\n",
    "9664.1 seconds runtime\n",
    "############\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "----------\n",
    "Training set accuracy = 0.9931\n",
    "Validation set accuracy = 0.8974\n",
    "----------\n",
    "############\n",
    "6422.0 seconds runtime\n",
    "############\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "----------\n",
    "Training set accuracy = 0.9931\n",
    "Validation set accuracy = 0.8985\n",
    "----------\n",
    "############\n",
    "7882.2 seconds runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_X_test_ids = pd.read_csv('/home/shared/practical2/data/features/ngram_X_testids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0015c8c9ff02fea9d0f45692b9eebfb4abff4e42f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>001f298a534ae4b0db7f2707169250aa215c3b5f2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>001f5fdaaa8bbe20303527198d09a30bb7ca3eb50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>002ca2c41b649f85c05ae30013436781a932fecc6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>003e109543b4ea22d2bcc1ec309bf2fd34e9a1a1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>004070b468d6bb29848c76cfCd5887849c7bb648d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>00461dd05c981edde167a5947c365472141e04bb1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>005b95d2520C8621171566f5803437b0c443778e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0071a3b818ed06d3865a24fdb31d4147c67fabfc5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>007436715ec13cedd38344772a2144a3d79f3ea68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>00810ef95f86daee349107255601afc51e9a7eba2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>00888535488746a0c494c41fbe93940f72aad0f30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>008cc72e6d82f36c8d4a95ab35e241b5e58411845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>00a2b881ddba2fbece1d2853bc8484072c0ad795b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>00ab51519cdf57cf9a53aa4e0caeada0753a36bd4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>00c0646c7dfd525f704f0f81dfa9f900e3357abf6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>00e379c843a3f67fb8d4A7832c0701d797f11f9f3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>00e586a3c25d97bc1b112cbad672a91ba238f4296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>00fb3b50ccfadd5b427aba20792bb95a4260db685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>010d1e20d98e8b87b4208a6b5c80f0C1c088037d8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0113a8aead089b16a65f837b3524f58e84c34e303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>01178cc12a1c4340c520ce669728Ad3538ab2f0f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>013652ef9219818cbfb498aaddb30c9774cdce199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>01392e526a68f01285549de36e16333e95e51ce60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>01457a2418244506c274051df725c475d1f7d92d7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0173a0d4005e410835b0fD49e3f02268265c3f8bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0175d1a73db8e4c2fd406628978721b2664d2deb8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>01d9d46e124041ac3e98E4fd9fea0ee0e838e3c15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>01ea0141110652ac0ecee45b753877bCe66a887cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>02049c8003b0c4ef4f7524c0cb8add4a2fe78bc8f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>022cc4a532bd85062d52516667c519b59cb8f419a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>023c00261dcaf806767f98513c4de1e29b7123644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>024b027b692a671388730bc598a28a51366d103ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>029b8627794ac19ce8df18110617586787ed9f84b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>029fd200642365a45173b6c43ea98c9c22141a46f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>02b8c7d0301b252ee6cebe72e68931cfd16df3d32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>02c6e4f6bada7f56394030e100085cc7f36cc4741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>02d57eefe3d00c56ed78becdda9d92a784fe243dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0312f8d09c1a7d3c7adadf9c377ab1dcf174bc5f5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0314043eed05f84414345157c8d5c3bb152802159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>031924e957675a27504121655055fccc1ea7b048c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>031f039eef2630048003A82f28ca3468e13f66e65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0323c5f1f60dc0c73a851992129a85cb59689e371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>032ef1E987f77687a3942322478e4c880f5b4067d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0337fa68498c85f02cace3808fa6d75b08371ddd3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>033a86c17053dad4dc8ecfd26b08fd0024bb44d7a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0349565eb0a4f21d6d0bf570ff754b71ac17db0cb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>03586cccaabf97a6bcb1f154dead6b70d07fFf1c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>03835934aafbaf58f11f9b747a7e7f895da219205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>038b047c1eb914f55428964122a83d40d2fc2823a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>038b1388ae68acd91a1394c8f5753878dcc54ed85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>03960f0bdedf6f822acf81a1fb7dad0f9d1E8ae5f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>03a2b9a9e7a91703da192801a301f66066af5b4ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>03de3ccbf59e224ca963b5f79ac7b1d0f6db2b314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>03e2b31b781b23ee746c63d473b8fc9df8581afd8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>044db66b4af90ee2f9ee594b0456ca97eacf8dc8c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>04664bebcb495b843f19178a60473a4b75db7585a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0499b6b7f9e77b3ae5ecc7ffe6a008a0c6da9f805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>049db6b45a8f8ac592dc357c46b0da6d34bf0769b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>04ab846fb169a0dbe53235b1d3e4d9a7a24132af9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>04abffa7752f91229bfa9bf9734a1dd0e892f32a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>04af29f80412f7c5c4c5d76f4042f8658da28cd4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>04afc344f00d43ec09b233a63f314d24f451114ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>04c53944ee1cD1bd7c4fb71b3d2b80aecf3e86579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>04e030d7bcff52a454b41f0e779a159Be6b23042e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>04f72225e18d019025c8240d8eade56d7620a3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>04febddbf8265a89506799631d6d42dbd8d6cfb75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>050775e0f0e120d94a5222f088bb1112e6f31542a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>0524d8bcf83c1641f7eb1c04443357f843088e9c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>052875f1ced29312d9ecfb44567731f420960c2a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>0531c44810f728fc4ea67308dC394bad95e7920e5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>053646f228b14bc830289ca6e7c2a2fd63b1e87f7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>053f9d3c7691eaaa32d76d053fc96B09ef4baad75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>05802f6a6e0c1f0e82faf9ba70e253b2c616985b3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>0587e8da9655f49f1935a222b7ca7ee681c2cf625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>05b79b606e858b2a56de8ee17fbaa00bd95ac6373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>05c5dfc70e0e60abbE6162d7087ab7e163630e08f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>05e00e37accf7659b95fa4b76879db927c12632cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>05e647496bed0efc0edc4d92a8ec6f6ed810a82dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>05e83d6acf321fb8041461a2c32f437785f661263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>066f5652b178cc8d647861Bb0f5e7593cba4b8037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>067b53bc9be6c26f04ae34b7779437c723df51089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>067c7ba7ef6781b9988428363737aa0afeb87A546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>069950321f2c1e95f8691453f60b032b79331bace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>06a0c29dd21f4bca07a86b188f7267d0978f88C7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>06c478322c242e4709ae507159b14876fbb6a7d1e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>06c55665ffba8549082ae12fe7d21a6f5ff7B9207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>06c73ed61aa8e89f0f9764dafcd10661c3011f25f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>06dcb6d94458cf29e0334336a1deed482dc1faeb8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>070262Db06f1c2459153a2d509fb411cfe20f9ba1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>071197d40735842d5fc9805a9cc9a20f27be0ea5e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>07334a91222a32708130ce07da51ddf78c9ced9f3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>073abb93dcd12b20f5f394ecedf6909b6fb274e03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>0743a2c1b1e3f37632c63e82f92bb05ad4e26c7Ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>07545d9aDdf29ab04638c5d15c34c4e075ff3f9e5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0768bd3ad5a017ed38bda79d185aac208c9d5fc0d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>076a9df0eb709330ff11f6a0c5bccff715aef24d1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>07973d3636f8208fe8e5e8de44f8dcd4c3651a1b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>07a6317ada8E1e975a3e46e71b8c99678134b4b95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>07b0055f1d28a79032f1bad1E4d7303e2e6266456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>3624</td>\n",
       "      <td>f83e7ac55aa699efa35f807A98291b4a274fd099b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625</th>\n",
       "      <td>3625</td>\n",
       "      <td>f84fdbd57a5775524c80fcb5c69db2e860a4db5d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626</th>\n",
       "      <td>3626</td>\n",
       "      <td>f866c59381d5fa3326d52dc15e2847dc8bdafb39e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3627</th>\n",
       "      <td>3627</td>\n",
       "      <td>f86c5a5880175d80cc02ae7dfA4a55808897ce46b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>3628</td>\n",
       "      <td>f86Ed911725afe152743a5385ad627683de8a33ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3629</th>\n",
       "      <td>3629</td>\n",
       "      <td>f87eb1e4a7f24180d4970aa05ca5a9d16319692ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>3630</td>\n",
       "      <td>f87eec0323E143f4b434824ea5ee70b86cd12aa93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>3631</td>\n",
       "      <td>f87faeddcb770589eb0da83e6eb415b5dbadd5180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>3632</td>\n",
       "      <td>f881C84a0e2691dfa6839aadd32500b4e44f7df24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>3633</td>\n",
       "      <td>f8b8e3b94f007c8185c5b4a0bd17cb218840f95af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>3634</td>\n",
       "      <td>f8d792b1ed441a5e15dd5a523dbad766d0d61343e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>3635</td>\n",
       "      <td>f8eb1b7104ef03fa3c2aca1a633912348e4ba7324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3636</th>\n",
       "      <td>3636</td>\n",
       "      <td>f8ec3183a33338aedd6ece78ea26337c7f6b392a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>3637</td>\n",
       "      <td>f8ed30a9978bcb3d5ddb24a7cf2bdd94b94a68ecd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638</th>\n",
       "      <td>3638</td>\n",
       "      <td>f930630406e352aab24a48a4951fbd38025f3e838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>3639</td>\n",
       "      <td>f93e6f0034f09b1308294c83e7b0b47e58d37500e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>3640</td>\n",
       "      <td>f95afc0cf9e7d2ba86ec249b0ba5314942da8ad8c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3641</th>\n",
       "      <td>3641</td>\n",
       "      <td>f969a765879d6ce6a55582d4812300641400eda6e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3642</th>\n",
       "      <td>3642</td>\n",
       "      <td>f97471a9244b11f59cfcd3405a672ae6Efbab008e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>3643</td>\n",
       "      <td>f9ec29ac7a5b7ccb2a1754b5671b52c85ac0cefbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3644</th>\n",
       "      <td>3644</td>\n",
       "      <td>Fa12cdca53067b731c7df22e992176d078132656d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>3645</td>\n",
       "      <td>fa276251a64c2a87b54e85b1d7abead335a4affef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>3646</td>\n",
       "      <td>fa3b4b6757f323eca96675803530a0871bbc51b68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>3647</td>\n",
       "      <td>fa3b78cca3835113c1dca8c6ad014Bcce83f5b742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>3648</td>\n",
       "      <td>fa45413d84dea9fdb6a351587238286c76fe7f65e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>3649</td>\n",
       "      <td>fa5721627ed430f197971aaa6580840530425f567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>3650</td>\n",
       "      <td>fa81ad229d05a9bcc026E5140f5526f90d8ab30f8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>3651</td>\n",
       "      <td>fa85d6b60e619890ad5f0e1806b614d0762431d3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>3652</td>\n",
       "      <td>fabaf5d9bae26001c3b78cbc5d5ec33ede599513e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>3653</td>\n",
       "      <td>faC49e5c95cfeb1a440d1288e7e80db44106ebf7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3654</th>\n",
       "      <td>3654</td>\n",
       "      <td>Fad0232625dd31dd0b345c349dbe7953c113f7339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>3655</td>\n",
       "      <td>fad2f6bd60f1193cd05a5eca61e19acfc5ecdea69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>3656</td>\n",
       "      <td>fae17083dbf7955fa08891aa0a34cff972a8866ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>3657</td>\n",
       "      <td>fae27622493787baa43d9c68ffe87839F89a26a13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>3658</td>\n",
       "      <td>fb0537030062e8059e57b3df54c816fa860e365e8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>3659</td>\n",
       "      <td>fb05627B6c81d4444cf9b2bf942f63e58fbde4dc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>3660</td>\n",
       "      <td>fb1277f924df6a1cC9b6086773d588a763563d406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>3661</td>\n",
       "      <td>fb15be243460f8774ff4611df78ea01ab9ffeca01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>3662</td>\n",
       "      <td>fb17bc7ee057f90d1034f49c21e4e227578a63c50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663</th>\n",
       "      <td>3663</td>\n",
       "      <td>fb2d91287851dCd9f107c40b05b0497c2aa2d4832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3664</th>\n",
       "      <td>3664</td>\n",
       "      <td>fb35c1ebc431168836b2a0ca2684b025d28c3afc8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3665</th>\n",
       "      <td>3665</td>\n",
       "      <td>fb3d10af73ed03f001691d204608d30464b506a71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3666</th>\n",
       "      <td>3666</td>\n",
       "      <td>fb436f68cf31c13771cc0bca64466e78a9be6a325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>3667</td>\n",
       "      <td>fb4c2e3bc44e8a46937a4cdccb7654717da85c979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668</th>\n",
       "      <td>3668</td>\n",
       "      <td>fb5a1ba96d6990Ea715fe269eedc5f85407015803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3669</th>\n",
       "      <td>3669</td>\n",
       "      <td>fb71aba18c6e35b01d33dd1e9a04adc1c8de38440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>3670</td>\n",
       "      <td>fb8dc0d98d40f9472b833ef4b98e1715b3e87a005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>3671</td>\n",
       "      <td>fba7e375ee56f21c49eda2e2145f6dd5d0b665800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>3672</td>\n",
       "      <td>fbAdb1c0440bffe803a5c13961f3a6b9c3e283b88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3673</th>\n",
       "      <td>3673</td>\n",
       "      <td>fbb07a86c4cEd2be4e0924e4052a3d3c0293ab4f9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3674</th>\n",
       "      <td>3674</td>\n",
       "      <td>fbc51aedefd6e4d9398d527667d30b9f8138e115e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675</th>\n",
       "      <td>3675</td>\n",
       "      <td>fbc9de7200643ea6aa369294d5d9749a5b9f98a8e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>3676</td>\n",
       "      <td>fbd350c9cea045524816243d3ebda9b80a4ca6093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3677</th>\n",
       "      <td>3677</td>\n",
       "      <td>fbd7021ed3c06ae048cfc7a1d83657436ae878582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>3678</td>\n",
       "      <td>fbd87082f94217c0f9e66836541245d338b71c3f6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>3679</td>\n",
       "      <td>fbd94cc78d51e5fff1f07a05bc0c5eA6722ce6282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>3680</td>\n",
       "      <td>fbe19662f73327028a7edc60e3c13f8cfdbb1823b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3681</th>\n",
       "      <td>3681</td>\n",
       "      <td>fbfbc7aea31e9878d6c28fd717fe2513c52883dae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682</th>\n",
       "      <td>3682</td>\n",
       "      <td>fbfc1489295e3792523ee90e0fe61f789cc65003c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>3683</td>\n",
       "      <td>fc014c2567bdfecac0d746f6ef93370979f03edac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>3684</td>\n",
       "      <td>fc3f5b550191d66Df49d84bd7fa0ce28ec35cb96b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>3685</td>\n",
       "      <td>fc79f646bebcc50aec2236b60b189e60b6060ce61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>3686</td>\n",
       "      <td>fc8b447104431b50c295F3157e911a34ac9883fa3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>3687</td>\n",
       "      <td>fca1588e56534959e72b851391c91e09671b58696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>3688</td>\n",
       "      <td>Fcba9a02970dbd3bbd10f24ee0d91e490a28d1f2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>3689</td>\n",
       "      <td>fcd073a8c4fb85ac32ae8dfbe19b41644de9fe288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>3690</td>\n",
       "      <td>fcD544f6c792106510c4eb8a8dfed8b2c41fc0d96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3691</th>\n",
       "      <td>3691</td>\n",
       "      <td>fcddab356b94adf655eB0eec2f168c5553dc6e2b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>3692</td>\n",
       "      <td>fce4159a190da0c92f418c1c2a681886d6fd140d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3693</th>\n",
       "      <td>3693</td>\n",
       "      <td>fd60f567e8f2626a92e18ed43b6a79c16f4b5fbe2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>3694</td>\n",
       "      <td>fd76e9af95e779a5f23e2791474f3edBf04e87a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>3695</td>\n",
       "      <td>fd875a4fb7aaba3e643a2db3692d018871e04fd76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>3696</td>\n",
       "      <td>fd9a2393f610e53a43043bd019cc696f5c07e4944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>3697</td>\n",
       "      <td>fdbbeffe82dbef183af9ffb404e89500d6bc0b6c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3698</th>\n",
       "      <td>3698</td>\n",
       "      <td>fdbfd653c850dfd6c4aea152f6500c52d5950e43d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>3699</td>\n",
       "      <td>fdd14bdbd3f1aac3116c2c1169a86cbc61b1Ae9c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>3700</td>\n",
       "      <td>fdd658beec58b195a2c2edc5d92ddfca77285b559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>3701</td>\n",
       "      <td>fde0cfe1e6656cd418c3f8a4e0ad47c4c17e25f34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>3702</td>\n",
       "      <td>fdf35b62e7bd49fdf50bb2143bbaaf7121520ed65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>3703</td>\n",
       "      <td>fe09e746b753fcee22e2c7d2be2883685761d4145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>3704</td>\n",
       "      <td>fe255d4daf56461e5D7a5749a054eedc50b087509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>3705</td>\n",
       "      <td>fe4e28d7b30d26a2fde0fc4c815e7eb0a52367fdd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>3706</td>\n",
       "      <td>fe53725f47540d4f31d61bdd0a5aa5bb5cca28a50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>3707</td>\n",
       "      <td>fe7887a3ff58c609fe633b6118e0c033a92ffd555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>3708</td>\n",
       "      <td>feae6E291a49da14d05a6ffb9fbee2815d7c8153d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>3709</td>\n",
       "      <td>fec6d2Eb64b083c0b8f4b4f0bd04671e78607be09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>3710</td>\n",
       "      <td>fec8e57b083bd354dd6b02d129baae82f7591eae6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>3711</td>\n",
       "      <td>fed5e724a012c38ec624fba4fd3650da59a5595c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>3712</td>\n",
       "      <td>feea3c1b728377170a6ad93689f0d9b2c07b0fe12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>3713</td>\n",
       "      <td>ff15577c4d58442b758e85670263ada014fc91dd7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>3714</td>\n",
       "      <td>ff272446010174efce45afa0e3ec77acba122b6df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>3715</td>\n",
       "      <td>ff31496ea9aa36804397160dcc442890ec3a7df95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>3716</td>\n",
       "      <td>ff393ca012e3bb6b89846114181ece70fde991c58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>3717</td>\n",
       "      <td>ff3f10990b37a97c4990cfa36c14A6feb79c5ed32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3718</th>\n",
       "      <td>3718</td>\n",
       "      <td>ff42c4ecb06a8838228a03cb930e87e3bdf5c08e2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3719</th>\n",
       "      <td>3719</td>\n",
       "      <td>ff5abc2369a9Bea144b697fa2c147f37f8bbcc410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>3720</td>\n",
       "      <td>ff7cc6e8d270894363730c008d579197bebcbd07d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>3721</td>\n",
       "      <td>ff85866b215233b2fecdca2c2b8fda54ad24c86fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>3722</td>\n",
       "      <td>ff884224571e0476990574df5da76e0991db583af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>3723</td>\n",
       "      <td>ffc47163a530c51ef2e6572d786aefbaed99890f2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3724 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "ngram_X_test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_X_test_ids = ngram_X_test_ids.drop('Unnamed: 0', axis=1)['0']\n",
    "\n",
    "# turn into numpy matrix\n",
    "ngram_X_test_ids = ngram_X_test_ids.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0015c8c9ff02fea9d0f45692b9eebfb4abff4e42f',\n",
       "       '001f298a534ae4b0db7f2707169250aa215c3b5f2',\n",
       "       '001f5fdaaa8bbe20303527198d09a30bb7ca3eb50', ...,\n",
       "       'ff85866b215233b2fecdca2c2b8fda54ad24c86fd',\n",
       "       'ff884224571e0476990574df5da76e0991db583af',\n",
       "       'ffc47163a530c51ef2e6572d786aefbaed99890f2'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "ngram_X_test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3724"
      ]
     },
     "execution_count": 26,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "len(ngram_X_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3724"
      ]
     },
     "execution_count": 27,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "len(ngrams_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Ngrams & Call Counts & Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# update model class and/or parameters to search over here\n",
    "model = RandomForestClassifier()\n",
    "estimators = [10, 50, 100, 150, 200, 250] # default = 10\n",
    "features = [0.1, 0.25, 0.5, 0.75, 1.0, 'sqrt', 'log2'] # default = 'sqrt'\n",
    "depths = [None] # default = None (i.e. ignored)\n",
    "samples = [1, 5, 10, 25, 50, 100] # default = 1\n",
    "\n",
    "# cross-validation on training set to identify optimal parameters\n",
    "model = p2.cv_optimize(model, {'n_estimators': estimators, 'max_features': features,\n",
    "                            'max_depth': depths, 'min_samples_leaf': samples}, ngcp_X_train, ngcp_Y_train)\n",
    "\n",
    "# fit model on training set with optimal parameters\n",
    "# check out-of-sample performance using validation set\n",
    "model = p2.fit_model(model, ngcp_X_train, ngcp_Y_train, test_x=ngcp_X_valid, test_y=ngcp_X_train, ngcp_X_valid, \n",
    "                     ngcp_Y_train, ngcp_Y_valid, title='Random Forest Features provided',\n",
    "                     tracker=tracker)\n",
    "\n",
    "# fit model on entire training set with optimal parameters and make predictions\n",
    "model = p2.fit_model(model, ngcp_X_train_all, ngcp_Y_train_all)\n",
    "Y_test_pred = model.predict(ngcp_X_test)\n",
    "p2.write_predictions(Y_test_pred, test_ids, 'predictions/combo_countcalls_ngrams_random_forest.csv')\n",
    "\n",
    "print '%0.1f seconds runtime' % (time.time() - start)\n",
    "\n",
    "# option to save fitted model\n",
    "# joblib.dump(model, 'models/f02_random_forest.pkl');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multi-class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Features Provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# model = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "model = LinearSVC(random_state=0)\n",
    "\n",
    "Cs=[0.01, 0.1, 1.0, 10.0, 100.0] # default = 1\n",
    "# Cs=[0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0] # default = 1\n",
    "# Cs=[50, 60, 70, 80, 90, 100, 110, 120, 130, 140]\n",
    "loss = ['squared_hinge', 'hinge'] # default=’squared_hinge’; 'hinge' is another option but cannot be combined with l1 penalty\n",
    "penalty = ['l1', 'l2'] # default=’l2’\n",
    "\"\"\"\n",
    "multi_class (default=’ovr’)\n",
    "Determines the multi-class strategy if y contains more than two classes. \"ovr\" trains n_classes one-vs-rest \n",
    "classifiers, while \"crammer_singer\" optimizes a joint objective over all classes. While crammer_singer \n",
    "is interesting from a theoretical perspective as it is consistent, it is seldom used in practice as it rarely \n",
    "leads to better accuracy and is more expensive to compute. If \"crammer_singer\" is chosen, the options loss, penalty \n",
    "and dual will be ignored.\n",
    "\"\"\"\n",
    "\n",
    "# cross-validation on training set to identify optimal parameters\n",
    "model = p2.cv_optimize(model, {'C': Cs, 'loss': loss}, X_train, Y_train)\n",
    "# 'penalty': penalty, 'loss': loss\n",
    "\n",
    "\n",
    "# fit model on training set with optimal parameters\n",
    "# check out-of-sample performance using validation set\n",
    "model = p2.fit_model(model, X_train, Y_train, test_x=X_valid, test_y=Y_valid, title='LinearSVC Features provided',\n",
    "                     tracker=tracker)\n",
    "\n",
    "# fit model on entire training set with optimal parameters and make predictions\n",
    "# model = p2.fit_model(model, X_train_all, Y_train_all)\n",
    "# Y_test_pred = model.predict(X_test)\n",
    "# p2.write_predictions(Y_test_pred, test_ids, 'predictions/svc_2_feat only.csv')\n",
    "\n",
    "print '%0.1f seconds runtime' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Counts & Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST {'loss': 'squared_hinge', 'C': 0.01} 0.815740740741 [mean: 0.81574, std: 0.02896, params: {'loss': 'squared_hinge', 'C': 0.01}, mean: 0.80139, std: 0.04905, params: {'loss': 'hinge', 'C': 0.01}, mean: 0.78519, std: 0.03555, params: {'loss': 'squared_hinge', 'C': 0.1}, mean: 0.77130, std: 0.02303, params: {'loss': 'hinge', 'C': 0.1}, mean: 0.57083, std: 0.17874, params: {'loss': 'squared_hinge', 'C': 1.0}, mean: 0.73935, std: 0.04636, params: {'loss': 'hinge', 'C': 1.0}, mean: 0.61481, std: 0.07967, params: {'loss': 'squared_hinge', 'C': 10.0}, mean: 0.63935, std: 0.12817, params: {'loss': 'hinge', 'C': 10.0}, mean: 0.68889, std: 0.03149, params: {'loss': 'squared_hinge', 'C': 100.0}, mean: 0.63889, std: 0.08277, params: {'loss': 'hinge', 'C': 100.0}]\n",
      "############\n",
      "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0)\n",
      "----------\n",
      "Training set accuracy = 0.8583\n",
      "Validation set accuracy = 0.8326\n",
      "----------\n",
      "############\n",
      "############\n",
      "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0)\n",
      "----------\n",
      "Training set accuracy = 0.8639\n",
      "----------\n",
      "############\n",
      "124.4 seconds runtime\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# model = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "model = LinearSVC(random_state=0)\n",
    "\n",
    "# TODO try smaller? 0.001\n",
    "Cs=[0.01, 0.1, 1.0, 10.0, 100.0] # default = 1\n",
    "# Cs=[0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0] # default = 1\n",
    "# Cs=[50, 60, 70, 80, 90, 100, 110, 120, 130, 140]\n",
    "loss = ['squared_hinge', 'hinge'] # default=’squared_hinge’; 'hinge' is another option but cannot be combined with l1 penalty\n",
    "penalty = ['l1', 'l2'] # default=’l2’\n",
    "\"\"\"\n",
    "multi_class (default=’ovr’)\n",
    "Determines the multi-class strategy if y contains more than two classes. \"ovr\" trains n_classes one-vs-rest \n",
    "classifiers, while \"crammer_singer\" optimizes a joint objective over all classes. While crammer_singer \n",
    "is interesting from a theoretical perspective as it is consistent, it is seldom used in practice as it rarely \n",
    "leads to better accuracy and is more expensive to compute. If \"crammer_singer\" is chosen, the options loss, penalty \n",
    "and dual will be ignored.\n",
    "\"\"\"\n",
    "\n",
    "# cross-validation on training set to identify optimal parameters\n",
    "model = p2.cv_optimize(model, {'C': Cs, 'loss': loss}, cpcall_X_train, cpcall_Y_train)\n",
    "# 'penalty': penalty, 'loss': loss\n",
    "\n",
    "\n",
    "# fit model on training set with optimal parameters\n",
    "# check out-of-sample performance using validation set\n",
    "model = p2.fit_model(model, cpcall_X_train, cpcall_Y_train, test_x=cpcall_X_valid, test_y=cpcall_Y_valid, \n",
    "                     title='LinearSVC count calls', tracker=tracker)\n",
    "\n",
    "# fit model on entire training set with optimal parameters and make predictions\n",
    "model = p2.fit_model(model, cpcall_X_train_all, cpcall_Y_train_all)\n",
    "Y_test_pred = model.predict(cpcall_X_test)\n",
    "# Kaggle 0.74211\n",
    "p2.write_predictions(Y_test_pred, test_ids, 'predictions/svm_count_call_perc.csv')\n",
    "\n",
    "print '%0.1f seconds runtime' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR Features provided': [LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False),\n",
       "  0.65833333333333333,\n",
       "  0.66090712742980562],\n",
       " 'LinearSVC count calls': [LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
       "       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "       multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "       verbose=0), 0.85833333333333328, 0.83261339092872566],\n",
       " 'Random Forest Features provided': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=1.0, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.79861111111111116, 0.75269978401727866]}"
      ]
     },
     "execution_count": 52,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST {'loss': 'squared_hinge', 'C': 0.01} 0.865277777778 [mean: 0.86528, std: 0.00516, params: {'loss': 'squared_hinge', 'C': 0.01}, mean: 0.85463, std: 0.00766, params: {'loss': 'hinge', 'C': 0.01}, mean: 0.85509, std: 0.00911, params: {'loss': 'squared_hinge', 'C': 0.1}, mean: 0.85926, std: 0.00990, params: {'loss': 'hinge', 'C': 0.1}, mean: 0.82222, std: 0.01868, params: {'loss': 'squared_hinge', 'C': 1.0}, mean: 0.83519, std: 0.02089, params: {'loss': 'hinge', 'C': 1.0}, mean: 0.79028, std: 0.04912, params: {'loss': 'squared_hinge', 'C': 10.0}, mean: 0.75741, std: 0.08724, params: {'loss': 'hinge', 'C': 10.0}, mean: 0.77731, std: 0.02119, params: {'loss': 'squared_hinge', 'C': 100.0}, mean: 0.75741, std: 0.08724, params: {'loss': 'hinge', 'C': 100.0}]\n",
      "############\n",
      "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0)\n",
      "----------\n",
      "Training set accuracy = 0.9542\n",
      "Validation set accuracy = 0.8726\n",
      "----------\n",
      "############\n",
      "2071.2 seconds runtime\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# model = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "model = LinearSVC(random_state=0)\n",
    "\n",
    "Cs=[0.01, 0.1, 1.0, 10.0, 100.0] # default = 1\n",
    "# Cs=[0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0] # default = 1\n",
    "# Cs=[50, 60, 70, 80, 90, 100, 110, 120, 130, 140]\n",
    "loss = ['squared_hinge', 'hinge'] # default=’squared_hinge’; 'hinge' is another option but cannot be combined with l1 penalty\n",
    "# penalty = ['l1', 'l2'] # default=’l2’\n",
    "\"\"\"\n",
    "multi_class (default=’ovr’)\n",
    "Determines the multi-class strategy if y contains more than two classes. \"ovr\" trains n_classes one-vs-rest \n",
    "classifiers, while \"crammer_singer\" optimizes a joint objective over all classes. While crammer_singer \n",
    "is interesting from a theoretical perspective as it is consistent, it is seldom used in practice as it rarely \n",
    "leads to better accuracy and is more expensive to compute. If \"crammer_singer\" is chosen, the options loss, penalty \n",
    "and dual will be ignored.\n",
    "\"\"\"\n",
    "# cross-validation on training set to identify optimal parameters\n",
    "model = p2.cv_optimize(model, {'C': Cs, 'loss': loss}, ngrams_X_train, ngrams_Y_train)\n",
    "# 'penalty': penalty, 'loss': loss\n",
    "\n",
    "\n",
    "# fit model on training set with optimal parameters\n",
    "# check out-of-sample performance using validation set\n",
    "model = p2.fit_model(model, ngrams_X_train, ngrams_Y_train, test_x=ngrams_X_valid, test_y=ngrams_Y_valid, \n",
    "                     title='LinearSVC ngrams', tracker=tracker)\n",
    "\n",
    "# # fit model on entire training set with optimal parameters and make predictions\n",
    "# model = p2.fit_model(model, ngrams_X_train_all, ngrams_Y_train_all)\n",
    "# Y_test_pred = model.predict(ngrams_X_test)\n",
    "# p2.write_predictions(Y_test_pred, test_ids, 'predictions/svc_ngram.csv')\n",
    "\n",
    "print '%0.1f seconds runtime' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR Features provided': [LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False),\n",
       "  0.65833333333333333,\n",
       "  0.66090712742980562],\n",
       " 'LinearSVC count calls': [LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
       "       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "       multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "       verbose=0), 0.85833333333333328, 0.83261339092872566],\n",
       " 'LinearSVC ngrams': [LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
       "       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "       multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "       verbose=0), 0.95416666666666672, 0.87257019438444927],\n",
       " 'Random Forest Features provided': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=1.0, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.79861111111111116, 0.75269978401727866]}"
      ]
     },
     "execution_count": 56,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0)\n",
      "----------\n",
      "Training set accuracy = 0.9601\n",
      "----------\n",
      "############\n"
     ]
    }
   ],
   "source": [
    "# fit model on entire training set with optimal parameters and make predictions\n",
    "model = p2.fit_model(model, ngrams_X_train_all, ngrams_Y_train_all)\n",
    "\n",
    "Y_test_pred = model.predict(ngrams_X_test)\n",
    "\n",
    "p2.write_predictions(Y_test_pred, test_ids, 'predictions/svc_ngram.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2701ec71e466d1f6bc966d516aa9b574c0773a361',\n",
       " 'e9729c0163329b25671504a250e1b8ba8adc38b0e',\n",
       " 'faC49e5c95cfeb1a440d1288e7e80db44106ebf7c',\n",
       " 'a9b307db4e8a41c47104598d5d632fEacfb3134bf',\n",
       " 'bfd2c650d81dd2bb598c193b6df68cbb30894b2c7',\n",
       " '28b7c7b16f89904b2526478a1b18a20a460b74Ef7',\n",
       " '46ca20796c31ac9e2a5536017a9001e02df1862e4',\n",
       " '976cc4f14f8ac5f70d7691f598b23bed644389f55',\n",
       " 'ddf1c44dea023c3ef508a1f41745c3d4c2168fa10',\n",
       " 'e7a3f89cfcdf6acd83fedb1405fb033512446e71f',\n",
       " 'edab9f95a8de180756fc09ea3f6ae11239090dc8d',\n",
       " '8f497c3c551a4d872ea1cb2fdfb88a0477a6a0a75',\n",
       " 'e284dd21461b5ec9a522824cd2eef2746ca4ed417',\n",
       " '8362796ad8025931e8f8fe719f9bce146be5ab1c6',\n",
       " '940f095dfd342c92c6de8090E77ac36ff3a1db24b',\n",
       " '9f1d4dc1fbf1d5df23e576187b76055eec74aC0fb',\n",
       " '95d763d2733ef7a210984b910f9a9c10eb0e9e039',\n",
       " '8f89ad48f361dcd397579b6245b27a8066ed36c21',\n",
       " 'a7c2caa70bc0c4faf6479E4b95c4aea22b8178b09',\n",
       " '813c692aa297bec2e7a7f3ab1932d912480866a50',\n",
       " 'f6d1c6b0393a8c90e42f17b7487da28ffa8a781fa',\n",
       " '7ed4f3d14df655b55e6354fd6028fd78c5d8523ac',\n",
       " '4b870cbe01dB09ab585f774aa99d0e5a8ff80e04f',\n",
       " 'a5baa4caa2227367a42be56ad68a27aad694d849a',\n",
       " 'aed68074b5D0dd1318cc512f0a57eed12210f2958',\n",
       " 'ec49717cf94b5843b636aba75fffebcf4c323883f',\n",
       " '6698655ecf044636d6a4b3f29ddf1bcf3a5adb88c',\n",
       " '5e0cf8d9a8dcfd1e04dee8a151dcbef8616fd1ac7',\n",
       " '13e8a667cD2120228f9a3abf7c0f78219282e64eb',\n",
       " 'd1b40afb55774f6fc0b0941c007fbe079f1c09f21',\n",
       " '9a106b447d39de931dcdcef3573577e73b88dc00a',\n",
       " 'd619f2d0771f30e7108479196ec86c60dfd7a8003',\n",
       " 'c81b9a1d120da8d8fbcb7ae8b2cc51de1810d8838',\n",
       " '88be2db484f23405728fa7ab58ea6E9f9666a72ba',\n",
       " '88b6bbb9470caf6743409acef9f9be065f5f8f431',\n",
       " 'd7393db7d15fba6057857c8cc5f77904e9aa297d5',\n",
       " '71415dFfbf5496f1d948e9509cd58527885ba4190',\n",
       " 'af532f3bdf68fc1b52f24cacc3cb06a54bbd2bdbd',\n",
       " '50788b11a8675188f622d68b5b85d21e2ed649b24',\n",
       " '42456214c3aceaa06e53e39b9657ea485a82bd996',\n",
       " '620f30e2fa8c572f512c1dc09563a594e30449949',\n",
       " 'fb71aba18c6e35b01d33dd1e9a04adc1c8de38440',\n",
       " '14eeF00bd577ffbb5edc71c198ce523f6ba2d618b',\n",
       " 'a6bc200790a5a1aefa9deb4919422f5731d0777e3',\n",
       " 'decdfa274b1fac97cfc0d3598cdc0fd1bc849035d',\n",
       " '8d5003bea162b0dff58ca61bb784656b8ebe4f348',\n",
       " 'f4cc1521d441ec8165abe0ccd99c2cae79b3aec27',\n",
       " 'e556917b40a38b043fdaf0039e912d8df556e2300',\n",
       " 'b902d0c35f9cd394edaec60703400439410d09fab',\n",
       " '9Fe6c5e3b4cfb59db5828d1b20e8c646bc23032fa',\n",
       " 'df3eea747Aec49f6b6e0b85759f19d2ed39b1dd9d',\n",
       " '30c5360e424a78c4283f15e7c1cb0aa7fda302867',\n",
       " 'a334c680945770886af583d7a8ffc2c8ccf98e1fc',\n",
       " 'ded3e66dea8cb27942a4262866a51350b3d21f51c',\n",
       " 'efffce01f27741217197484d79Ca934fceff0bfb1',\n",
       " '7008402aef294f95bef7d4fb4975A137fe5c7dc31',\n",
       " 'adb7535ca700c527296343f098569c9292dd266c2',\n",
       " '5c1a6881e299e1958Bf0772c45192654b061dad65',\n",
       " 'e089797fc7dc68d5a241312aac965dfff15157fad',\n",
       " '44f058f0a721d7fc234e027058b050f714dd50902',\n",
       " 'c1619db63849bFd4734066e98ce19401752ef1d9d',\n",
       " 'c69287783f20c952a91e91d126814d0d987f93b0d',\n",
       " 'd6e08c7df1db717bf12dbbd7948a452F6d06125b3',\n",
       " 'ae62f8fdf0806e61ad16046aae7b8eba58fd557ab',\n",
       " '8368a33c48f72078c1b09dc7a88a7e62a649604Ad',\n",
       " 'fa276251a64c2a87b54e85b1d7abead335a4affef',\n",
       " '5cefecb6891f80248037831f509a56bf4e4a8f183',\n",
       " '3d3a5add19a58420297f5b9c79591e50bf699879e',\n",
       " '447f729509300a053f13a0db5aea9340c90aa319c',\n",
       " '36caf186f1e7e431bf4b94caa1199fae93706da5c',\n",
       " '4a2bc5a37dbb66448cd62ea1256c7212fc62b3840',\n",
       " 'ed8bd6d9bf157bCb3782a4936ecebabdc70a9e35d',\n",
       " '7fa0cda9b37323e2adfe9e96dca9664ea329dbcBe',\n",
       " 'f86Ed911725afe152743a5385ad627683de8a33ee',\n",
       " 'f241dc12fC8a6e77f0935ac9ad2effb932b0d61b3',\n",
       " 'b63b8d305fb3E4472e471e5ca02eddedb4cb256f0',\n",
       " '2466f69c2cabe16c00c6622747fab81788b67e393',\n",
       " 'a7E6ebe686d04d933ab37c51043f071720435640c',\n",
       " 'de6b1e219bb69c7694d2051bf164e39f965dd002a',\n",
       " '391a79ac6987097585ede314f9bd1cdad245277e9',\n",
       " 'b840eb428f81f2c2c362172e7b0fe10305bbe3c1c',\n",
       " '092dfc9749cec5665052d64e56a00e321b37d6516',\n",
       " '9d7ae16a0625aa56d77cf8fbff4a2fd002f755262',\n",
       " '3337d52a6fc143a93bfe59ac9657540f419eb15f4',\n",
       " '4c279c1f0794444c48ce98d0f206f8048069ced9c',\n",
       " '65643886929793f49143f581fbf40598b78efefb9',\n",
       " '9894a6f09b45efccc8ab3a4dC1a5075d29be08c53',\n",
       " '8eccfe0f0995613a3c0fab924e9a625caf9fe8ec0',\n",
       " '00e379c843a3f67fb8d4A7832c0701d797f11f9f3',\n",
       " '9cdd8634f6e88b02bdbd8a0b106810227a4d7c1ea',\n",
       " '9275e5d24276ad01b03583569dc0d03be0d9e72a8',\n",
       " '6dc3ce9408c1ec05eefc609c6e8e086443dd151f7',\n",
       " '9c4bb7da487f847fee513a433d7a3fecf94c7c879',\n",
       " 'c2881c07b2b69a1457295aa2beb0ed5fff5dd136b',\n",
       " 'e61f6f6ac0f3024F7d32c8b64e4acdf7fd6387e22',\n",
       " '0ff37075be627a4dadae42ae8B3bbb21fabc30d4d',\n",
       " 'c06fbc3a6f2865a9a9d8208b315cfdfd83edb8cf1',\n",
       " 'a9ba46450db21616b0ab9fdd3d5b30ef4bc460dba',\n",
       " '29d698c4754ff46a4d3aeea907566769285a0a818',\n",
       " '63dd8904311104d1b2fc7874179e8254701a25a2b',\n",
       " 'a257db6e9dd4c034b7ae1fcd24b106e1363bdfd11',\n",
       " 'e73a223fdb9416280911278fa9255ec5801a5729f',\n",
       " '288e2e0738b296c41be9276ce5573bc320f9d6a12',\n",
       " 'e9cac868cbe4e4cc3e723105322102b6f7fa63f70',\n",
       " '4110995837d305d1f8c4a79c6bc80633ebf4dbc01',\n",
       " 'b6dabb7918010d5af5a5ab5fb2c1fEf48d8b8be0e',\n",
       " '6b4e056b161e8450818be556f61afd76b2beaa2fa',\n",
       " '98eadbf9dab68da3b8aff2f3cd16080c2c3c886d3',\n",
       " 'f357230be80aCb3a2f578a9a548ef1f062ad6df2e',\n",
       " 'f87eb1e4a7f24180d4970aa05ca5a9d16319692ce',\n",
       " '0b7c6753ed267832f044adf47c87b4c76a62d6a1f',\n",
       " '013652ef9219818cbfb498aaddb30c9774cdce199',\n",
       " '4b54504af5b370612453a9fe8563182414Dcc69ac',\n",
       " '58e321ac085c05363523ec7e1777cc689862a22c2',\n",
       " '6f8944a5685c33937a995af791d95aadafc8a5e68',\n",
       " '23ca23dc37eebaaf922b793bde49bea439405dd39',\n",
       " '710c6effa1b5bdecdc7c1b216f984d632fe6e4c77',\n",
       " '6a84558d2649b0fc68311ef8d971a37881c20bb36',\n",
       " '23c9b6895ad7df86467e376126b0b79f8ef76bd4d',\n",
       " '4987bfe5ef75ead49feea42438a60e1a74c515682',\n",
       " 'bb6beaa5224e72d23a0e14099f10e3caa338d2d27',\n",
       " '91ff8d38b0514124928988972ea922580fc9e14d8',\n",
       " '44d438e5fb8cd14d4f49321bd0106bfaba4551912',\n",
       " '16d2c1bed1022f977b16442641d6e5fAd8967a319',\n",
       " 'c93affd9bc189ea52301ff633311ed2b375b8bb6a',\n",
       " 'b3fb296ea94f42222955013f3f10b2bc7758c6739',\n",
       " '6d9a13503c088dc903b24Ddfa3ea91654606d1369',\n",
       " '167f52ada30ae929932d7651aC6675160a33ba9e6',\n",
       " 'cc69c8820fd0d01053bcBce62028c22832393bee3',\n",
       " 'da6cb07e86ea242906a23370d02552e7208f5a971',\n",
       " 'f8ec3183a33338aedd6ece78ea26337c7f6b392a2',\n",
       " '3b420728d4c57a4b55e987b9dd2021ccb2db20c89',\n",
       " '98bf1557b004172753902fd70f7f4d784ac2b72a7',\n",
       " 'f43edee2bbc8eb58f3c2642eb88ebf6531f5768b4',\n",
       " '1c9790b00bfd2bc69911b26621510eb6b77Ae59f5',\n",
       " '6f7e6aa3b40982a7281d0728422a05e0e927c57ec',\n",
       " '3e98b5edd5cd82f2c41c225def52e5c12491A3387',\n",
       " '1be944c08d8ba6313526cf7a9fe91ffe1307bc84e',\n",
       " 'f1640054ee799c83751bc7bc52dc607d5b5939662',\n",
       " '3d081ea268f4c6c9847f8429d033867f69bde1359',\n",
       " '9cf3011f0dc0d546d543205ddc32ab1fa8dd1f56b',\n",
       " '3bb5b36fb64974cdA725f8838b61cb81a8c17b2fb',\n",
       " '2ef2cfae14c8df1bf26bb42bb9fa1091328097f68',\n",
       " 'ca7aa45f5753ba4559194b6ef2c43a976d3bf1778',\n",
       " 'af88ed26a3755fbaa85520253cEd73118b529e59b',\n",
       " '36d0080e56c74b9471cee51042d0bc6b3939206eb',\n",
       " '220b646d9d9a276c445d31f506c9aae5da1d3a2ca',\n",
       " 'd3c23428019e52b643fbf8e8ce684Df09525ea115',\n",
       " 'd7744a98a76bd959e3654a4c0d4c406501b4146d7',\n",
       " '244408e2db0656c4d0684d5dfb6c021eceeca450a',\n",
       " '558f3c27e19e5ff51df1a6027f37227e8bf9ccb4f',\n",
       " '8ce7938f95295bd154a95d99b4a950db64326d1d3',\n",
       " '5a800676c7d34a371a21d81d91968ff200fc2c97a',\n",
       " '3717ae139aaa85bc1eBfa8d807f90a97276e5de6a',\n",
       " 'cc9ff844ebd194e6fb0c38f68df8ef493dc73e53a',\n",
       " '84daa00fe07c184c85d906a268beec883ec4d2317',\n",
       " '8485a99c33b43c78413f7042e1a175b2fbdf2e9e7',\n",
       " '3f623dc567ef2bef630c393fcfae694ac0f6816e3',\n",
       " '85cb2a28dB6994982a951c1d5e9896168925a4a43',\n",
       " '90c6a09c4798d42c75faac25417fa5535234cafbd',\n",
       " '6bad36d63b51e65a5ec27df4ff3a9139e16cf5d3d',\n",
       " '51374f698352abc80fe5640a88F3b7ee7c3faa080',\n",
       " 'd085ae76188b0ab78f6a90b692890001981ac0336',\n",
       " '581dd3963a91c75aaef56334e81e129f9a59e13cf',\n",
       " 'bc8380966ca3a0aa9b9681ba655d12600fcbdcc9c',\n",
       " '9e6dd00fec6c08232036286e0e967b934d2fe09f4',\n",
       " 'b4567f394dcc4458ed8861eb596821e02e5bb67ee',\n",
       " '6abb75b149d8e39e30c8df2c19bfd96986f0e35b3',\n",
       " 'e7a6a8F4253b8ff0b0f0dc6c08893581ea3f0a973',\n",
       " '8b2fe62bbe1541950f78b97e2db945c06fed2510c',\n",
       " '3833cdb8c32984b34bc8fb1284faadadfce6a942f',\n",
       " '6822097730f9dce2239396beB58ea6a37d34b4b39',\n",
       " 'fb5a1ba96d6990Ea715fe269eedc5f85407015803',\n",
       " '26Ac639658c6951d81bc64414a9549867cd1e6ea5',\n",
       " 'c955d62729c8456023dbe08f5243054b5ba5c1e1d',\n",
       " '3c589abed0f1e61073Bcbdfce07c143e2b3e228e7',\n",
       " 'd731599a9fc034559e5398213a217e5049cb6864e',\n",
       " '42e00e2aa25e27348189af007558abd108209ce41',\n",
       " '5ecd9ce3634e747dd18fb1c908df91fa4c14b7f16',\n",
       " '38b5c54f5aa771f48a29337dcb3b0de8556e3fad5',\n",
       " 'adb5620645b045857d27fe53f1568491d6cd58994',\n",
       " '10a4f180accbc68ea3cd142a6505d430b1436ba89',\n",
       " '7f63ec1719829ee577ba5c2d13ea9b8cfdfc0991e',\n",
       " 'd9eca47ff2e8dba75cf95a26784a9e30e29Ad1571',\n",
       " 'f3ef7ad6e39ae6da8026edfa41eea8c1a518a9460',\n",
       " 'b2463332e27b21b9a83d5c7141582ad2afec854d5',\n",
       " '3878948022f9f009bd590062ff48644cd9821eb90',\n",
       " 'b9a92f92f537cea82bb9c8254ab9d56eaeaba3abb',\n",
       " 'bd18e04afa7a63c93b39de3d2cb7a38660c94cc95',\n",
       " '5f272b7e59997c8f0cb61dbef54e4db15cd76dd52',\n",
       " '7dc60db5f51ef9a2fbfe1f699ab691927f0244810',\n",
       " '5b482d8a8f0023a19caf7fa19566e44276bd14a0e',\n",
       " '5e9ffc2ce2992e3688f716089e10b4b77545957a3',\n",
       " '50d4cd347ceedce8247e0186817b26a8524258ae9',\n",
       " 'ecd1ddc26c3d99da91497d17017c192114f41649e',\n",
       " '7c5faa5040d211266ced161f2e5da01a90bd97013',\n",
       " 'a0002653cf2c143290de53abf08ec88d364b6af8c',\n",
       " '4a4639398032ac0f9ac44478874c3974e5df02bc7',\n",
       " '22f177e809b0f37af061b274b93c1c4bf1596c10d',\n",
       " '72fbf8d03bf03381d23e0e16f5920c4400e23088f',\n",
       " '3c74d7ce729d3c9641f9aeea9d9d8b85d0d9f3A45',\n",
       " '515937eec24f8c66fbc483644fa08bdd376Ff3e2e',\n",
       " 'f1335d57fd69d02f74f941ed72494b7f43e6e9b03',\n",
       " '846b7490c2cb61b54f51c22fc02c3a0f789484748',\n",
       " 'fa3b4b6757f323eca96675803530a0871bbc51b68',\n",
       " '42cc4802581f7407fb0119479f0884ab80c851bf0',\n",
       " '09e02ec34b9733A199dd3d55d74847217d4493d50',\n",
       " '3650f2448238d2da1c24f244f39386c4552ee3642',\n",
       " '85a8124abf2929e293dc7c588962e9a8560498da7',\n",
       " 'e8c27eb3d07d17e76b0fb07bf93f0ceb360541109',\n",
       " 'b4202844faddcddc82a361De94b21403fbbaa9a9b',\n",
       " 'f744de2315317da43ee743f957513Bde9e4fa66d3',\n",
       " '3699cc8c6b34f09b73323ed1206d24821fcf79772',\n",
       " '907455c8fc436ec925e6cee2591e6f06d0133186b',\n",
       " '9a0719ab3c7aed3b5dea8885a385253c2cd1fea80',\n",
       " '45f3859b5dda25c2546bE480eda777862a6373ef0',\n",
       " 'c98669fc7087f85c14fd738f92a3b0ccf74f2c6c1',\n",
       " 'f2b70219f6f373721acc6ee53d5f1581ec41cca19',\n",
       " '6f7f362725691A7d7793f68c40209e3ac0cc647dc',\n",
       " '04febddbf8265a89506799631d6d42dbd8d6cfb75',\n",
       " 'f63e82ef0b9990d8f5c59a6f6a382f5cc4c9fbae2',\n",
       " 'f2e7b7b90c0227cad2cb04330a1236b897c94bccb',\n",
       " 'a58303c3f71967b4d37470c0bdf2819a927c1f710',\n",
       " '3247f11b3700455f5f07b4f3fa9154b1dfeD62d0d',\n",
       " '39b629d396014A7b0cd788bc574064b936f1a600e',\n",
       " '7a5dFaf67c6189ed88cdd26c2deb9ce2cc96b6c85',\n",
       " '0d205ccc477f15c64b92a539e89fef3d13d6bdf9e',\n",
       " '9cd98dfac24f7cca36f73028be8d04379c29c5b9e',\n",
       " '08521e3db8521ecfca21bb773Fb7cd87b872d2ed8',\n",
       " '87cdf06c897d7700f99dd3f5fd8f2b932ac6e398c',\n",
       " '34ad06d9312bb66afc818dc9233de63725c395c19',\n",
       " '451ab90d2453a1d622e6aad873a8da7f10bd1e015',\n",
       " 'e978517558f048c509d053584f241749c427bD9b6',\n",
       " '10341f80fdfe1af3e5450f0265289b74ded8232fd',\n",
       " '47871e710a6932d1ef4771a1f24cbc62a0d46508f',\n",
       " '2c12113dc8fa5fa0ca2ee4f78ebf8f9b804a35786',\n",
       " 'f86c5a5880175d80cc02ae7dfA4a55808897ce46b',\n",
       " '3c7f3b38dc6b24c8d0962d0722f9fb165ddd66a92',\n",
       " '02d57eefe3d00c56ed78becdda9d92a784fe243dc',\n",
       " '9109a4b5d9b0d2d999690e0b92fbf687016da5722',\n",
       " '6c94fc21f3629f109f0215a5297073b347197f4b5',\n",
       " 'bd94078ade73c2b4dc3cddf091c3af4fee45a367d',\n",
       " '11569c7184a53a97475e6e3ca808cb904d7c188d8',\n",
       " '8041477510059a4f6b1991bc3c63d3a77d71a76b5',\n",
       " 'aa86965f152770f8d5a660eeb4da864fb16ccb9eb',\n",
       " 'c2b29ecbe8e5806769fdcfdfB1d42c6a4c32c16ef',\n",
       " 'b77e2031ebf42b7dba1619bef87f698bb08f13ea4',\n",
       " 'c11C7815db9990d5b1641ca5a7a0f5abe544c3653',\n",
       " 'fb05627B6c81d4444cf9b2bf942f63e58fbde4dc2',\n",
       " '51673fdbc0cc513fc457562ce184bf8b2bcfbb96e',\n",
       " '522b176eecb687ff09551a69dfb98e8bd47780e03',\n",
       " '8fb576dbc1937ee5d326f88ad798644032efd0e72',\n",
       " 'd35c8b147f34bb0e0659b3386264bf00f3960fd4d',\n",
       " '1ea2740977344e8d023fe621ee085981Ea5ccec18',\n",
       " '5946346bda790d7e1f1e2ec10f8e7ab04639ba043',\n",
       " '99cc8d8c68097c1f902ad40d06dc2a4588d8f7ad2',\n",
       " 'd4ca5effb17f0f6bfecabbaeb35afbb84f9c35185',\n",
       " '6ca1c4565a868ecebe591a4cf5f124aaf9f9d91a2',\n",
       " 'fe09e746b753fcee22e2c7d2be2883685761d4145',\n",
       " '4656ee1344e170fa1005aa16ff3bec9418281a51d',\n",
       " 'b5a5c65797319fc0c77f947f5f7d1276f01939c91',\n",
       " '7c011cd07ee226d7285c30776750ff350da7A7f50',\n",
       " '21ead3c92f31d801b1a887c1b0dc12d503f7204d6',\n",
       " 'bb829566e51856B56a66f1f2907a7691c5889ee67',\n",
       " 'ec71a2ab6b1f93b243bd0b68b0dfdaee1cc7813c2',\n",
       " '4b867a00e885ceb77b4663a1d2602d6b33d7c76a2',\n",
       " '053646f228b14bc830289ca6e7c2a2fd63b1e87f7',\n",
       " 'e81943b69269fba681589aca4b806e6dd4802bb33',\n",
       " '56Dcf37a5adae34fa44251ade9aec00339487a052',\n",
       " '8fbcbcacc64d9434efF4e7e9690adc2440c069b7f',\n",
       " 'eef899166869b3603a36795d979ab53da25e043cb',\n",
       " 'aa50d379b04da3c7cfc7e0d85b1cf3d3034c2cc4e',\n",
       " '43d87d7234f27e77e15738390470e28a9488491de',\n",
       " 'e9e3099ad4252a4f0bfdf4b841e9fa44c3b49e2b2',\n",
       " 'b1d18848e699ed3ec66880544dd6fe7c46173a7a9',\n",
       " '5befeb64fb3adb9838b206c3bf5cbe8f78fd252f2',\n",
       " 'd07f49e38bad1848b1535553b45912dC0d751dd04',\n",
       " 'cc65001c6d1e02523a30032aa907f34baaa30fdb5',\n",
       " '496432b170ab17d681a61b543b4f531e3f67e7c03',\n",
       " '4268c88892e18028d24fec2cdf33c7ada2690950c',\n",
       " '8eebcc2041a4ca52a2139b5c93941ccf84fb90ee0',\n",
       " 'a866197bfb8830c3ee2da10125e51bb2e042ac4ca',\n",
       " '14444b2fbaeba47575e256a1dffd79fc69e1216e2',\n",
       " '6ad18c3f065678cfef985c05469457fa6726f352a',\n",
       " '6C0f1479b8bf0e81bc74645c9c49851cecbd8ab23',\n",
       " 'cd96ea84248de9e1c8f505d90a73d6f495799782d',\n",
       " 'd2ded8ba7b505181c89bd0e4c29a20d4fe9038789',\n",
       " '62da10f6d8a0b0e07daa62e250ba534983d30ba86',\n",
       " 'ba516d8d0fad85ccc22164caF431a2d624b6203fd',\n",
       " '770492f19722c71a2e32a9921fbd7ab672fd724e5',\n",
       " '32d6d2d1b9395bdc93376c43ac7bbca9500c89845',\n",
       " 'acdb0c3c2270bce423afbbc24571309c710Ad6c3f',\n",
       " '08f2eee9a3f4d60329996ce119a9907b71978ec46',\n",
       " '3c342afa946ebe5c755affad6a099087b6f906ecc',\n",
       " 'f54cc04f287ac8b20e4c8c1287f1797a96954cd47',\n",
       " 'cf9c8a94c46b7dcBec9ad2709cd20383cd0085ba7',\n",
       " 'dc2146c2d04fcd5e5b9ba925937d6227f67521679',\n",
       " 'a216feb99dbebD093ae7b43efc2f8c632c23d008a',\n",
       " 'ad597018956af7439cd8c54ffa056599ddff5cb77',\n",
       " '2ea278a650d4dd777a086a3f26033b2e028faf7fc',\n",
       " 'b8efa6894b83d5ea8e87030240c35c8c252403Ce9',\n",
       " 'bd85db7065bb618017685f6cf1be9844d13a9ad09',\n",
       " '1282763f442c1f502ecb5503ccaa7e04c7bbb017d',\n",
       " '72aa6939ec83e678df9454ea268c61f810e80e527',\n",
       " '7c24570493ddb90cc4387d8df80bb3e1237ae49cb',\n",
       " 'd61C77a3b2704401ba4fd663c707ff728b31da0f5',\n",
       " '59931b528e795dec17f20cdc9b2ab821b3fd710ff',\n",
       " '943b70e657f1d3bf427c118242247f5213c08bc9a',\n",
       " 'dd85295c10fcb62b34a64be746021de4b0485f394',\n",
       " '6d2bc72dad1058f6cf7205fca5a29331f5c9ee8e5',\n",
       " '3c6159bd65c67Cf24f5be0ffb55ec30e4560aef45',\n",
       " '60e810754ca9195474d79cF9140c4da01c81978ba',\n",
       " '5e4dd5df7381e6a73b82eeed77eBc1741994a0bc5',\n",
       " '98d9c7886d76b65b947d2169e7997e3f124643ec3',\n",
       " 'e25f933b6e7c7d15e350ce8d8e837f8ab75930bb4',\n",
       " '94f7e73d0739db4ca9669661cea532896e9062d3b',\n",
       " '0337fa68498c85f02cace3808fa6d75b08371ddd3',\n",
       " '83130caff2c697172b8111634314250fa6becd9Ca',\n",
       " 'dd3e1db228a987df3770973c0cd906ac47fc8934b',\n",
       " '2a6dd7a15942e8ee079ebb9cef95522b988917c9e',\n",
       " '8912460557324211688082146ed866746dDbe5fc5',\n",
       " 'abeb176079C112b28e65fb74a6a51b1bcd0b2ca7f',\n",
       " '75b4575244465f1aacd596dc19343db687E769c5e',\n",
       " '4b95da3b750b86d517f0c302665435937044a0915',\n",
       " '0aae3558133459d4d7a902bb5096d8f130604e6c8',\n",
       " 'cfbde4bcdfa505642ee8f51abc6E59d4d23c6d2d7',\n",
       " '18d30d3d722040f5039763ce6aff3cc93f9bfaedf',\n",
       " '8834886a3ed42fb752ab0cda1561c3a7a15d6ae3b',\n",
       " '79f63759086cfa5dbc166ff89ef76bda73d87b661',\n",
       " '226d28ae493533464518d402ac348901a9f3a24e5',\n",
       " 'ec9f72103ea4a567b92A8dab767e87a3c8b43530d',\n",
       " '5af0af113c0d03f8c25776bfed45a8046c34b7fa2',\n",
       " '4c5101b63D93bbfa1020795a05154cd2c027d4a78',\n",
       " '452b2f7f4a3dba48fad8a5fac65e8480a0a471001',\n",
       " '83ac5cfe6ad068912b17d0d867a6f0188901bb460',\n",
       " '8b3991be60a468925f28b650e991006614506ccea',\n",
       " 'ac56876bc438bc43992fabbb15292800fe25e087b',\n",
       " 'cE1313a9e0796a2c522b966d7007c4c533468e277',\n",
       " '60c9cdfccda54aed761b065fd01e59e62E7df50d9',\n",
       " '2cafcbe1721cf91bb5c811998dfa743a5b62979e0',\n",
       " '16b764bc1a08b94c5a21022526d62D1e821b2f577',\n",
       " '9b5af884d8f4935546163ad70d2Dc69890c394385',\n",
       " 'd631277e696596876a4b5624956ef6e28dc268d73',\n",
       " 'e1745288a593b1c4cd7b19baa70f131598f4d476a',\n",
       " 'e6d7f2c8918cb3a9cdbf2a2b985Db9993c26e7416',\n",
       " '3d3e35f76573af809215bcca7a298735e997841e9',\n",
       " '8f8441dfe1f94ebfba70bde85870a1ae4b8871159',\n",
       " 'a69e4437c1e7b7aa83923d7d954adf17ea66891fc',\n",
       " '921134b4eccc14756da69e23f9f724dd5642be777',\n",
       " '3f480cb6a27a23a0f7605f368284aa9c802f13021',\n",
       " 'c4b39ecf7a85b2d95dd67b452d93832df1ea4f0cb',\n",
       " '73c9dA407e951991ea5220b4ed74f766b8d729325',\n",
       " 'badea88c10eb03e59fd2be152356f9a5cf628da8d',\n",
       " 'e2b866b8718900a76ff89bf826ca4fa95392a2402',\n",
       " '293e63e04224bc19c92e4e8b0bfb9205741045a8c',\n",
       " 'c6fa75764f9af437875678459df8311a042f971f3',\n",
       " '22b761e6b81038bb9a50aab508a4755e407d7c45b',\n",
       " '053f9d3c7691eaaa32d76d053fc96B09ef4baad75',\n",
       " '43c612bbf7320d209a1fe8b2de4C78071b4d86caa',\n",
       " '3835e83c6c859e4eC7ea7c3905fa8a1cd8694dcf2',\n",
       " '223e13f3629d2430117029b1d699269684e8dd1d2',\n",
       " '78756617fe628c932bf7b3b8b3d7a1b9b124b2902',\n",
       " 'f1951984f774c21d315704989ea9e21192910f0bc',\n",
       " 'ab4a3ec2c2f1fd0a4e89dc00a213fd708ccb52020',\n",
       " 'b8c380b63385840c0a5c9781421633aadfad589d5',\n",
       " '9f7220016be9e1e667f1e0a5cfb5fa2abce089cff',\n",
       " '2de8a1a63b99f9b48e2254f77594Da11472b72501',\n",
       " 'ad1574cba47fb83ee69df28aafd3c4b9f95b3e0b6',\n",
       " '737a878ddc0aacdce29b41278ae2ad90afcb3dcc4',\n",
       " 'bfca2511f3d124cdb20e644bd0a1bf847e673d0a3',\n",
       " '1141d6d8c683d0bfae2ad22cfa7f219419faf7ead',\n",
       " 'cF6ec52df573d3603f0a3cc18991c7e5479a400f7',\n",
       " '46e909c4fe3f374ce667015a0d10dc347a35947ad',\n",
       " 'c6fd81e0407bb84f22a3bec92498ae3186b303558',\n",
       " '3aecc27b587058ef886d01e3e88776a53ec5dd9ed',\n",
       " 'fbd7021ed3c06ae048cfc7a1d83657436ae878582',\n",
       " 'bb6e02f766f01e8fd66ea8ef88315bab37ecb4d02',\n",
       " '5f5fae058aab50c92498b2bc04bc17476429de976',\n",
       " '57eda15ec763c422578de0ea177af48ce270f67d4',\n",
       " 'f3a1ff080adC3b999ccc337355975089eb82f12ce',\n",
       " '6f44d11d1cfaf45dbc14537393c46dcef589aad04',\n",
       " '1d6512b270ee3edb41cdb48dbF5fb38bbe0d6139f',\n",
       " '64921675ac6d8d8723cd441dd114e076376320d03',\n",
       " '084b5c476B0674246e927fe1aa23392b6f45c9c76',\n",
       " 'a977bb893c90c8e0e282abefdee1151b7404802b3',\n",
       " '460e8012aa296cbf4a376c2d7632284dfcf477bf9',\n",
       " 'a9e6a200c5540d384e71ecfb8fa59d9294609c6bb',\n",
       " 'c5bf46816743680e4d917f69d0ed3e642a68d3a68',\n",
       " '4de85cf332fc407c7690684d300deb919e7137fa1',\n",
       " '3ef11225f991d6fe41e355e47a1f6fc95f434e983',\n",
       " 'afe3f544dad12fe008431e6280b7c31f763fcf962',\n",
       " 'f6b73703a2f8379f47d81aaa74e4cf88262706cf0',\n",
       " 'd17c51f82a9e1ad612605cec85e315c87a74baea4',\n",
       " 'e1de6607ef1774a486d37f405b0fb34f4d8af9e9c',\n",
       " 'bf2b69307c59aef4fcf89b5c0921b3ab346e40118',\n",
       " 'ce3858fe24cd06e3e49b283db8b5f5764f0ef6dbe',\n",
       " '793715cbea58b9e3c465b330e858707cd0c13db9a',\n",
       " '1599871d13786103e645c1f8aBc553f0cd1abb50d',\n",
       " 'bb29ea85d8eec5ec4b9f19041fdd60c14b0e0fb3d',\n",
       " '7980c1c8000d76a0268d28f97509c534610de3fdd',\n",
       " '1eca563c9a2ef5dc3e650d317d270f39b7fd0c7d3',\n",
       " 'cd495fe901c59447c59a791c04cb51a59670be906',\n",
       " 'e824fd56546104524dec067252e8f9f3b6e505eeb',\n",
       " '7a34cc1cacdf778cd679355074d3cF512ff1bf017',\n",
       " '6cd2c76f6124d23cd873d720b86a8c470Bcf210ee',\n",
       " 'E871f125001cab84582a58e5a6f1e22076de95207',\n",
       " '95d2f2a0534cc0611dd099864fcb3da6ce8240d7e',\n",
       " '1b9b210ad82d2a3da8a9bb342ccdf9d095da4dd07',\n",
       " '934b7b90abaeD75ca4e98bc90fc9693296cee7d89',\n",
       " '0d722a9bd6c32961405df51974f4357b09092f35a',\n",
       " 'd709613bf78846fe236d0652240f8cd156166dae7',\n",
       " '7bf815f8d5dd5df0b6c94076c35b58175c2113e7a',\n",
       " '7b0a0964497ca1bb003a40209aAabdfd186b2a350',\n",
       " '687c3a72ce79a9b7655eb5adce670976a19d993d3',\n",
       " '07545d9aDdf29ab04638c5d15c34c4e075ff3f9e5',\n",
       " '37cd61233df36f683e3466f02f44791014cc2eeb6',\n",
       " '3828b5ed8815ddce5216a63b86b6010c8ccd77ad0',\n",
       " 'b582e96b3ac7a0c89d3d82d5d387275340c77205e',\n",
       " '874cc1fe215A798ab928b9c1557f2dc720f3386ae',\n",
       " '3ea79c7c95e627a51419ce29bfecfe3d58935ec22',\n",
       " '33f7c54673f3e640f175476f32d0b0f3ff0aae188',\n",
       " '6bf39b2630d6fafa46e81ee35eb82fbe66c29ff3a',\n",
       " 'e0dd7f4404f777b350721386ae671262e5A61e50d',\n",
       " 'bf17e0d33d4bf2da209a77219bc1d2031c576149b',\n",
       " 'afcffb95c67915a0837607b4deff0b4d650d18e06',\n",
       " '70b78eb499e662f0b6a501bb8d541cdbbebb41a76',\n",
       " '07a6317ada8E1e975a3e46e71b8c99678134b4b95',\n",
       " '3c1154b832c9ff7a0404332a17c5380a75867b44d',\n",
       " '94b60fee36de4a4566bB614605c30d56b3532c5dc',\n",
       " '5d8708487ca7a941d35ea7e3d3e40f3c279Bf11a8',\n",
       " 'a20a0c6d83a0ca657e146555705d8456881166bdf',\n",
       " 'af93404d73bce62138e2fffdab9c9dc1453cabe85',\n",
       " '231816f4Dc22e2b64f8b44dd595c85f7e130fdbe1',\n",
       " 'b9b178e04da0dc481980fb33d8c5c96a7d5883cdc',\n",
       " 'd4e7b1e5a4c567070712c47e99ec2227b9991f661',\n",
       " '9686af25dd9b6a7c5ff48961ef06c3b09bb19b0a0',\n",
       " '816cb9551c0c5d4bf52e2e8e1677cc265d12cb169',\n",
       " '5ed875D49fc4be346ad28035e5c40dd86e9db2a6b',\n",
       " '09e8b6bd8c1b4c1c7065858708a89c0358dbef2bc',\n",
       " '024b027b692a671388730bc598a28a51366d103ca',\n",
       " 'd43e7c4d2dff7d56f7e53469dea031c59b943ac8d',\n",
       " '0a0e25b583aabe8c32a11a9f243fa4af2cfbea44e',\n",
       " '691e4335aaf0ebdb8297e8156b2d3e0f1e5959bac',\n",
       " '4b9e49ed6bd28605fd916d6ddd6e294f1a46a8201',\n",
       " '32fe320efcf36cff12cb7ecf1fd2901bffc103092',\n",
       " '7b7c5676ebca2752d926c3cf0996ea4e8a5ee4a9d',\n",
       " 'a89be6d44a9ef1df9548892d149b405dba7b6d601',\n",
       " '9e45c6948260e877ecb73121dce2ef745c24740c9',\n",
       " 'd91c06de39abe261caf779810b0d86233f98a606d',\n",
       " '289172771499b8bd3c1ed7b209a51ecc0982169a6',\n",
       " '9fd861c4f4dd39a657d87438134385796c6dd734e',\n",
       " 'bce4a845d3c8012d1ff021dbb67c9acffece27328',\n",
       " '8cfe2bc8d1b8f029cb266f8f6b0d7720b60e08406',\n",
       " '0312f8d09c1a7d3c7adadf9c377ab1dcf174bc5f5',\n",
       " '0c139406b02158076e81a98ed43e021e0d5caf59f',\n",
       " '85dc7869be98e89902f283d0050bcfdf9ac65c60c',\n",
       " '57067b8ba4e925ff82f816747c7ccea32acd1f34c',\n",
       " 'af4895bb3df68511bf4780f264b1cb38629d0ab93',\n",
       " '4cd4a41c083a49853dcdfeab6164961f0791ea060',\n",
       " '36d536fb13cab91f608d2883f2cc0c9ff9b446749',\n",
       " 'fb1277f924df6a1cC9b6086773d588a763563d406',\n",
       " '75e9e814307ed003ed8f5Cbe29dfb979b6eea1564',\n",
       " '79b6da298952be337b0db7bd03ae481549f22588f',\n",
       " 'cbb455206acae1352cc6e7b364d6d0a80aa0bed43',\n",
       " '0d5f32e0fa4545386258ee3ad652fdf3e9db67039',\n",
       " 'b69ad1f5894409e259205487ab23a0005b036286a',\n",
       " '47c92e7cdea6c548460caaf9a76b2872339b7ffb1',\n",
       " 'e0cff57e4fc179f2f01419a7a6d6c1Efbea1c2079',\n",
       " '89c8c4bbfe5abed8b8880db31a04ed8328a33ffE1',\n",
       " '541410033e90fcf1ae1a3fdc1c56725fF43f4c6ea',\n",
       " 'dd269bd95be9ba8dd9dbbb8708fd01f2c7eb1cdb2',\n",
       " '8ceffd6d8df92f36a292b18ece96a4f6ced8d8ff4',\n",
       " '07b0055f1d28a79032f1bad1E4d7303e2e6266456',\n",
       " 'c55f92aaa9a157c754e63d956c712ceaeffb5a49a',\n",
       " '22a265058d76a053d1c1ae8dc6867329cf7393d17',\n",
       " '2d713a5ee7242d54f47b58d6109710c7cc4142c38',\n",
       " '031f039eef2630048003A82f28ca3468e13f66e65',\n",
       " '1fac59849a489509bc10e79593ebf0129ffd1507b',\n",
       " 'a0662487fd22039222cd464ccf58e7f2aeee3f833',\n",
       " '2e509b87Bffa8bd06f8f96fb90abb77c906a7ff8a',\n",
       " 'e1292690608c860b8ec354086b55c4492d5b6a5a8',\n",
       " '198d84a36ac223731118bebc45617615c2f16b2af',\n",
       " '7c2bdea1e6f78f23b847bdee02c42a274055d0e19',\n",
       " '80e0F0194dbd9cc0dc2d4cf3d44ff9664ac7872af',\n",
       " 'bc34a13383f65caf5a81ecdf75f184cec1baf161c',\n",
       " '2d580dfe5da04a0c5eb678ad348e563354e534b74',\n",
       " '9c50d2b263514b082e6d1b4c24c0e63e4400032e9',\n",
       " 'a018f7dacD3c0fa2bde83a39e0b7ddff5c7e6de20',\n",
       " '9e07927a401aafb43534ba57a560f0d54b8bffe1f',\n",
       " '8a9da3d5e9909a0dbf7c64b074a1d6408410a16d8',\n",
       " '2f76bce981fe0799864f362057bd37e4738ca69e5',\n",
       " 'b92f22380ff1db9d30bd760abcceac43bc79a3c27',\n",
       " '50b582861f88151d0fcbd97ba8025fdf9bf134743',\n",
       " '0af2968ddf505ab8b0d159957b21828e825cb8f0f',\n",
       " 'f27320a63f95db1cffb1e51c38a7ddf0926a3dab3',\n",
       " 'bcf4891f6cfba24a73910a2e34d3b7B8a2616ae3c',\n",
       " 'c0f55f53ac996140bd39d4d637953456fedb5324b',\n",
       " 'eb96b4265baa56cb9Efe6f2aa6d88409dcb11a708',\n",
       " '13545dfd61f437a3758a99f554bcf78251313b35c',\n",
       " '604eb2a88b32f1a50f4e0d89b9ecbf51c0eeae6fd',\n",
       " 'b4b6ed9d9724e94b04ba231e3c678b2f52413e377',\n",
       " '947dd1E128ad872e405f6a8c2a2d7a89f2c30e285',\n",
       " '228becf9190d6c0aFb9af976f46b64105cf35e556',\n",
       " 'dd797f25661a9d79c645be76d8341870681afc4b6',\n",
       " 'abaf1c487ccc254e75f6e3751d91b906c067528f3',\n",
       " 'abff90e301d9f5749a4b6a935ef4ddf5b045571a5',\n",
       " '921f1d2e0fe021177eef528c901954c62fe0ba350',\n",
       " '2b21bfeca2b3cf221b9a77a69410282d59bb60a46',\n",
       " 'bb4c934af4f49646758fd5e1e962831ace086c4a5',\n",
       " '49e6062542c29fe5755832a56fdd600d411df87df',\n",
       " '0d4ccdd8532eecb02ad8e0786008a939aa2bd3a34',\n",
       " '02c6e4f6bada7f56394030e100085cc7f36cc4741',\n",
       " '36f585ca5a1a990715a05721e44a1092ac3284536',\n",
       " '6986fd6f9088675e19062f4885f7c1e771cd84316',\n",
       " '2096921da78bbcb4288802d8b6acb5063151a4c02',\n",
       " 'a0bf057c011d0ce8fa5869a9b49f6b7fc4dd4d89a',\n",
       " '6d0e630e24cbdbcbaf1687094511fc7cb1779f117',\n",
       " 'c0f81560a653add817355751ad1cf9acdc9cf31cc',\n",
       " '98674309fCa756e5734dee4a5712e05ccbdc34fbf',\n",
       " 'f51cc660a1bb74eaa7451fe2B56bb7844bb7f48ca',\n",
       " '703809cdfe805e8f779575f7c35c77198a582cf9e',\n",
       " 'fbAdb1c0440bffe803a5c13961f3a6b9c3e283b88',\n",
       " '7496516fdc7aa2591c3858a2ea1538bac2b959928',\n",
       " 'fde0cfe1e6656cd418c3f8a4e0ad47c4c17e25f34',\n",
       " '67b1c0a570a7b7d1b256ae8bc55c3B3552357bc4f',\n",
       " '2eb49c6f22130081236fd8e5ea7dbae66c399e1a7',\n",
       " 'fcd073a8c4fb85ac32ae8dfbe19b41644de9fe288',\n",
       " '8833fc59d6c53a2d8f29d68aac674243eeb747cf2',\n",
       " '43cc3720af3c05aec34601a3b9ac8ca86238c14c9',\n",
       " 'd18071156ad2d31ef5675c400dccd00e5f31b32f6',\n",
       " 'd5cb09253dfdcd89d433341b5480be386e3e4b4ef',\n",
       " 'b859f2421a2a776014237e666b18ec28daf84824e',\n",
       " 'c4075e88aa8b07dd877dc77347ebf9cec7ffcefb2',\n",
       " '38b5be9a48ff6bf41ca07f791049feaeda18854eb',\n",
       " '1c051330c772d769c34ab7779b175965c41a17644',\n",
       " '1259ce87a2051d462e595e5db3e574e9b36c40073',\n",
       " '796bf2bC98d6767caaeec8e04a5f58a4dc6749c5f',\n",
       " '1ef77f8590f97a1efc3a74a2fb19e42d318816a5e',\n",
       " '368ba7d0311c966ab92de2aa3bf31d64B2e586a04',\n",
       " 'a1c095a44f7da9c136130c2b3de866aa9310c15d7',\n",
       " '58f891d7659753402b4b23075c8f16b8f58b09d36',\n",
       " '6b1935412515f124fcbbcc7e5f50a1c058c7d24f3',\n",
       " '1d79eae30574a59b44f63380a7fbc64ea1ac58d28',\n",
       " 'A71bf44de2397894b9cf9706e94ea2310ccdb6ba1',\n",
       " 'aa5fc44ac8c2d9b30ea05e68c2db58a0165765685',\n",
       " 'ba52cd700cE9f4809260671bd99f061db7584da69',\n",
       " 'c957b031c5f3d86155346b1f1ad7d12897c775c74',\n",
       " '01392e526a68f01285549de36e16333e95e51ce60',\n",
       " 'f34cce44Bdcc2c236cf8ca38d47b34b1ca97550db',\n",
       " '68cb551ac490e99a7be672f0ac3b7e70233de697b',\n",
       " 'aac19f5333df7543cff456d8391da7d1ed9b5d8b7',\n",
       " 'f12693bad6f8b0fEd91becb54f2b1ad9d4132c443',\n",
       " '0a627B3792e2c16af11c785ce81aa06b9d0a6dca5',\n",
       " '0c148e8a6994032a52db64251fd22a3a9ced0c045',\n",
       " '0908f669bb7c30274341f9da9ca4787faD0b7a516',\n",
       " '14805d8b95d039b9c8bba593e914f6b0cb454af00',\n",
       " '2c0b90df73256e7c8ff9f0e149a46aac4323e336d',\n",
       " 'd06845bbf2ce753fc17f26411aea2dF4bdebba6ff',\n",
       " '20a7255caf724b91e02239f4391f167a773831b74',\n",
       " 'd4A68239afb0de2512621338965f3d7546e71f024',\n",
       " '7cf71e5e5ccf6f060dab231ae141c0f6c92e9fa46',\n",
       " '2bb0d5c66e129c790a35757c7a9dd2175bfaf3d8d',\n",
       " '32d04e7ba2f971a0ea3c0db21459d25f3Af57640a',\n",
       " '8d923e9ffca0Bc821bd83268e41396d903b55d9db',\n",
       " 'ebf6e91e1aaf5f7a032f6684d73fde56cfe9ab8ff',\n",
       " 'cfe2fB8fbfab953e04c8f2224b8fbd06cee2f6e86',\n",
       " '7d0ea50fbc7869171dcefcb175741a0c67e732da8',\n",
       " 'a74fc3f411051571f8eec93e7498C24f6ef15f6e9',\n",
       " '1bf6c92419191a088fd5a47cd5e22b3fa122b8e99',\n",
       " 'b755f80B0b0a4f1558e7a93fc84762a604ee38ad3',\n",
       " 'cac0349ed6d4681dd522aa9cded0d82f6b5f30f84',\n",
       " '8ef9c059484bc6a8695a51c00b2a08c5ec7d13c17',\n",
       " '7c545ef5d6454103e4eaf110b680983d83984b01e',\n",
       " '17293e36f0a84f588f86a8d1a64a80ff0f94ffbca',\n",
       " 'b3d0e8697031116d0b0826a0070d009c355516d3f',\n",
       " '8e32de6D2cb4dedfe708483d09310424fdcea2070',\n",
       " 'f6da7fed26cd7ebE00ebf374037d93de60d8136d9',\n",
       " '15af6050b53284d93a7b3b750934d4242A480de58',\n",
       " 'b9885e5f118762d57ca7ea39dd19ee6a6dc5264e1',\n",
       " 'c5737fc988c5301bfd1d00b44feb1542fef9ae1e6',\n",
       " '59a49278433f819705694941933729f17da996dBf',\n",
       " '98da944fcbbdc02a9421c49f263c2c84de213bc79',\n",
       " 'dba770d83a05Eacb849fa5a960fb016e1be0bfc1e',\n",
       " '0587e8da9655f49f1935a222b7ca7ee681c2cf625',\n",
       " '217fa57816034d1bd81013fe9c9eeb4704a9046e2',\n",
       " '47f219869b45d69591e0c01745515c46ae8222e65',\n",
       " 'e4270378012ef2aeb7a2281809b2c8929a68d6d25',\n",
       " '5932b63024953dff4662dbb3680f31b6992f805b1',\n",
       " '40d3d2a1cade05d9f7a77394bc27c3a645837c836',\n",
       " 'ba222cef57c5e3801026d3c4f97e8871adec8cf76',\n",
       " 'a3b09caec6edcfeb2f3ef321b62a5100a6c2f23f9',\n",
       " '45657560d9031fCfce2f7ee79dea04646e43bf433',\n",
       " 'cecb78762289592a2e132e2b195c0a12f60b91cb0',\n",
       " 'f6a03048037c851377978ded5daFd74a1aac2b282',\n",
       " '99d17e88023ce24fa570236c94f928e55387d2322',\n",
       " '6b1f7238b83e054eb48a9df8918e8ecb5fbd127d4',\n",
       " '69b325f5F71cda85d9c60b66515a6beae00c70769',\n",
       " '15827ac0908586891fabb695eede2c2ad33eb1e56',\n",
       " '35e51b28e0e991d775f38ef8005bbbda0fdc569a1',\n",
       " 'a7abe16d5197f7d2257b81724a241c4b0b3f35bed',\n",
       " 'c12d68e09c44615ffe1a09d41736071ca0eAa7b75',\n",
       " '64eac038ee1d22d8dd4828c03b8266efb087801f1',\n",
       " 'a9d2aaf8bd5d30aaf4913e80c16dcecc0929aaec5',\n",
       " 'ae1142bd7444aebb5eb5bb7120fb2454815ccc2d5',\n",
       " 'aea509bded3e7a9daa34a8caE1ae001703223eaa4',\n",
       " 'b6393d1ec3e4ccbd1a98e80867f9fa8219eb0735b',\n",
       " '8abdf4e30d70c86377ba6074791ed37db854be0c8',\n",
       " '48efa8dbccb481e6d84eebf264db45e4bf84e3645',\n",
       " '85f810a528337702becf5681be66efb59e667c488',\n",
       " '5848a2bf028751cc76871cb374f033826855854a8',\n",
       " 'b6c6445f7bfc3449611edf2c2e3f2807ab88d71ef',\n",
       " 'fb8dc0d98d40f9472b833ef4b98e1715b3e87a005',\n",
       " '935477f9f760d6b1aec1f180e4c51efa09b83f118',\n",
       " '5e0A6184d7a19eb82efb4b500dc83cd839817f2c5',\n",
       " 'e4d9f9bbA17f7045b6665c00c19983178f73c6a7b',\n",
       " '3d7a7915a4eaf251414064d4e701fab7657b22915',\n",
       " 'da90bfde924276f2a9cdF2c32cc6af9bcab4146ca',\n",
       " 'cda6c55132b726803e5c1a725a210d8726c933134',\n",
       " '5fb0596c2f00f4163fb3dfed98852066b5c717eb6',\n",
       " '93632faa8f1798f3e6c470af793592680fbb9005a',\n",
       " 'aa58633bacff72dde7e52bcaec1e463f72f112719',\n",
       " 'ab8bae1677002c6660ae9b27e4812eac443b4abe3',\n",
       " 'ba9ff9b1075a24Ccf96298502ec8c47326f143687',\n",
       " '4d390b358decf094eaff0eab20C7076f214781e50',\n",
       " 'c5aefb9dac718c12a3fa2a0a794e399ca52739a8a',\n",
       " '5a2065fbbaf6d8b1930657000ceb8816484df9e7b',\n",
       " '4f47df0229a40Dc74996494db57a39e495a7f81fe',\n",
       " '46ac3d1866c0728c2b6bfeaef224d7Dcdc1f51ecd',\n",
       " '81F9d667c9a97876c8c1f28e224ea839045ddca7c',\n",
       " 'b1d74d723feb344ea57a526d389dc6771fe8251d1',\n",
       " '7946d265b16b5b1d6c5ac22cd65cefd103340aa0f',\n",
       " '6024c5857be695602ba3f5bd42169ea3a883f59c9',\n",
       " 'b68ffd8139695a3b43d28c930a3c2126a1683359c',\n",
       " '7b6c08d34c95711f2d784104db7ab2f2d7aad2538',\n",
       " 'd77d1d8741c5d998729c8a4377854dfa5b0d5f40d',\n",
       " '8ad5aed903e6e7015fd1488453880437d2Bec4ae0',\n",
       " 'e7a475ed5a7e173c80672d9259a81097d97573921',\n",
       " 'f526de9f72816d8f978659393c20356993abbe5df',\n",
       " '9db1baccfd3d5bea4b8b9A5b6f93668a91ba7714a',\n",
       " 'f525e9bf12db51f9eeaf09cd4add61e94b240e264',\n",
       " '33c9927aef9bdb2d47a7c780c5b990bee62b8e7f6',\n",
       " '5a128523e57687a2995ca147d223002e937978812',\n",
       " '5fbda7ffda3b5cf11f27714f0dea5d5d72a079e5e',\n",
       " '489e6d09808886f108c7538cb8354d9ff316390ee',\n",
       " '430a538cbb2e6be0a32c7b8d2e4ba99a7aae06f01',\n",
       " 'c364ad0ca71b27021906c8f3203f429accb0bc559',\n",
       " 'f370239f4a0d3e90da8853d6f24c7ee8127f9827f',\n",
       " 'fb17bc7ee057f90d1034f49c21e4e227578a63c50',\n",
       " 'ea3b608c1e733ab0b52c4eb5ceb4af742f075be7d',\n",
       " '4c0357bf0dbc90db79e91d51a3f74ce7d12ac1fd8',\n",
       " 'ea0639fe2bf9ec24ca4410ab90736c0657d9e92d0',\n",
       " 'ba4dc13b512fc38ac93f506e200bd219dc038ff6a',\n",
       " '217446e61601122b70fd3b3adb78dd9b929f56540',\n",
       " '4a1eb8130c4c98091354385c548ec034a81db26a2',\n",
       " 'db4Eea7e101a7b76d58745d9327fac9bc36a34fd5',\n",
       " '4799d454B305ff81ab6566a39ab8988c342d37fa6',\n",
       " '45862884dd3cbce00e3afc1c2f33a99de9270dc7a',\n",
       " '8d73f90ff0dc6c5f63cc51acadc9a7b6e69b5c5db',\n",
       " '3a0a8103b053a3f1160898ce2ca95730573f5f8a5',\n",
       " 'eea992e32571e9db244709de60a314851059c4069',\n",
       " 'd28555464a9821dac70c39d78e939f55154ee1467',\n",
       " 'fdbbeffe82dbef183af9ffb404e89500d6bc0b6c3',\n",
       " '3E857e47b62c04e45b4995e72a39e1d0a0e7aac35',\n",
       " '48a3cfa64d8beb6bfcffa72b7c133416aff89ce98',\n",
       " 'e5272cb18e87083545a7cda7ad979a2472ef1cc80',\n",
       " '65bca0a6d41c3de26e278e5e67965ff11ac8e4b12',\n",
       " '2f51afeb86a78fac8fee8d3fc707aeCcbc50c8109',\n",
       " 'c75fa1e6c3620a4f1efedd096cad6f10fda23b408',\n",
       " '5da974d3d8b41700eb12c531F89d549b63aa7b7f7',\n",
       " '9c1aaa2e887967479826cdcfdd3d54783950986f1',\n",
       " '6c5649c951655bfe96930f896993b3273b23b7cec',\n",
       " 'e1a7db85450bd3efd97590dE7304cef16029c76e5',\n",
       " '744Cca61fee3c66226b89d287fdeffa65541f7c55',\n",
       " 'c5f392589f943825fa3ee89313c42e86bba9d65cc',\n",
       " '2ae8e702b6a0986b969635489adc52e4497b0800f',\n",
       " 'b6beac6551be7896558fd3d0a0ea3bfdb62f38b45',\n",
       " '0349565eb0a4f21d6d0bf570ff754b71ac17db0cb',\n",
       " '68d507bc9ec9c6cf614d341787fa973f9a67fD556',\n",
       " 'f4a95c5dbbf54cb95479b0800e03ffb0b641443e4',\n",
       " '40a061d7818cb18e06d87bea1c985031cace6aa47',\n",
       " '236c19787cc8233524b6180837b4ee6cfc7047c1e',\n",
       " '4473d9c833cb76bbaca61083e400d29ed66eed7b1',\n",
       " 'ed1049964da2ef7f0cd90e3fa6b6a5626a4afc0ac',\n",
       " 'f2df5440a137d745f52b5a90db3965c4fad667abf',\n",
       " '627385f035a93fa2bacfec9f87566e42054d69a04',\n",
       " '32d6cc6dfa726eec775674f105bb0dae97faba007',\n",
       " '4f9f596a15bf7486c46975143e0e7bafa3e6b5db9',\n",
       " 'b22e98289863b241654f38304fb40f1815e1297c1',\n",
       " '94207d76ebd06d7118fb8da555d6326e6c5104de1',\n",
       " 'aad7bc99158fb6174c3d824581753953f633c8658',\n",
       " '9d3229247ab973f1178E70c4ed7186959a9f619b2',\n",
       " '5a4bba213d24bb1078bcd5aca686fe2e9fFc1cf65',\n",
       " '04664bebcb495b843f19178a60473a4b75db7585a',\n",
       " '5924e86A5a621901511f501f53d47ca8119089731',\n",
       " '9d24d22efd0bc8daef5cf4952f30b58820e1ce7a0',\n",
       " '45eC751ab1e7e73d90972e58a3c03ca832bbc0d48',\n",
       " 'd3802b7f5f289c056b47e855148960B3c61d04f9a',\n",
       " 'a45a196cd76e20f92819134fbb96c005Bd4a2bf14',\n",
       " 'e0c810e82f61d9d70987b531e9ddaf5b125b9f281',\n",
       " '28c9b549417d1f3038b38E21bf82b3156a41021b5',\n",
       " 'cdcb79e5432f382373ae7e04e801d9a1b05d215bf',\n",
       " '6fa689529f87b378bc6a2f2c3fbc2226e4a2a579d',\n",
       " 'c0fce68762a26f571bac90b456ba75a2b315592e0',\n",
       " '3ba26fec0ffe8259ec6140a6bf24111c43a1fd229',\n",
       " 'ca96D22c3f3707d615eeda13f8dc7b8aff7a84810',\n",
       " '4c25b4932684a888690313d148d1b7f3892e03f52',\n",
       " 'e4A30b00591d7323daa1e829c60b0f4cbfde88c04',\n",
       " '34ef70935dadac093d80b187fdb88dae69561a927',\n",
       " '771b85faaa237aca2239185f36f65986d65d0af70',\n",
       " '379Badaa466fc5c9e86842fc1f919a56ad384f5ea',\n",
       " 'e05ad805c8cdcab7d27ee8359010fd0fc9a409c0e',\n",
       " '8edae72002a62ff52dab53bd29499366004c25587',\n",
       " '67e08725d44f2ae3364785488a0f3ab17026bf8f2',\n",
       " 'aa01e154b1bba895d57aa67777fcfe5db4a5d6de0',\n",
       " '2bfb78d6e74f3e2f1113f825e0864c53e0e454042',\n",
       " 'eaabfe838110437cbae08a2177b3dc027ff3674d8',\n",
       " '1dbe3bf6280ec55a48e3d23a5e46632ec60417347',\n",
       " 'bb42257d793ae09150aa32a2d972a9332383a1b43',\n",
       " '9abf3cc15304e812d4dcb46b24e357111d3123523',\n",
       " 'd52f89e456d4bAdc69fa0a3ea21cfa81000b0198a',\n",
       " 'Ea032974e216d0f1e0a1ba6b5c37e547337acbba4',\n",
       " '588f076880524bdae3f8114edacd8c3b59861c02e',\n",
       " '262448274698812b2151e116ada45aa9ae31db057',\n",
       " '72b6fb73fc2622756010d79405d8b6bf9fa560cd2',\n",
       " 'c53f6e37c98ea5e69fd90a221174b7516cabd1da3',\n",
       " '9ae0bc8f6e236cef13e7197bb5efa3b2b18724bd9',\n",
       " 'f72eb0cbad7e1fb8426ce6082133b7160211a6d0d',\n",
       " '8cbd7edbd798fddf10dc3adc7b1a71641740c9009',\n",
       " 'b1d61dc7cD18cf1df78b0720bfc88f610721c4323',\n",
       " '00461dd05c981edde167a5947c365472141e04bb1',\n",
       " '998d90ef61393bcb5de41daBd7a9b87faa6af8431',\n",
       " '63c6915f9aa2ea05f84a3c21308c79d25d65478db',\n",
       " 'd7390919e2298ada12718fe37f94924bdf2953551',\n",
       " 'f80b2267c139d3d59d2756e0762308acf1fc69122',\n",
       " 'a5f1a74e6364346d67e25eca496f3be3b40a74725',\n",
       " '74b483B63a4a6b109ab1640dc11a366707e1c3f1d',\n",
       " '895d64f39620b74db25bcfcc3051c43bea79225b0',\n",
       " 'd91f25ba6ff8c875bf642778cf40a4ae769c7a689',\n",
       " '3b97ba5947aef402057b485d100ed2b032ccab1ad',\n",
       " 'c325c838c436de3eaaa549e2e6f2a16e419f56017',\n",
       " '1282d116f780809c2897083d4575fb2926561f169',\n",
       " 'ef88e6e2655e8c3f3d0638593cd6f5af353d909ab',\n",
       " '505a24c323e3c88fe132c4a68719ae1a5de7f7879',\n",
       " '6e19ca5cd8dca2509d202d56f17f0190009160dc0',\n",
       " 'ed1D6b7424432ed327adb1e62d5ff5830bffe6f65',\n",
       " 'e82e1b6ddfe57266dc072c92cb16e5aa80d8a57c4',\n",
       " '689d64c5cd891700521325fe487667d55ed6b670b',\n",
       " '33e7380eaefc302f909efd37accf286de9c772882',\n",
       " '96d9449148b3549d5e994b2b8a7584a8655261181',\n",
       " 'a503bf9f2a4e75aaf2f4db0d121849aee96db3bc6',\n",
       " '2c3ddf585084222c6e9d4cd601cf01ecd258cb7c2',\n",
       " '10989cf0dbfacc6497955bc75533edf31e8a0e772',\n",
       " 'adb950bd92f9c62c3f575097eab4a35e63ca2ead0',\n",
       " '16a34859dDcb87cb93a86825bca715c2a97e13880',\n",
       " 'cb9a3764b2564d526f510d193c36a5698ee63b9f0',\n",
       " 'f324dd7ca803b3a44e2807513cafb0e119cf855a5',\n",
       " 'b837c3c07301a68b4de31fcc626ee956e7f7ea4d2',\n",
       " '62f4d173d3ba4236f7dc6cab66908c2af854b996f',\n",
       " '04ab846fb169a0dbe53235b1d3e4d9a7a24132af9',\n",
       " 'a2f9458281965fbf1249d2bd769c18caec07497e1',\n",
       " '6370efa1615ef7271f1d3979903d0542a4b3904e2',\n",
       " '3ba7f75f8f39bea7064ecc3ec1d95f6e0fc8e53B1',\n",
       " '71aaaa56d73d70d6c985c83148078350a8de74a18',\n",
       " '332dc60810103a9d8410d0db04ade6a953951f714',\n",
       " 'a2d66e70c52852a754730c8f66532da4deb9071d9',\n",
       " 'b0332289cb5c2a6e3ac4e3b93c3227e888ce868b0',\n",
       " '30d5A3bf300d40ad8c849ab0db0aef310eb7a7cb4',\n",
       " '5c565ec2cc8cb4aB39978091818d792831a04db45',\n",
       " '77c3aa5a9610946882d84cc100b2148a042ffba9c',\n",
       " 'f04d60150f30bb81f204f688718b101d7a3c83119',\n",
       " '66ead819c5166c3a2c59ad961e4453bd138b58ce5',\n",
       " 'aac6df6596d551a53a2b05baa3adfa5fc2e0f386a',\n",
       " '64214f2596ea6307bc06251970d8b20a25621930b',\n",
       " '13589ee0c1Ddd83d5cbe5fbad2d7f7ca768fe3e32',\n",
       " '985483798ad73cd1eb69d65cab59e1fcf7ea9d7b3',\n",
       " '793c501967fc39d8f7311cce875c264195181a629',\n",
       " '09c4d7cc24c99e3f84cc36c7aa56f727cfc6f532a',\n",
       " '55b289a4b5eb00a6473d39aeE4223fbf14b82a27a',\n",
       " '1890b086f4a7321d3a1b832abc322b3e3236f17a5',\n",
       " 'fb35c1ebc431168836b2a0ca2684b025d28c3afc8',\n",
       " 'dcc11259674c62f1f8cd28759e8bcd85361a333b3',\n",
       " '093c4f3e92d89ce49b3f60f2aebe6d0f4599ade3f',\n",
       " '8b5a3880a826cc0051ef44f001d661ab825aa2f05',\n",
       " '02049c8003b0c4ef4f7524c0cb8add4a2fe78bc8f',\n",
       " '69029fb8e880f73b62d19f0d8a70987c3f3ebe2f0',\n",
       " '85194760776745fc92571c5eecc207989f4f0bc78',\n",
       " '85b28c218b22760402a1ef72ba0fdee86f1c8129a',\n",
       " '5707fb6711b190ca91a495519d585df1727a3afee',\n",
       " '63d63f89d6dcc5d0767ca89fbbfa9ce2e8c339991',\n",
       " '59bcc775c5c7940a3857acca53508fb3deb1c4f2d',\n",
       " '8bb19ea2fc01fc3ca0750b61686b70479aabc9ed1',\n",
       " '37d30a681c56c1eb916fe504e44d6177e24f20f87',\n",
       " '88cb8c660e40af736c96e29cd2dd2d8Eb015156e2',\n",
       " 'bdb5e926549954f5796ba9bf5e6c5c2e444383bc9',\n",
       " 'c751bdd35f9744e818bbb5e75ad8c0Ffc15a3474c',\n",
       " '8216f9bb8cd213accc1f7a913fbc0f96f3c1b1e98',\n",
       " 'a412cbccc8ceca02bf960afa14594074667e38af7',\n",
       " '7b376bbffcbac6da23b777771753804354bdda887',\n",
       " 'ec195c3383aeec41bd7591c95cf923f224af3efa9',\n",
       " '6510f3a4c4d9cc4a2bf94f9b048bdcb7a5532c141',\n",
       " '8ca185fffa7ab9b3dd686943cecf8d13c9ea516fd',\n",
       " 'af2288a4391ea4bac2caf836fbe6a611e5387d26d',\n",
       " 'd26c279ac25c96f9a31af072ce0d22972ae6f72b9',\n",
       " '3f9b2f1556146e0634272daa49e2fd38ed5756d6e',\n",
       " 'b2cc4c065aa5078d438e0c73216765B04519386bf',\n",
       " 'b2740f3facf5ff1b236f7e4770f7c8127154612d2',\n",
       " '8e483b631fa3bdca10e8b2b5f1bae9a4e0ec7907d',\n",
       " '7e190ee740d4be5d244f8fb5b50fef449d86cbb54',\n",
       " '697b8068b6433391b8e07686969ed8f37d9fbc606',\n",
       " 'bf822f9d27b882ec955b61aad972e9435cea43a3c',\n",
       " '8532be792ba7f8b6afaaf13a368dd7e7dc51476df',\n",
       " '5467ded2572c98c4a4b8c4e8f43334893204fc8da',\n",
       " '8cdf53fd4a4a88728039fbbfc8ad503ce5ee83014',\n",
       " '278850e91efe7350b4d9b9bb69041f40f5297f93b',\n",
       " 'ae1bedb5d3c406c0f3f68734894a6f73aa3e89ec7',\n",
       " 'b1965b853586bab08b6bcb3573c0964314ce3a340',\n",
       " '86894e1b1038a7661954a4d1e389be81087c35e02',\n",
       " '3d9a5ccd0661841a14d34670085f91d56d44681f8',\n",
       " '61a9cdc87c724723da52d095c0ff073482a4367b8',\n",
       " '28e24786c3d318a7d537Bd80022724422f8777628',\n",
       " '4b90448f6bfda38107c7ea2460265120d5325989a',\n",
       " '6b5557721a0a5dfeC1d3f99356d6290c0791faa8b',\n",
       " 'acd5f4b945e17ca9882c8500f417aa70e63060f88',\n",
       " '005b95d2520C8621171566f5803437b0c443778e1',\n",
       " 'c87c1a4cd1b4f5bbf031867dce85738fe74f6c982',\n",
       " 'e0d8825338112c35e1ebdba46ed093b5702344205',\n",
       " 'ad1fe6fc8b9664f93976E6c405714386079a70f90',\n",
       " 'b2e80c38d0ac2d8979ef3444084c8488359742f77',\n",
       " 'c9cd4768604740ae01d18bcb9d30b63e08fc9051e',\n",
       " '41d68524974e0b76f8a3b8212f81f8895f185038c',\n",
       " '6c55c80711e015fdeb2a54c2918d09dae0b2d2a45',\n",
       " '84e7be4cf5678bf35fd8ef3e58565c00ff5410451',\n",
       " 'fb2d91287851dCd9f107c40b05b0497c2aa2d4832',\n",
       " 'a203d7fa70b66bfe5ebd0d696f2fb8255924689dc',\n",
       " '61020761876583278c057cf7a65b666ca4e75063b',\n",
       " '0eea26b783b227613a7eac74733e08955938ae26d',\n",
       " '20b8dfa48eea5dc261ca3378a56cf028daa29e2a4',\n",
       " '1f6e6ead42a5cb0f16e19bde5d5adafef635f3a3e',\n",
       " '4595081eab5fb8dfcbb5c9fb6b3860acd2d860384',\n",
       " '15e76ccf1e5dbd1c410dccaaadbe5567def7271e9',\n",
       " '073abb93dcd12b20f5f394ecedf6909b6fb274e03',\n",
       " '8b19f8a0754fb7fad5f9f603a3f3c47516c35628d',\n",
       " '469724bd0406c9bcecd765b22a31dd8d336753d99',\n",
       " '1d5c7ecd532e2582f2b897aa882d33ffc6a318f29',\n",
       " '5e525a9f8b0a33db2f17b686ef758e23c6eb80c4e',\n",
       " 'cd6efc87851651e70843ceee5bfc901dd7c90f740',\n",
       " 'bcfae5a518f991950f16a4a8254cc9226b31b5d48',\n",
       " '29d216532b20fd7388a31e93276ea042a2780cFad',\n",
       " '9ebe5c80726c4b9b5f3dbc36fe58e7512d6d84936',\n",
       " 'c8a0271fd87ff68f7c480227be3d1c08243f338e1',\n",
       " 'b10f6907d317bc760ed80c070390588e1f6cd2dbe',\n",
       " '6f9a01860b6793eE3fa117904206dccc9db3f01c7',\n",
       " '3a01fe4c7c84d21888b98504143183903b5e5b8ca',\n",
       " '825d6553b7fdd98ed49859ac6e82c5900ed3b5772',\n",
       " '662c5659b9b41baf1471ed6dcbaCdf5dd310414d7',\n",
       " 'aa1463befbb2ca10f36d956be26cA22203cc11cfd',\n",
       " '29806cdca4c826bc660b79536609e37261a32fce7',\n",
       " '7f2f1a006d89c8d1637f0f0ee35b9432cfd7092db',\n",
       " '1ce7bd3b92a099a8c4d7b3fa415478c4580e6810b',\n",
       " '4bfeebb9e5b284d1eb960df80742401ca4f6ac39a',\n",
       " '913a4ce4b59d7b86877eb3abe550f2db9e189e02e',\n",
       " 'b9f945e8999f0f8de42cffcc0c0f773cf897cbeb8',\n",
       " 'c4Fa7e8dd45eb874d97eead68b5c0c20a3f376745',\n",
       " 'ed51748b98e3Aa6b11af3d7f93767ee02e7c9292e',\n",
       " '1abd0496c3845de0e467b34cf6a322ce75f7c072f',\n",
       " 'e3c3ff0bbf6be9ffcda7e4fe98dad32b437b64e76',\n",
       " '51e4ef97b3b1dbe46660b5f674e69800c9fb529a2',\n",
       " '7c9da8974854870b313026f9b6273b7f03b0d8fa7',\n",
       " 'eae7cf848bc0af90eb75F5b77dd7049384f1e9858',\n",
       " '734e83f9e52e725242f79d6734408f67e18b90691',\n",
       " '98053b1bf65defaa11f88289570d871b58b46ea62',\n",
       " 'Cbf2843efa31ea18474e5b37af5af0b551b47abf7',\n",
       " 'cb51d995b9793acce82ede8d31094189214af8b02',\n",
       " 'cabe8dbcf0b910bfb1a21e6134b2f6a1a244958b0',\n",
       " '04afc344f00d43ec09b233a63f314d24f451114ef',\n",
       " '029fd200642365a45173b6c43ea98c9c22141a46f',\n",
       " '4b8bd35da56a8b6545e3896929f03300d5e5e717d',\n",
       " '4119e2d2e10eb566D6cb7102479872814e6e93a92',\n",
       " '0de89af99d899367f9c4c4100635e21ed603cd9ca',\n",
       " '8845b1617a919bf08b565f120e89e23373e2a5049',\n",
       " 'cf7c05ff812a78a5c498fd4ebcb7256be2673A478',\n",
       " '0ef11cc42cb4f6620f476674047dfec40439604c5',\n",
       " '27bd952e077aa7c041be2dc2614c2e5be85e49eeb',\n",
       " '8c9b2F7700bb72c139e76cbd87f288ca73b83e4d0',\n",
       " 'e094dbb2b774beA8a22c0d9adce1f660a4d17add1',\n",
       " 'b2595af074a6083756afb32dd93cc10b9a04F43bd',\n",
       " '636c6e6f47293efbe299b438b0adfcd231D56e43e',\n",
       " '87b8db2075962fa01276b3Df25a5a8330c99934f2',\n",
       " 'f0badaa7fd7Ff00ef28259ffdc22162824898500d',\n",
       " '4e26d73a6040c5e7605d1721a1cc9c18bfb357db2',\n",
       " '5eca4dd39e087c6a55fbfc09dbba6e75ba0595e62',\n",
       " '9f623af715960135c2d8a0448945f93dc6b368204',\n",
       " '3307040868eeed136a839ac8c40eba0b050b3ff20',\n",
       " '4e3d879b32ef51538d35aa8348b6a0d27d8bdfa2d',\n",
       " '715dafc73bEa7946cbb06ad0e0b5ed4abb1e7d490',\n",
       " '3917059f7ce46a1754eb60a7b5aa0d28018ccb1a4',\n",
       " '22e9622bf4fcba83e65e4b921319185b5c233e257',\n",
       " '80ab2eca817d3ffcabc7324395a6c4df29af60699',\n",
       " 'b6f85a864e015e3f78f3debb2cc86c599ebda8676',\n",
       " 'aca5957cdda7dd0809f8331d23026134cbeb9b4b3',\n",
       " '5c91e01f86051512beac02a7a05a50f9802481455',\n",
       " 'c9e89f3eeeb8a0d123857d2d429073e2342f6212d',\n",
       " 'a8a199fC90e2d2a46f6283337aaaa07ff113610cd',\n",
       " '9d6819b8ba53623825269b0473ae02bd8d3cda174',\n",
       " '41909b21137c2a8f7bd0966d8f3a6c111a51338eb',\n",
       " '6a9774285cba6ad7e1310B084f2f9cdcf308af2db',\n",
       " '36071185f23669d073715d2159793007304bb160f',\n",
       " '546ad4c6ffdf0d2e390f80fb10102384b256a41d4',\n",
       " '049db6b45a8f8ac592dc357c46b0da6d34bf0769b',\n",
       " '44b693b6cc686ea687138353094cb65339f43cfb6',\n",
       " '81c6612452f8a53b99501c1c44e23b94a5ae25b6a',\n",
       " '5f18448ab56f1e47726d9472987c614204eb20563',\n",
       " '674b789c30c1C57bd268dced0389b7dbfee3ab033',\n",
       " '9d6a494b920721ac854c42956d4e1389b8e34998a',\n",
       " '5da2dba2951c3fb77090a7fa8911f6e56e5d404f3',\n",
       " '37a5a9488bd38a9a9d7429d05d49618cf12a130A5',\n",
       " '6eee22f9887435cbf06304461f5beb9d67aeca9b3',\n",
       " '9fcc7eebaDe6b6d5656a50cece36a96ded1ec5c40',\n",
       " '439119511663bf83e1148920e70547E2e6322e007',\n",
       " '1940275fc1f6aef5cf205a9fcb6358cc0035ff404',\n",
       " '9bA3465e23b0e9b5749f2a7c447b0ec2d7cb4d122',\n",
       " '636fccbd5580b0c9a9560bdc1d63f8395422083e2',\n",
       " 'd9025aa2f51692d201eeed0bd007d4b22df47f2f8',\n",
       " '1826f1c5584486ec5b7e74ef19503af2515b1e73f',\n",
       " 'e2f8c813a6a45d6485b8717dc3d526204a127b763',\n",
       " '6e501b610375cadf5bf3c240d5e37b03852ea415e',\n",
       " 'e894A1bad0ae645f5b965a3d4a083c40eebfc1254',\n",
       " 'bf7785181f34fe9afb8d13e99ed14327702ae0b2e',\n",
       " 'cdec8115b49eb79a177edfa0eb251405147ac0b66',\n",
       " '1d702a2ea2854865aec72b3f85cf9de295c37f43d',\n",
       " '0ff661021d6ab6d0c546523635a0cfd39e3e8b6a9',\n",
       " '4c31df678d0d524cbe8313544b360222c064cd873',\n",
       " 'c1419e8b4832cb41f7ef55f20f8ee51fb246ba36e',\n",
       " '2af7dC4ce636cd7ddb8108135bede308691c60b4f',\n",
       " 'd88f9237669bfb8f9b595acd8ad9f4af1d35a6b83',\n",
       " 'c22471cc6f2b9ad346423fabe3113a3bb2ef9cc66',\n",
       " '4d2e5ef7da0862944e9a09dffb79c605c9d7e8fe5',\n",
       " 'cb81eee8cac4af929c10a649424ef5cdf779b544d',\n",
       " '6c8e68a15797c8450ccb7806e802caed4e980b8a7',\n",
       " 'ae5f7f1d306fea82Cc43cd2541d5eb3150fe96259',\n",
       " '4f1d3c30d00ff453efe7323e6a8e3a287da915d75',\n",
       " '572dd4e5a369f75edce81eb83aef44D1279c045a7',\n",
       " 'be8d1a1d077fae189fd6797a72b202bc9ca6a55fd',\n",
       " '64df72da0b7171a6f4e423dead8f7c8fc254910c3',\n",
       " 'c573cc545b56cc9ad8a687a21e0d11fd5fcaf6db0',\n",
       " '54f29465d5c981cc3469c8070a088cc282daaaa80',\n",
       " 'ac2a30d24ac27b46fbb0c001ba8b6e44d759bedf8',\n",
       " '12ac5ef4c09cd1d823d0963d0540e3b314c18426e',\n",
       " '6D4f009d7817650bc7e3e2148f6bb63d753a4b76e',\n",
       " '6580b485ebbe07ef1e3a3c735ea4a8ef5ae5820e3',\n",
       " '9d7d267754db3c6f2545152c48329d9cf20a510a8',\n",
       " 'fb436f68cf31c13771cc0bca64466e78a9be6a325',\n",
       " 'e72922481a0431d01949b06a0d18ec627fa4f0383',\n",
       " '1ef7d7f50cfededb7ba1cc6659169d1fe4c6cdeff',\n",
       " '28307fD56aec2b826e0f79e39e6637b0d63e7c9e4',\n",
       " '1b895f9858e2b2924974b48b4f46581c49bac6939',\n",
       " 'fbd350c9cea045524816243d3ebda9b80a4ca6093',\n",
       " '6ba119f341b10e04a0ccafc4bc157ba1ed4a471e9',\n",
       " '0071a3b818ed06d3865a24fdb31d4147c67fabfc5',\n",
       " '15741d47daabdb3afd77fa4f4d4646f30bde8c276',\n",
       " 'dd920bfda41d7297204fa9506926a28ef86d42a14',\n",
       " 'c38d2bb322609f92d82aaec1014fc1ee5041edc27',\n",
       " '520ac0cb44af270d7efbeaaa244d23e235cfb1e53',\n",
       " '0f1426886f020bcfcc95ba2816ceb5f9838f009b5',\n",
       " '0f7a9041fdb80fc2cb093c914c6f00bba74709d2d',\n",
       " '30de0757a785dde851b23d7df69fe232af58f7002',\n",
       " '4a846c03e03941f22b8a085af9af160a58771abe5',\n",
       " 'be4835d06b6758d77af95fbe73aa41e7d13c5eaa7',\n",
       " '242c7dbc51bf9a215bf7436246fece3ceae4b7ed9',\n",
       " 'e94f6078adaf3c385a365ddea58276215390aded8',\n",
       " 'b3b61963f6c45a3c9ffec21a9423d0e3592af4217',\n",
       " '5206cc6594242d2b42160373f4ba2be8b98078fd0',\n",
       " '268ced8A36d3589c328cd40708edd0c1daf7c1fa5',\n",
       " '26ef21359d1fad9eabcd71441a5363096aaf4a595',\n",
       " 'b6f363ec4903f2ecf7ec41d9a8625aafab2c827e3',\n",
       " '0f7bac1a22f81533cc70d488e8668b5887d690ebe',\n",
       " '06a0c29dd21f4bca07a86b188f7267d0978f88C7d',\n",
       " '29099d32a6a7Ca64accaed9e4a305c60f3b0577c4',\n",
       " '06c73ed61aa8e89f0f9764dafcd10661c3011f25f',\n",
       " '0e9cfe0a25ef3e40961e1c11132ebab9b1673c61f',\n",
       " '00a2b881ddba2fbece1d2853bc8484072c0ad795b',\n",
       " 'ba6f1ece17570b1Cd8ceaf585fad74f5ec33eee32',\n",
       " '385ec6Ff6fb07367820c00a7590c8fb060070fc13',\n",
       " 'bad2bdaa319530a2a4d12350d725973ad0aaa0ce1',\n",
       " '24109f49b992870524d5bccd65c3aa2a59a90a7b9',\n",
       " '0fd1a0b7D9329502b94b06af6eca3905082a37ceb',\n",
       " 'aa7d7bede0c0d305846d1cd6174d753D1dc23803c',\n",
       " 'e90a3496a92f64043dbf5a7e82a85be745e54112d',\n",
       " '02b8c7d0301b252ee6cebe72e68931cfd16df3d32',\n",
       " '3914b7e2f3573F31156f0ee0c96334b567b5ddd0d',\n",
       " 'df754339951c239216156d9d6d100fe237ec35401',\n",
       " '4c67198ca75111e8cf2ac94b148953c8349df2cc8',\n",
       " '348e5fa6dbd18740ef57007b815c0c440ca50f1e7',\n",
       " '20a1af15ffce3cfc136c37d30b60dcae04f39144d',\n",
       " '53032cb69b137514565480d2d3d59fc21385ffcfe',\n",
       " 'f866c59381d5fa3326d52dc15e2847dc8bdafb39e',\n",
       " '42ac782e1e30ea7e58b77264fe02ab25928165eea',\n",
       " '288a6e0db911a20fdab3fd9a06f9d838dbdc89aaa',\n",
       " '9b952908110a098d82434bd5b398ddad546c445D3',\n",
       " '299113893d9046626bda0e76a9ddf58efd28ef81b',\n",
       " ...]"
      ]
     },
     "execution_count": 85,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "test_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Ngrams & Call Counts/Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# model = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "model = LinearSVC(random_state=0)\n",
    "\n",
    "Cs=[0.01, 0.1, 1.0, 10.0, 100.0] # default = 1\n",
    "# Cs=[0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0] # default = 1\n",
    "# Cs=[50, 60, 70, 80, 90, 100, 110, 120, 130, 140]\n",
    "loss = ['squared_hinge', 'hinge'] # default=’squared_hinge’; 'hinge' is another option but cannot be combined with l1 penalty\n",
    "# penalty = ['l1', 'l2'] # default=’l2’\n",
    "\"\"\"\n",
    "multi_class (default=’ovr’)\n",
    "Determines the multi-class strategy if y contains more than two classes. \"ovr\" trains n_classes one-vs-rest \n",
    "classifiers, while \"crammer_singer\" optimizes a joint objective over all classes. While crammer_singer \n",
    "is interesting from a theoretical perspective as it is consistent, it is seldom used in practice as it rarely \n",
    "leads to better accuracy and is more expensive to compute. If \"crammer_singer\" is chosen, the options loss, penalty \n",
    "and dual will be ignored.\n",
    "\"\"\"\n",
    "# cross-validation on training set to identify optimal parameters\n",
    "model = p2.cv_optimize(model, {'C': Cs, 'loss': loss}, ngcp_X_train, ngcp_Y_train)\n",
    "# 'penalty': penalty, 'loss': loss\n",
    "\n",
    "\n",
    "# fit model on training set with optimal parameters\n",
    "# check out-of-sample performance using validation set\n",
    "model = p2.fit_model(model, ngcp_X_train, ngcp_Y_train, test_x=ngcp_X_valid, test_y=ngcp_Y_valid, \n",
    "                     title='LinearSVC ngrams and call counts/percentages', tracker=tracker)\n",
    "\n",
    "print '%0.1f seconds runtime' % (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on entire training set with optimal parameters and make predictions\n",
    "model = p2.fit_model(model, ngcp_X_train_all, Y_train_all)\n",
    "\n",
    "Y_test_pred = model.predict(ngcp_X_test)\n",
    "\n",
    "p2.write_predictions(Y_test_pred, test_ids, 'predictions/svc_callcountpercentage_ngram.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest Features provided': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89416846652267823],\n",
       " 'Random Forest ngram 150 trees': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89308855291576672],\n",
       " 'Random Forest ngram 200 trees, 0.5 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89308855291576672],\n",
       " 'Random Forest ngram 250 trees, 0.4 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89632829373650103],\n",
       " 'Random Forest ngram 250 trees, 0.4 features, 10 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.4, max_leaf_nodes=None,\n",
       "              min_samples_leaf=10, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.91388888888888886, 0.87365010799136067],\n",
       " 'Random Forest ngram 250 trees, 0.5 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.90064794816414684],\n",
       " 'Random Forest ngram 250 trees, 0.6 features, 1 samples': [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features=0.6, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False), 0.99305555555555558, 0.89740820734341253]}"
      ]
     },
     "execution_count": 67,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try classification report, heatmap visualization of Confusion matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix\n",
    "# https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "# Plot Confusion Matrix: \n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#example-model-selection-plot-confusion-matrix-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 68,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# try with linear svc ngrams\n",
    "tracker['Random Forest ngram 250 trees, 0.5 features, 1 samples'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_Y_valid_predict = tracker['Random Forest ngram 250 trees, 0.5 features, 1 samples'][0].predict(ngrams_X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([29,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 0, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0]),\n",
       " array([ 0,  0, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 0,  0,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 0,  0,  0,  0, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 0,  0,  0,  0,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 0,  0,  0,  0,  0,  0, 17,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0, 14,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  0,   0,   0,   0,   0,   0,   0,   0, 471,   0,   0,   1,   1,\n",
       "          0,   0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0]),\n",
       " array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 168,   0,   0,\n",
       "          0,   0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 5, 0, 0, 0]),\n",
       " array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 122,\n",
       "          0,   0]),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 15,  0]),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 14])]"
      ]
     },
     "execution_count": 70,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# confusion matrix \n",
    "svm_ngram_cm = confusion_matrix(ngrams_Y_valid, ngrams_Y_valid_predict)\n",
    "list(svm_ngram_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(p2.MALWARE_CLASSES))\n",
    "    plt.xticks(tick_marks, p2.MALWARE_CLASSES, rotation=45)\n",
    "    plt.yticks(tick_marks, p2.MALWARE_CLASSES)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc4AAAGQCAYAAAAnYoA3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XlcVPX++PHXDAMqbggoKqTmlqZiKm5pLrgCIY6hlomJ\n3cJvmkuaClaYXrVr7mKK3iyXsjQERbEU3KrrhtZ1Ca+pXRcURBEFEXCY+f3Bj3Mj2QaZYYD3k8c8\nHjPnfM7nvM9YvPl8zud8PiqDwWBACCGEEMWiLusAhBBCiPJEEqcQQghhBEmcQgghhBEkcQohhBBG\nkMQphBBCGEESpxBCCGEESZxClFBmZibjx4/Hzc2NKVOmlLieyMhI3nzzzVKMrOzExsbi4eFR1mEI\nYVIqeY5TVHSRkZF8+eWXXLlyhRo1atC6dWsCAgLo1KnTU9W7c+dOvvrqK7799ltUKlUpRWu5WrVq\nxf79+3nmmWfKOhQhypSmrAMQwpS++OIL/vnPf/Lxxx/Ts2dPrK2t+emnnzh48OBTJ86bN2/SpEmT\nSpE0gSKvMzs7GysrKzNFI0TZka5aUWGlpaWxcuVKgoOD6d+/P1WrVsXKyorevXszffp0ALKyspg/\nfz4vvfQSvXr1YsGCBTx+/BiAEydO0Lt3b7744gtefPFFXnrpJcLDwwFYtWoVq1evJioqio4dOxIW\nFkZISAjvv/++cv74+HhatWqFXq8HYMeOHfTv35+OHTvSv39/du/eDUB4eDijRo1Sjjt9+jS+vr50\n7tyZ4cOH88svvyj7/Pz8WLFiBa+99hodO3bkzTffJCUlJd/rz43/n//8pxJ/dHQ0hw8fZtCgQXTt\n2pXQ0FCl/JkzZ3j11Vfp3LkzL730EvPmzUOn0wEwevRoDAYDQ4YMoWPHjuzdu1epf/369fTs2ZOg\noCBlG8D169fp2rUrcXFxACQmJtK9e3dOnjz5FP+qQlgAgxAV1JEjRwxt2rQxZGdnF1hm+fLlhpEj\nRxqSk5MNycnJhpEjRxpWrFhhMBgMhuPHjxuef/55w6pVqww6nc5w6NAhQ/v27Q0PHjwwGAwGw6pV\nqwzvv/++UtdfP9+4ccPQqlUrQ3Z2tiE9Pd3QsWNHw3//+1+DwWAwJCUlGS5dumQwGAyGHTt2GEaN\nGmUwGAyGlJQUQ+fOnQ27du0yZGdnG3bv3m3o3LmzISUlxWAwGAyjR482DBgwwHD16lVDZmamYfTo\n0YYlS5bke2258X/22WcGnU5n2LZtm6Fbt26GadOmGdLT0w2///67wdXV1XDjxg2DwWAwnDt3zvDv\nf//boNfrDfHx8QZPT0/Dxo0blfqee+45w7Vr156of8mSJYasrCxDZmam4fjx44bevXsrZbZt22bw\n8vIyPHr0yDBu3DjDokWLivhXE8LySYtTVFgpKSnY2dmhVhf8n/nu3buZMGECderUoU6dOkycOJGd\nO3cq+62trXnnnXeUlqqtrS1//PFHieKxsrLi4sWLZGZm4ujoSLNmzZ4oc+jQIZo0aYK3tzdqtRov\nLy+aNm3KwYMHlTLDhg2jUaNG2NjY4OHhobTo8mNtbc348eOxsrLC09OTe/fu8cYbb1CtWjWaN29O\ns2bNuHDhAgBt2rTB1dUVlUpFw4YNGTFiRJGtQ7Vazbvvvou1tTU2NjZP7B8+fDiNGjVi+PDh3Llz\n56kGUQlhKSRxigrLzs6OlJQUpas0P7dv36Zhw4bK54YNG3L79u08dfw58VatWpWHDx8aHUu1atVY\ntmwZW7dupWfPnowfP54rV64UGU9uTImJicpnR0fHPPWmp6cXeF47Ozvl3mTVqlUBcHBwyHM9ucf/\n97//Zfz48fTs2RM3NzeWL1/OvXv3Cr0ue3t7rK2tCy0zfPhwLl26xOjRo4ssK0R5IIlTVFgdOnTA\n2tqa6OjoAss4OTkRHx+vfL558yb16tUr0fmqVatGRkaG8jkpKSnP/h49erBhwwZ+/vlnnn32WT76\n6KMn6qhXr16eeHJjcnJyKlFMxpgzZw5NmzZl//79xMbGMmXKFAxFDLovasBQeno6CxYswNfXl5CQ\nEB48eFCaIQtRJiRxigqrRo0aTJo0iblz5xIdHU1GRgY6nY7Dhw+zePFiADw9PVmzZg3JyckkJyfz\n2Wef4ePjU6LztW7dmpMnT3Lr1i1SU1NZt26dsu/u3bvExMTw6NEjNBoNtra2+Sad3r17c/XqVfbs\n2UN2djZRUVFcuXKFvn37luxLMMLDhw+pUaMG1apV4/Lly2zdujXPfkdHR65fv25UnX//+99xdXVl\n3rx59O7dO98/FoQobyRxigrN39+fWbNmsWbNGrp3706fPn3YunUr/fv3B+Cdd96hbdu2DBkyBB8f\nH9q2bcv48eMLrK+wFtaLL76Ip6cnQ4YMwdfXN0+y0+v1fPnll/Tq1Ytu3bpx8uRJ5syZ80QddnZ2\nrF27ls8//5xu3brx+eefExoaSu3atYs8f3H89fg/f545cyaRkZF07NiR4OBgvLy88pR99913mTFj\nBl26dOH7778v8lwxMTH8/PPPBAcHAzBr1izi4uKU0cRClFcyAYIQQghhBGlxCiGEEEaQxCmEEEIY\nQabcKwUZGRmcO3eOunXrypRjQohyJzs7m6SkJNq2bas8tmRKKSkppKWllejYGjVqYGdnV8oRGUcS\nZyk4d+4cr7/+elmHIYQQT+Wrr77Czc3NpOdISUnBrWsPrNCV6PjatWuzb9++Mk2ekjhLQd26dQH4\n7J+bqOdUv1TqtK0iLVchhHkkJiTgP+Z15XeZKaWlpWGFjsQqbuhUxrVuNYYMuB9LWlqaJM7yLrd7\ntp5TfRo0dC6VOmtUlX8aIYR5mfNWk05tS7a6mnEH6S1jWI78dhZCCGF+KsDY55ItZAU/SZxCCCHM\nT6XOeRl7jAWwjCiEEEKIcqJcJ87o6GhatWpV4mWeCnPhwgUOHz5c6vUKIYQgp5u2JC8LUK4T5549\ne3Bzc2PPnj2lXndcXBxHjhwp9XqFEELwv65aY18WoNze40xPT+f06dNs2rSJgIAAJk6ciMFg4OOP\nP+bEiRM0aNAAKysrfH19GThwIOfPn+eTTz4hPT2dOnXq8Mknn+Do6Iifnx/t27fn+PHjpKamMn/+\nfFxdXVm5ciWZmZmcPn2at99+Gw8Pj7K+ZCGEqEBK0oK0jBZnuU2cMTExvPTSSzRu3Jg6derw22+/\ncf36dW7dukVUVBR37tzB09MTX19fdDod8+bNY82aNdSpU4eoqCiWLl3KggULgJxZM7Zv387hw4cJ\nCQnhiy++YNKkSZw/f54PPvigjK9UCCEqIJWqBIODJHE+lT179vDGG28AOWsqRkZGkp2dzeDBg4Gc\ntQO7du0KwB9//MHvv//OuHHjMBgM6PX6PIsVDxw4EIC2bdty8+ZNM1+JEEJUQiW5Z2lEeb1ez7Bh\nw6hfvz5r164lJCSEbdu24eDgAMDUqVPp1asXAKGhoYSFhWFlZcXs2bPp2bNnoXWXy8R5//59jh07\nxsWLF1GpVOj1elQqlbLG4l8ZDAZatGjBN998k+9+GxsbANRqNTpdyaaBEkIIYTk2bdpE8+bN88yJ\n6+/vj7+/f55yly9fZu/evURFRZGQkIC/vz/79u0rdO1by7jTaqTvv/8eHx8fDhw4QExMDAcPHsTZ\n2ZlatWrxww8/YDAYuHPnDidOnADg2Wef5d69e/z6668A6HQ6Ll26lG/ducuTVq9evcSTEAshhCiC\nCQcHJSQkcPjwYYYPH55ne37LT8fExODp6YlGo8HFxYXGjRtz5syZQusvl4kzKiqKAQMG5Nk2aNAg\n7t69S/369fHy8mLmzJm0adOGmjVrYm1tzYoVK1i8eDE+Pj5otVp++eUXgCf+qsj93LVrVy5duoRW\nq2Xv3r3muTAhhKgsTPg4yoIFC5gxY8YTv9+3bNmCj48Ps2fPJjU1FYDExEQaNGiglHFyciIxMbHQ\n+stlV+3GjRuf2DZ69GggZ7Stra0tKSkpjBgxgpYtWwLQqlUrtmzZ8sRxmzZtUt7XqVOHmJgYIGcG\n/u+++84U4QshhDDRzEGHDh3C0dGR1q1bc/z4cWX7qFGjmDBhAiqVimXLlvHJJ58wf/58Y6MGymni\nLExAQACpqanodDreeecd5UawEEIIC2KiwUGnT5/mwIEDHD58mMzMTB4+fMiMGTNYtGiRUmbEiBGM\nHz8eyGlh3rp1S9mXkJCAk5NToeeocIlz8+bNZR2CEEKIopjocZT33nuP9957D4ATJ06wYcMGFi1a\nRFJSkrJs2v79+5XeSHd3d6ZPn87YsWNJTEzk2rVruLq6FnqOCpc4hRBCiL/69NNPiYuLQ61W4+zs\nzNy5cwFo3rw5Hh4eeHl5odFoCA4OLnRELUjiFEIIUSZKMoWeceW7dOlCly5dAPJ01f5VQEAAAQEB\nxa5XEmcpsq1iVWoLUGc8zi6Vev6sqrX5FqkVorzL79GFp1FUK6bSUatyXsYeYwEkcQohhDC/crwe\npyROIYQQ5mfiKfdMSRKnEEII85NJ3oUQQggjlOMWp2V0GAshhBDlhLQ4hRBCmJ8MDhJCCCGMUYKu\nWqSrNo/o6GhatWrFH3/8UWTZjRs3kpmZWWQ5d3d3hgwZwpAhQ/Dz88szH6EQQogyZMJlxUzNMqIA\n9uzZg5ubG3v27Cmy7MaNG3n06FGR5VQqFZs3b2bXrl106dKFzz77rDRCFUII8bRUlGBZsbIOOodF\nJM709HROnz7N/Pnz2b17N5AzOW/u7PUA8+bNIyIigs2bN3P79m3GjBnDG2+8AcDu3bvx9vbG29ub\nxYsXK8cYDAZl9o8XXniB27dvAxAfH4+3t7dSbsOGDYSEhADg5+fH4sWLGT58OIMHD+bUqVOmvXgh\nhKiMpMX5dGJiYnjppZdo3LgxderU4bfffiuwrJ+fH/Xq1WPz5s1s3LiR27dvs2TJEjZv3szOnTs5\ne/assqbmn/3444/079+/WPFkZ2ezfft2AgMDlYQqhBBCgIUkzj179uDl5QWAp6cnkZGRRR6T25I8\ne/YsXbt2xc7ODrVajbe3N7GxsUq5MWPG0KtXL3788UflHEUZOHAgAG3btuXmzZvGXo4QQoiiGN1N\nW5LBRKZR5qNq79+/z7Fjx7h48SIqlQq9Xo9KpaJ///7o9XqlXGGDgQqbjHnz5s3UrFmT6dOns3Ll\nSmbNmoVGoym0bhsbGwDUajU6na6klyaEEKIg5fhxlDKP4vvvv8fHx4cDBw4QExPDwYMHcXZ2Rq/X\nc/nyZR4/fsyDBw84evSockyNGjVIS0sDwNXVlZMnT5KSkkJ2djZ79uxRlpGBnKSqVqsJDAwkIiKC\nBw8e4ODgQHJyMvfv3ycrK4tDhw4VGF9pr5AghBCCcn2Ps8xbnFFRUbz11lt5tg0aNIioqCg8PDx4\n+eWXcXFxoU2bNsr+ESNG8Le//Q0nJyc2btzItGnT8PPzA6Bv37707dsXyLuMT926dXn55Zf56quv\n+L//+z/eeecdfH19qV+/Pk2bNlXK/XXpH1kKSAghTCB3VK2xx1gAlUGaVE/txo0b9OvXj6h9MTg7\nu5RKnbIepxBlqzKtxxkffwPPgf2IiYnBxaV0focVJPf3ZXzTN8m2qW3UsVZZ93G+8rlZ4iyMZbR7\nhRBCiHKizLtqhRBCVELleHUUSZxCCCHMrxyPqpXEKYQQwvykxSlKmykG8jzW6YsuZARrjWX89SeE\nKVjyYJ6KQKVSGf0dW8q/iSROIYQQZpfT4DQ2cZooGCNJk0EIIUSFo9fr0Wq1ymIh9+/fZ9y4cQwa\nNIg333yT1NRUpWxoaCgDBw7Ew8ODn376qci6JXEKIYQwP1UJX8W0adMmmjVrpnxet24d3bt354cf\nfqBr166EhoYCcOnSJfbu3UtUVBTr16/n448/LvIZXkmcQgghzC73Hqexr+JISEjg8OHDDB8+XNkW\nExODVqsFQKvVEh0dDcCBAwfw9PREo9Hg4uJC48aNOXPmTKH1S+IUQghhdipKkDiL2eRcsGABM2bM\nyJNo7969i6OjI5AzBWtycjIAiYmJNGjQQCnn5OREYmJiofVL4hRCCGF2pmpxHjp0CEdHR1q3bl1o\nl+vTjNA1aeJs3bo1Wq2WoUOHotVqTbK2ZXx8PN7e3gCcOHFCuRFsivqFEEKUDlMlztOnT3PgwAH6\n9evHtGnTOH78OO+//z6Ojo7cuXMHgKSkJOzt7YGcFuatW7eU4xMSEnBycir0HCZNnNWqVSM8PJyI\niAjCw8Np2LBhnv3Z2aU/kbkQQojK67333uPQoUPExMSwdOlSunbtyqeffkrfvn3ZsWMHAOHh4fTr\n1w8Ad3d3oqKiyMrK4vr161y7dg1XV9dCz2HS5zjzayaHh4ezb98+0tPT0ev1hIaG8s477/DgwQN0\nOh2TJ0/OmTk/Pp7x48cTGRkJwIYNG0hPT2fixImcO3eO2bNno1KpePHFF4uM4+jRoyxatIjs7Gza\ntWvHnDlzsLa2ZvXq1Rw6dIiMjAw6dOjA3LlzAYyuXwghhJGMHCWrHFNCb7/9NlOmTCEsLAxnZ2eW\nL18OQPPmzfHw8MDLywuNRkNwcHCRLVuTJs7MzEy0Wi0Gg4FnnnmGVatWARAXF0dkZCQ1a9ZEr9ez\nevVqqlevzr179xg5cqTyl0BBgoKCCA4OplOnTixatKjQsllZWQQGBrJp0yYaNWrEzJkz2bp1K2PG\njMHPz48JEyYAMGPGDA4dOkSfPn2Mql8IIUQJlGDmIGNnQOjSpQtdunQBwM7Oji+//DLfcgEBAQQE\nBBS7XpMmzqpVqxIeHv7E9hdffJGaNWsCOQ+pLl26lJMnT6JWq7l9+zZ3794tsM7U1FTS0tLo1KkT\nAD4+Pvz4448Flr9y5QrPPPMMjRo1AmDo0KFK4jx69Ciff/45jx494sGDB7Ro0YJOnToZVb8QQgjj\nyZR7RrK1tVXeR0ZGcu/ePSIiIlCr1bi7u5OZmYlGo0Gv/9/cqpmZmcp7YxeYza98VlYWc+fOZceO\nHTg5ORESEqKcQ9b2FkII0yrPidOkg4OKk4BSU1Oxt7dHrVZz7NgxZeStg4MDycnJ3L9/n6ysLA4d\nOgRAzZo1qVWrFqdPnwZg165dhdbftGlTbt68yfXr15XyXbp0ITMzE5VKRZ06dXj48CE//PBDvvXn\n3mMVQghRenLnqjXuVdZR5zBpi7M4fx14e3vzf//3fwwZMoS2bdsqUyRpNBomTJiAr68v9evXp2nT\npsoxCxYsICgoCLVaTY8ePfLUd+zYMfr06YPBYEClUrFixQoWLFjApEmTlMFBI0eOxNramuHDh+Pl\n5UXdunVp165dseoXQghRSiwkERpLZZB+yad248YN+vXrR9S+GJydXco6nALJsmJCiPzEx9/Ac2A/\nYmJicHEx7e+w3N+XyS9MRl+1jlHHqjPuYf/rCrPEWRhZVkwIIYTZled7nJI4hRBCmJ0kTiGEEMII\nkjiFEEIIY5h55qDSJImzEintwTy67NIdbASgsZIBR0JUBuW5xSm/pYQQQggjSItTCCGE+ZlhrlpT\nkcQphBDC7FQ5UwcZf4wFkMQphBDC7FSUIHFayOggSZxCCCHMT0bVCiGEEMWnUlGCrlrTxGIsk4+q\nbd26NVqtlqFDh6LVapXVT0pTfHw83t7eAJw4cQI3Nze0Wi1eXl6EhISUqE4/Pz/Onz9fmmEKIYSo\nAEze4qxWrVq+i1nnys7OxsrKqlTP6ebmxtq1a3n06BFDhw6lX79+tG7dulTPIYQQouRkcFAh8lt8\nJTw8nH379pGeno5eryc0NJR33nmHBw8eoNPpmDx5Mv369SM+Pp7x48cra2Ju2LCB9PR0Jk6cyLlz\n55g9ezYqlYoXX3wx33NXq1aNNm3acPXqVWrVqsWMGTN49OgRAB999BEvvPACAOvWrSMyMhIrKyt6\n9erFe++9lyf+oKAg6tevz+TJk0v76xFCiEpJEmchMjMz0Wq1GAwGnnnmGVatWgVAXFwckZGR1KxZ\nE71ez+rVq6levTr37t1j5MiR9OvXr9B6g4KCCA4OplOnTixatCjfMvfu3ePf//43EyZMwNHRkS++\n+AIbGxuuXr3Ke++9R1hYGIcPH+bgwYOEhYVhY2PDgwcPlON1Oh3Tp0+nZcuWBAQElN6XIoQQlZ0M\nDipY1apV8+2qffHFF6lZsyYAer2epUuXcvLkSdRqNbdv3+bu3bsF1pmamkpaWhqdOnUCwMfHhx9/\n/FHZHxsby7Bhw1CpVAQEBNCsWTPS0tKYO3cucXFxWFlZcfXqVSBn4ethw4ZhY2MDQK1atZR6Pvro\nIzw9PSVpCiFEKZMWZwnY2toq7yMjI7l37x4RERGo1Wrc3d3JzMxEo9Gg1/9vPtTMzEzlfWHrb+fe\n4/yzL7/8EkdHRyIjI8nOzqZ9+/ZFxtixY0eOHz+Ov7+/kliFEEI8vfKcOE0+qrawBJcrNTUVe3t7\n1Go1x44dU0beOjg4kJyczP3798nKyuLQoUMA1KxZk1q1anH69GkAdu3aVaxz1KtXD4CIiAiys7OB\nnJbvjh07yMjIAOD+/fvKMb6+vvTq1YvJkycr5YUQQlRuJk+cxfkLwdvbm3PnzjFkyBB27dpFs2bN\nANBoNEyYMAFfX1/efPNNmjZtqhyzYMECPv74Y7RabbHOMWrUKHbs2MHQoUP573//S7Vq1QB46aWX\ncHd355VXXkGr1bJhw4Y8cY8dO5bnn3+eGTNmGH3tQgghCqJSVkgp7stSbnKqDMVpEopC3bhxg379\n+hG1LwZnZ5eyDsdsZFkxISqG+PgbeA7sR0xMDC4upv0dlvv7Mqv3B2Brb9zB6cnYHP57oXFmZWXx\n+uuv8/jxY7Kzsxk0aBATJ04kJCSEbdu24eDgAMDUqVPp1asXAKGhoYSFhWFlZcXs2bPp2bNnoWHI\nzEFCCCHMz0Sjam1sbNi0aRPVqlUjOzub1157TUmQ/v7++Pv75yl/+fJl9u7dS1RUFAkJCfj7+7Nv\n375CezLlz3shhBBmZ2w3rTELX+feisvKykKn0ynb8+tgjYmJwdPTE41Gg4uLC40bN+bMmTOF1i+J\nUwghhNnlDKo1NnEWr269Xs/QoUPp0aMHPXr0wNXVFYAtW7bg4+PD7NmzSU1NBSAxMZEGDRooxzo5\nOZGYmFho/ZI4hRBCmF3u0yjGvopDrVYTERHBkSNHOHPmDJcuXWLUqFHExMSwc+dOHB0d+eSTT0oc\nuyROIYQQFVKNGjXo0qULP/74I/b29kpX74gRI5TuWCcnJ27duqUck5CQgJOTU6H1SuIUJaaxUpf6\n67FOX6ovIYRlMtU9zuTkZKUbNiMjg3/96180bdqUpKQkpcz+/ftp2bIlAO7u7kRFRZGVlcX169e5\ndu2a0rVbEBlVK4QQwuxK9FhmMconJSUxa9Ys9Ho9er0eT09PevfuzYwZM4iLi0OtVuPs7MzcuXMB\naN68OR4eHnh5eaHRaAgODi4yQUviFEIIYXYqjJ9yrziZ87nnnst3fvSCFgMBCAgIMGpOckmcQggh\nzK8EedNgGRMHSeIUQghhfmq1CpXauExoUKuwhJELMjhICCGEMIK0OIUQQphdCVYVs5Q53i2nxdmh\nQ4c8n8PDw5k3b16J6wsICCAtLe1pwxJCCGECppxyz9QspsWZ3xfyNF9SaGjo04QjhBDChMpzi9Ni\nEmdhAgMD6du3LwMHDgRyWqe//PILJ06cYOXKlVSvXp2rV6/SrVs35syZA+Q81Lpjxw7s7OxYvXo1\nkZGRODg4UL9+fdq2bYu/vz9xcXHMmTOHjIwMGjVqxIIFC6hZsyZ+fn60b9+e48ePk5qayvz58+nU\nqVMZfgNCCFGxlKgFaSEtTovpqs3IyECr1aLVahk6dCirVq0qsOyfv+yzZ8/y0UcfsXfvXq5du8a+\nffvylDl79izR0dFERkaybt06zp07pxw7c+ZM3n//fXbu3EmLFi0ICQlR9mVnZ7N9+3YCAwPzbBdC\nCFEayu9C1hbT4qxatWqeh1bDw8M5f/58kce5urri7OwMgJeXF6dOnWLgwIHK8jGnT5+mX79+WFtb\nY21tTd++fQFIS0sjLS0NNzc3ALRaLZMnT1bqzW3dtm3blps3b5bORQohhCj3LCZxFsbKygq9Pufp\nHYPBwOPHjwssa0zTP7+12XLZ2NgAObPs/3k9NyGEEE+vJPc4LaSn1nK6agtLYs7OzkoXa0xMTJ5E\ndvbsWeLj49Hr9URFRSktyFwdO3bkwIEDZGVl8fDhQw4ePAjkzJpfu3ZtTp06BcDOnTvp0qWL0bEJ\nIYQwnoyqLQWFfSEjRozgnXfeYejQofTs2VNZ3RtyulLnzZunDA7q379/nvratWuHu7s7Q4YMwdHR\nkeeee44aNWoA8MknnxAcHExGRgbPPPMMCxcuzDcWS/nHEkKIiqI8tzgtJnGePn06z+fcgUIADg4O\nfPvtt8q+6dOnK+9r1KjB2rVrn6gvJiZGeT9u3DgmTpxIRkYGr7/+Om3btgWgVatWeerNtWnTJuV9\nnTp18tQlhBDi6eUkTuMyoSROM/rwww+5fPkyWVlZaLVaWrduXdYhCSFEpSYtzjLSpUuXAu9L/tmS\nJUvMEI0QQojKoFwnTiGEEOVTSQb7WMp4E0mcQgghzE66aoUoJdaa0n1CSpdduqv3aaws5gkuIcq5\nkjxeYhmZUxKnEEIIs5MWpxBCCGGE8nyPU/qdhBBCCCNIi1MIIYTZSVetEEIIYYTy3FUriVMIIYTZ\nmarFmZWVxeuvv87jx4/Jzs5m0KBBTJw4kfv37zN16lTi4+NxcXFh+fLl1KxZE4DQ0FDCwsKwsrJi\n9uzZ9OzZs9BzVMh7nB06dFDeHz58mMGDB3Pr1q0yjEgIIcSfmWp1FBsbGzZt2kRERAQREREcOXKE\nM2fOsG7dOrp3784PP/xA165dCQ0NBeDSpUvs3buXqKgo1q9fz8cff1zkilgVMnHmfrlHjx5lwYIF\n/POf/6RBgwZ5ymRnZ5dFaEIIITDtsmK5K2hlZWUpy1DGxMQoC4dotVqio6MBOHDgAJ6enmg0Glxc\nXGjcuDFRe7rUAAAgAElEQVRnzpwptP4K2VVrMBiIjY3lo48+Yv369bi4uAAQGBiIjY0NcXFxdOrU\nCQ8PDxYsWEBWVhZVqlRh4cKFNGnShPDwcPbv309qaiq3b9/G29ubiRMnlvFVCSFExWKqW5Z6vZ5h\nw4Zx7do1Xn/9dVxdXbl79y6Ojo4A1K1bl+TkZAASExN54YUXlGOdnJxITEwstP4KmTgfP37MhAkT\n2Lx5M02aNMmzLzExkW3btgHw8OFDvv76a9RqNUePHmXp0qWsXLkSyFkge8+ePVSpUgVfX1/69u1L\nmzZtzH0pQgghjKRWq4mIiCAtLY0JEybw+++/l+o6yxUycWo0Gjp06MD27duZPXt2nn2DBw9W3qem\npjJz5kyuXr0K5O2+7dGjB7Vq1QJgwIABnDp1ShKnEEKUEnOMqq1RowZdunThxx9/xMHBgTt37uDo\n6EhSUhL29vZATgvzz2NgEhIScHJyKrTeCnmPU61Ws2LFCs6ePavcAM5la2urvF+xYgXdunUjMjKS\ntWvXkpmZqewrzb9OhBBC5JU7qtbYV1GSk5NJTU0FICMjg3/96180a9YMd3d3duzYAUB4eDj9+vUD\nwN3dnaioKLKysrh+/TrXrl3D1dW10HNUyBanwWCgSpUqhIaGMnr0aBwdHXnllVeeKJeWlqb8ZZH7\nheb6+eefefDgATY2NkRHR7Nw4UKzxC6EEJVBTiI0tsVZdJmkpCRmzZqFXq9Hr9fj6elJ7969ad++\nPVOmTCEsLAxnZ2eWL18OQPPmzfHw8MDLywuNRkNwcHCRcVXIxJl70bVr12b9+vWMHj1aaZb/2Ztv\nvsnMmTNZs2YNvXv3zrPP1dWViRMnkpiYiI+Pj3TTCiFEKTLVc5zPPfcc4eHhT2y3s7Pjyy+/zPeY\ngIAAAgICih1HhUycp0+fVt7Xr19fGXbct2/fPOVeeOEFfvjhB+Xz5MmT8xwXEhJi4kiFEKJyUqtU\nqI3MnMaWN5UKeY9TCCGEMJUK2eJ8WlqtVnlQVgghROmTSd6FEEIIY5TgcRRLyZySOIUQQpidGlAb\nmQct5d6iJE5RoWmsSvd/tYzHpT/HcVVrq1KvUwhLJ8uKCSGEEEYoz/c4LaXlK4QQQpQL0uIUQghh\ndqr//2PsMZZAEqcQQgizU6tKMDjIMvKmJE4hhBBloCI+jvLtt98WeuDIkSNLPRghhBCVQ3keHFRg\n4oyNjS3wIJVKZTGJs0OHDvzyyy95tn3zzTdUq1YNHx+fAo8LDw/n3LlzfPjhh6YOUQghxF+U57lq\nC0ycn376qTnjKLH8mvqvvvpqiY8tSHZ2NlZW8rydEEJUdkXe48zMzGT9+vVcv36df/zjH1y5coU/\n/vhDWQTUEoWEhFC9enX8/f3x8/OjVatWnDx5kuzsbBYsWEC7du3ylE9OTmbOnDnKKuBBQUF06NCB\nkJAQrl27xvXr12nYsCFLliwpi8sRQogKp0J21eaaM2cOdnZ2nDt3DoB69eoxbdo0i06cf5WZmUlE\nRASxsbEEBQURGRmZZ//8+fMZO3YsHTt25NatW7z55ptERUUBcPnyZbZu3YqNjU1ZhC6EEBWSihLM\nHFReHkeJi4sjIiKCo0ePAlCjRg2ys0t/2jFT8vLyAsDNzY2HDx+SlpaWZ//Ro0e5cuUKBoMBgPT0\ndB49egSAu7u7JE0hhChlFbrF+dekkZWVpSSY8uLPf9XkF7vBYGDbtm1YW1s/sc/W1taksQkhRGWk\nUhk/2MdSEmeRU+516tSJ9evXk5WVRWxsLFOnTqVPnz5mCK14ipPEc7tdY2NjqVmzJjVq1Mizv0eP\nHmzatEn5fOHChdINUgghRB6qEr4sQZEtzqlTp7Ju3TqqVq3K/PnzcXd3Z/z48eaIrVgyMzPp06cP\nBoMBlUrF2LFjnyhTpUoVtFotOp2OhQsXPrF/9uzZzJ07lyFDhqDX63Fzc2POnDmmD14IIUS5U6yu\n2okTJzJx4kRzxGO03377rcgyQ4YMITAwMM82rVaLVqsFoE6dOixbtuyJ4yz1moUQoryr0MuKpaen\ns3btWo4dOwZA9+7dCQgIKDf3/izlixZCCPE/FXqu2qCgIKpUqcL7778PwI4dOwgMDGTFihUmD640\n/PnepRBCCMtQoVuc//nPf9i7d6/yuXPnznh4eJg0KCGEEBWbqR5HSUhIYMaMGdy9exe1Ws2IESPw\n8/MjJCSEbdu24eDgAOSM3+nVqxcAoaGhhIWFYWVlxezZs+nZs2eh5ygycdatW5eUlBTs7OwASElJ\noV69ekVHL4QQQhTAVC1OKysrAgMDad26NQ8fPmTYsGG8+OKLAPj7++Pv75+n/OXLl9m7dy9RUVEk\nJCTg7+/Pvn37Cj1XgYlz6dKlADg6OuLj44O7uzsABw8epFOnTkVfoRBCCFEAFcbfsyxO8bp161K3\nbl0AqlevTrNmzbh9+zaQ/+OLMTExeHp6otFocHFxoXHjxpw5c4b27dsXeI4CE6danfOIZ6NGjWjU\nqJGyfejQocUIXYiKqap16U/0n6XTl2p9NpoiH88WolK4ceMGFy5cwNXVlVOnTrFlyxZ27txJ27Zt\nmTVrFjVr1iQxMZEXXnhBOcbJyYnExMRC6y0wcU6ZMqX0ohdCCCH+xNSDgx4+fMikSZMICgqievXq\njBo1igkTJqBSqVi2bBmffPIJ8+fPNzZsoBj3OCFnLtcLFy6QmZmpbLOkSRCEEEKULyWZCai45XU6\nHZMmTcLHx4f+/fsDYG9vr+wfMWKEksOcnJyUlbEgZ3CRk5NTofUX2aezbNkyVq9ezfr167l27Rob\nN27k4sWLxQxfCCGEeFLuQtbGvoojKCiI5s2b88YbbyjbkpKSlPf79++nZcuWQM5CHlFRUWRlZXH9\n+nWuXbuGq6trofUX2eKMiYkhPDycV155hQULFnDr1i2Cg4OLFbwQQgiRH1M9jnLq1CkiIyNp2bIl\nQ4cORaVSMXXqVHbv3k1cXBxqtRpnZ2fmzp0LQPPmzfHw8MDLywuNRkNwcHCRXcJFJs4qVaooq4bo\ndDoaNGiQp1krhBBCGMtU9zg7depEXFzcE9tzn9nMT0BAAAEBAcWOo8jEaWtrS0ZGBi+88AJBQUHU\nrVtX1qcUQghRaRV5j3Px4sWo1WpmzZrFM888Q1ZWVqlPt9eqVStmzJihfM7OzqZbt25mHYB04MAB\n1q9fb7bzCSFEpab6X3dtcV+Wsq5YkS3O3NFFNjY2vPvuuyYJolq1avz+++9kZWVhY2PDzz//TIMG\nDUxyroK4u7srkzwIIYQwLWMG+/z5GEtQYOJ87733Cu1PXrJkSakG0qtXLw4dOsTAgQPZs2cPXl5e\nxMbGAnDmzBkWLFhAVlYWVapUYeHChTRp0oSMjAxmzZrFpUuXaNKkCbdv3yY4OJg2bdowZ84czp07\nR2ZmJoMGDVKWCHN3d0er1XLw4EF0Oh0rVqzg2WefJTw8nHPnzvHhhx9y8OBB1qxZg06nw87OjsWL\nF+cZyiyEEOLpmGpwkDkUmDi7d+9utiBUKhVeXl6EhITQp08f/vOf/+Dr66skzmbNmvH111+jVqs5\nevQoS5cuZeXKlXz99dfUrl2b3bt38/vvvyvra0JO4q9VqxZ6vZ433niDgQMHKsOP7e3t2bFjB19/\n/TUbNmxg3rx5ShwAbm5ubNu2DYDt27ezfv16Zs6cabbvQwghKjoVxq92YiF5s+DEOXz4cHPGQcuW\nLYmPj2f37t307t07z5yCqampzJw5k6tXrwI590AhZ9hx7nM6LVq0UBIjwJ49e9i+fTs6nY47d+5w\n6dIlZf+AAQMAaNu2LdHR0U/EcuvWLaZMmcLt27fR6XS4uLiY5qKFEKKSUlOMQTb5HGMJLCUOIKcb\nddGiRbz88st5tq9YsYJu3boRGRnJ2rVr88xglJ8bN27wxRdfsGnTJnbt2kXv3r3JyspS9ueOClar\n1eh0uieOnzdvHn5+fkRGRvLxxx8XeT4hhBCVh0UkztzWpa+vLxMnTqRFixZ59qempiqDlHbs2KFs\n79ixI1FRUQBcunRJmdEoLS0NW1tbqlevzp07dzhy5IhR8Tx8+FBZOi08PLxkFyWEEKJAuc9xGvuy\nBMWaq9bUcr8MJycnRo8e/cT+v/3tb8ycOZM1a9bQu3dvZfuoUaOYNWsWL7/8Mk2bNqVFixbUrFmT\nRo0a0bp1azw8PGjQoEGeZdCK88VPmDCBSZMmUbt2bbp160Z8fHwpXKUQQohcKlUJlhWzjLyJypDf\nAmV/ceLECS5fvsxrr73G3bt3efjwYZ6lxsqKXq9Hp9NhY2PD9evX8ff35/vvv0ejMe/fAzdu3KBf\nv35E7YvB2VnuhwrjyLJioqzFx9/Ac2A/YmJiTD6mI/f3Zd/AddjaFz6Z+l+lJydycOHbZomzMEVm\nmM8//5z9+/eTnJzMa6+9RmZmJrNmzeLrr782R3yFevToEWPGjFHuU86ZM8fsSVMIIYTxTL2smCkV\nmWV27txJWFiYMsq2YcOGpKammjyw4qhevTphYWFlHYYQQggjqUvQVWtseVMpsk+natWqyiTvuSwl\n6wshhBDmVmSLs379+vz666+oVCoMBgPr16+nWbNm5ohNCCFEBVUhZw7KNXv2bN5//31+//132rdv\nT/v27Vm2bJk5YhOiUijtwTx1Ok8s1foA7p0MKfU6ReWmKsFctZbS21msSd43bdpEWloaBoOBmjVr\nmiMuIYQQFVh5njmoyMT5008/5bu9Z8+epR6MEEKIyiFnrlrjj7EERSbOzz77THmfmZnJxYsXad26\ntSROIYQQJVYhlxXL9dfnNf/zn/+wceNGkwUkhBCi4ivPg4OM7jJ+7rnnOH/+vCliEUIIISyeUfc4\n9Xo9Z8+excrKyqRBCSGEqNjK81y1Rt3jtLKyonHjxixfvtykQZVEq1at8Pf3Vxac3rBhA+np6Uyc\nWPpD84UQQjydCnuPU6/XM378eHr16mWueErMxsaG/fv3ExAQgJ2dXVmHI4QQohAV9h6nWq1m6dKl\n5orlqVhZWTFixAi++OKLJ/bFx8fzxhtv4OPjg7+/PwkJCQAEBgby97//nVdffZUBAwawb98+5ZjP\nP/8cX19ffHx8CAmRh7+FEKI05c5Va+zLEhQ5OOi5557j3Llz5ojlqahUKl5//XUiIyNJS0vLs2/e\nvHkMGzaMnTt38vLLLzNv3jxl3507d/jmm29Yu3YtixcvBuDnn3/m6tWrfPfdd0RERHDu3DliY2PN\nej1CCFGRqUr4U5SEhATGjBmDl5cX3t7ebNq0CYD79+8zbtw4Bg0axJtvvplnsZLQ0FAGDhyIh4dH\ngXMX/FmR9zgvXrzIyJEjadq0KdWrV1e2f/PNN0VWbm7Vq1dHq9WyadMmqlatqmz/9ddfWb16NQA+\nPj5KggTo378/AM2aNePu3btAzoCon3/+Ga1Wi8Fg4NGjR1y9ehU3NzczXo0QQghjWVlZERgYSOvW\nrXn48CHDhg2jR48e7Nixg+7du/PWW2+xbt06QkNDmT59OpcuXWLv3r1ERUWRkJCAv78/+/btK3R6\nvyIT54wZM0r1okxtzJgxaLVahg0bpmwr7AuwsbFR3v95Te+AgABGjBhhmiCFEKKSM9Wo2rp161K3\nbl0gpzHVrFkzEhMTiYmJYcuWLQBotVr8/PyYPn06Bw4cwNPTE41Gg4uLC40bN+bMmTO0b9++wHMU\n2FUbFBQEQPfu3fN9WZrcpFe7dm08PDzyrNPZoUMHdu/eDcCuXbsKbDnm1tGzZ0/CwsJIT08HIDEx\nkeTkZFOGL4QQlYqaEtzjNPIcN27c4MKFC7Rv3567d+/i6OgI5CTX3N/piYmJNGjQQDnGycmJxMTE\nQustsMUZFxdnZIhl68+tynHjxvH1118r2z744AMCAwPZsGED9vb2LFy4sNA6evTowZUrVxg5ciSQ\n81fLp59+ir29vYmvQgghKgeVSmX0aifGlH/48CGTJk0iKCiI6tWrP3Hs06y0UmRXbXlx+vRp5b2D\ngwO//PKL8rlhw4b5ThP41wT65zr8/Pzw8/MzQaRCCCFKMkq2uOV1Oh2TJk3Cx8dHGcfi4ODAnTt3\ncHR0JCkpSWkIOTk5cevWLeXYhIQEnJycCq2/wMR58eLFfLtkDQYDKpWKo0ePFu8KhBBCiL8w5XOc\nQUFBNG/enDfeeEPZ5u7uzo4dO3j77bcJDw+nX79+yvbp06czduxYEhMTuXbtGq6uroXWX2DibNKk\nCevWrStelEIIIYQFOHXqFJGRkbRs2ZKhQ4eiUqmYOnUqb731FlOmTCEsLAxnZ2dlBrzmzZvj4eGB\nl5cXGo2G4ODgIrtxC0ycNjY2ODs7l+4VCSGEEOSOqjX2HmfRZTp16lTgGJ0vv/wy3+0BAQEEBAQU\nO44CE6e1tXWxKxFCCCGMYcp7nKZWYOLctm2bOeMQQghRiZTnuWorzKhaIUSOeydLf27lP08OUhqe\n5lEAUTGoUaEuxhR6fz3GEkjiFEIIYXblucVp7EQMQgghRKUmLU4hhBBmp6IEc9WaJBLjSeIUQghh\ndmqVyujHUYwtbyqSOIUQQpid3OM0k9atW6PVavH29mbKlClkZmYWWv61114zU2RCCCGMkdviNPZl\nCcpV4qxWrRrh4eFERkai0WjYunVroeWL2i+EEKJs5LY4jX1ZgnKVOP/Mzc2Na9euAfDFF1/g7e2N\nt7d3nlVQOnToAEBSUhKjR49WWqunTp0CYPfu3cpxixcvznPcsmXL8PHx4dVXX5W1OIUQQijKVeLM\nfQhbp9Nx5MgRWrZsyfnz5wkPD+e7777j22+/Zfv27Vy4cAH430PWu3fv5qWXXiI8PJxdu3bRunVr\nbt++zZIlS9i8eTM7d+7k7NmzxMTEAPDo0SM6duzIzp076dSpk8yiJIQQpUzF/1/M2oiXhTQ4y1fi\nzMzMRKvVMnz4cJydnfH19eXUqVMMGDCAKlWqYGtry4ABA4iNjQX+l2jbtWvHjh07CAkJ4T//+Q+2\ntracPXuWrl27Ymdnh1qtxtvbWznO2tqa3r17A9CmTRvi4+PL5oKFEKKCyl3I2tiXJShXo2qrVq1K\neHh4scvnfslubm5s2bKFQ4cOERgYyNixY6lRo0aB04hpNP/7WqysrNDpdE8XuBBCiDxUGN+CtIy0\nWc5anPklOjc3N6Kjo8nMzCQ9PZ3o6Gjc3NzylL958yYODg4MHz4cX19ffvvtN1xdXTl58iQpKSlk\nZ2ezZ88eunTpYtbrEUKIyqo8j6otVy3O/Jrpzz//PFqtFl9fXwBGjBhBq1at8pQ/ceIEn3/+ORqN\nhurVq/OPf/yDunXrMn36dPz8/ADo06cPffv2LfA8QgghSk95bnGWq8R5+vTpfLePHTuWsWPHFlh+\n6NChDB069In9np6eeHp6FnqeQYMGMWjQoBJGLIQQIj8yAYIQQghRSZSrFqcQQoiKoiSjZC2jySmJ\nUwghhNnlPptp7DGWQBKnEEIIsyvJc5mWMnBTEqcQQgizk1G1QogKrbT/0v/u3zdKtT7f9i6lWp8w\nvZxRtca2OE0UjJEspctYCCGEeGpBQUG8+OKLeHt7K9tCQkLo1asXWq0WrVbLkSNHlH2hoaEMHDgQ\nDw8Pfvrpp2KdQ1qcQgghzM5Ug4OGDRuGn58fM2bMyLPd398ff3//PNsuX77M3r17iYqKIiEhAX9/\nf/bt21dkS1hanEIIIcyvJBO8F6Ov1s3NjVq1aj2xPb8pW2NiYvD09ESj0eDi4kLjxo05c+ZMkeeQ\nxCmEEMLsVCV8ldSWLVvw8fFh9uzZpKamApCYmEiDBg2UMk5OTiQmJhZZlyROIYQQZpfbgDT2VRKj\nRo0iJiaGnTt34ujoyCeffPJUsUviFEIIYXZqVCV6lYS9vb1y33LEiBFKd6yTkxO3bt1SyiUkJODk\n5FSM2C3YmjVrePnllxkyZAharbZYfc8rV67k6NGjZohOCCGEJfrr/cykpCTl/f79+2nZsiUA7u7u\nREVFkZWVxfXr17l27Rqurq5F1m+xo2p//fVXDh8+TEREBBqNhpSUFB4/flzkcZMmTTJJPNnZ2VhZ\nWZmkbiGEqGxMtTrKtGnTOH78OCkpKfTp04d3332X48ePExcXh1qtxtnZmblz5wLQvHlzPDw88PLy\nQqPREBwcXKxnSy02cSYlJVGnTh00mpwQ7ezsOHv2LHPnzmXVqlVER0czbdo0Tp06hV6vx9PTk+jo\naAIDA+nbty8NGzbkgw8+QKVSodPpuHTpEkeOHOGtt95CpVJhMBi4ePEiMTEx6PV6goKCSElJwd7e\nnoULF1K/fn0CAwOxsbEhLi6OTp06MXPmzDL+VoQQomJQ/f8fY48pypIlS57Y9sorrxRYPiAggICA\nAKPisNjE2aNHD1avXs3gwYPp3r07np6edOzYkQsXLgBw6tQpWrZsydmzZ9HpdLRv3z7P8W3btiUi\nIgKARYsW0bt3b+rWrats++qrrzh16hQNGjRg/PjxDBs2DB8fH8LCwpg3bx6rV68GckZdbdu2zYxX\nLoQQFV95Xo/TYhOnra0t4eHhxMbGcuzYMaZOncq0adNo1KgRly9f5uzZs/j7+3Py5Emys7Nxc3PL\nt56oqCji4uLYsGGDsu3UqVN89913bN26FcjpFs5NlD4+PixevFgpO3jwYBNepRBCVE6qEgz2MbaF\naioWmzghZx7Dzp0707lzZ1q2bEl4eDhubm78+OOPWFtb0717d2bNmoVer39ilgiAixcvsnr1ar76\n6iul3/r27dt8+OGHrF27lqpVqyrnKYitra1pLk4IISqx8tzitNhRtX/88QdXr15VPsfFxeHi4oKb\nmxsbN26kQ4cO1KlTh5SUFP744w9atGiR5/jU1FSmTZvGP/7xD+zs7ADQ6XRMmTKF6dOn06hRI6Vs\nhw4d2L17NwC7du0qsPUqhBBCWGyLMz09nXnz5pGWloaVlRWNGzdm7ty5VKtWjbt379K5c2cAnnvu\nOe7evfvE8TExMdy6dYsPP/wQg8GASqUiKCiI8+fPs2rVKlauXIlKpWLdunV88MEHBAYGsmHDBmVw\nkBBCCNNRUYIWp0kiMZ7FJs42bdrwzTff5Lvvz89z5g4rzvXnpDd06NAnjv33v/+db50bN258Ypsk\nUCGEMA1Tjao1B4tNnEIIISoutSrnZewxlkASpxBCCLOTFqcQQghhjJJM2m4ZedNyR9UKIYQQlkha\nnEJUMPkt2Pu0ijN/pzF827uUan16felfs9pSbqhVUNJVK4QQQhhBBgcJIYQQRlBhfAvSQvKmJE4h\nhBDmV56n3JPEKYQQwuxUGN+CtJC8KYlTCCGE+alUKtRGNiFLe5BaScnjKEIIIYQRKlyLMyUlhbFj\nx6JSqUhKSkKtVmNvb49KpWL79u1oNDmXHBISQvXq1fH39y/jiIUQovKRrloLYmdnR0REBCDJUQgh\nLFY5zpwVLnEWZs2aNURERODo6Ej9+vVp27YtAJs2beLbb79Fo9HQvHlzlixZwokTJ1iwYAEqlQqV\nSsWWLVtkUWshhCglMgFCOXD+/Hn27t1LZGQkWVlZDBs2TEmc69ev58CBA1hbW5OWlgbAhg0bCA4O\npkOHDjx69IgqVaqUZfhCCFGhlOfHUSrN4KDY2FgGDBiAjY0NNWrUwN3dXdnXqlUrpk2bxq5du1Cr\nc76Sjh07snDhQjZv3syDBw+U7UIIIZ6eqoQvSyDZAFi3bh2jR4/mt99+w9fXF71ez9tvv838+fPJ\nyMjgtdde448//ijrMIUQQliASpM4O3fuTHR0NFlZWaSlpXHw4EFl382bN+nSpQvTpk0jLS2N9PR0\nrl+/TosWLXjrrbdo27YtV65cKcPohRCiAiqPzU0q0T3O559/Hk9PT7y9vXF0dKRdu3YA6HQ63n//\nfdLS0jAYDIwZM4YaNWqwfPlyjh8/jlqtpnnz5vTq1auMr0AIISoOUw0OCgoK4tChQzg4OBAZGQnA\n/fv3mTp1KvHx8bi4uLB8+XJq1qwJQGhoKGFhYVhZWTF79mx69uxZ5DkqdOKcOHFins8BAQEEBAQ8\nUe7rr79+YtsHH3xgsriEEKKyM9XgoGHDhuHn58eMGTOUbevWraN79+689dZbrFu3jtDQUKZPn86l\nS5fYu3cvUVFRJCQk4O/vz759+4qcoajSdNUKIYSwHKYaHOTm5katWrXybIuJiUGr1QKg1WqJjo4G\n4MCBA3h6eqLRaHBxcaFx48acOXOmyHNI4hRCCGF+ZhxWm5ycjKOjIwB169YlOTkZgMTERBo0aKCU\nc3JyIjExscj6JHEKIYSoVJ52snhJnEIIIcqAyuifkjY5HRwcuHPnDgBJSUnY29sDOS3MW7duKeUS\nEhJwcnIqsj5JnEIIIcwud3CQsa/iMBgMeT67u7uzY8cOAMLDw+nXr5+yPSoqiqysLK5fv861a9dw\ndXUtsv4KPapWiMrIUtYsNCe1uvSvOfbKvVKtz61pnVKtr7wz1Rzv06ZN4/jx46SkpNCnTx/effdd\n3n77bSZPnkxYWBjOzs4sX74cgObNm+Ph4YGXlxcajYbg4OBi/f8jiVMIIYT5mShzLlmyJN/tX375\nZb7bC3pMsTCSOIUQQphdeV4dRe5xCiGEEEaQFqcQQgizK8/LikniFEIIYXamGhxkDpUycY4ZM4aA\ngAB69OihbNu4cSM//fQTJ06coGnTpuj1emxtbVm4cCFNmjQpu2CFEKIiKseZs1Le4/T29mb37t15\ntkVFRREQEECjRo0IDw9n586dDB06lLVr15ZRlEIIUXEZP/2B8YOJTKVSJs6BAwdy5MgRdDodAPHx\n8SQlJVG/fv085dLS0qhdu3ZZhCiEEBWaKSdAMLVK2VVbu3Zt2rVrx5EjR3B3d2fPnj0MHjwYlUrF\ntWvX0Gq1pKWlkZGRwfbt28s6XCGEqJAsJA8arVK2OAG8vLzYs2cPkNNN+/LLLwMoXbX79+8nKChI\n1khGneQAACAASURBVOUUQgiRR6VNnP369ePYsWP89ttvZGRk8Pzzzz9Rxt3dndjY2DKITgghKgEz\nLClmCpWyqxbA1taWLl26EBQUpLQ2/yo2NpZGjRqZOTIhhKj4yvPMQZU2cUJOd+27777LsmXLlG3X\nr19Hq9Wi1+uxsbHh73//exlGKIQQFZNMgFBO9e/fn7i4OOWzs7Mzv/76axlGJIQQlUM5foyzcidO\nIYQQZaQcZ85KOzhICCGEKAlpcQohhDC7nAansYODLIMkTiGEEGYng4OEEEIII5TjW5ySOIUQIj9u\nTeuUan2Zj7NLtT6AKtZWpV6n2ZTjzCmJUwghhNmV5wkQZFStEEIIYQRpcQohhDC/kiwTZhkNTkmc\nQgghzK8c3+KUxCmEEKIMmDBzuru7U6NGDdRqNRqNhu+++4779+8zdepU4uPjcXFxYfny5dSsWdPY\nqAG5xymEEKIMqEr4U6y6VSo2b95MREQE3333HQDr1q2je/fu/PDDD3Tt2pXQ0NASx16hEueYMWP4\n+eef82zbuHEjgYGBTJ482ej6Nm7cSGZmZmmFJ4QQ4v/LnQDB2FdxGAwG9Hp9nm0xMTFotVoAtFot\n0dHRJY69QiVOb29vdu/enWdbVFQUr7zyCitWrHiifHZ24c9Vbdy4kUePHpVqjEIIIUxLpVIxbtw4\nXnnlFbZv3w7A3bt3cXR0BKBu3bokJyeXuP4KdY9z4MCBLF++HJ1Oh0ajIT4+nqSkJOrXr4+3tzeR\nkZGEh4ezb98+0tPT0ev1vPvuu2zYsIG1a9cCMG/ePNq1a0dqaiq3b99mzJgx1KlTh40bN5bx1Qkh\nRMVhysFBW7dupV69eiQnJzNu3DieffZZVH9prv71szEqVIuzdu3atGvXjiNHjgCwZ88eBg8e/MQX\nFBcXR0hICJs3by6wLj8/P+rVq8fmzZslaQohRClTUYKu2mLWXa9ePQDs7e3p378/Z86cwcHBgTt3\n7gCQlJSEvb19iWOvUImT/9fefYdFcXV/AP8uvUkvFqqoNBuCNEURG4iIRkElJlE0qIkaW15bNCox\n+tpiErsiYo8NbKhYKApIEQEpInVBEJAm0tv5/eG788PYWESN5n6ex+fB3dk7d2bLmTtz7hkATk5O\nuHTpEoDnp2lHjx790jI2NjatzqYionbtH8MwDAP8/5hT2H9vVlNTg6qqKgBAdXU1bt++jR49esDe\n3h5nz54FAPj5+WHo0KFt7vlndaoWAIYOHYoNGzYgOTkZtbW1MDY2Rl5e3gvLyMjIcH+Lioq+EBxZ\nMhDDMMz7977ujlJcXIw5c+aAx+OhqakJzs7OGDhwIHr27In58+fjzJkz6NKlC7Zt29a2juMzDJwy\nMjKwsLDA8uXLXzna/LsuXbogPT0dDQ0NqKmpQUREBMzNzQEAcnJyqKyshKKi4vvuNsMwzL/K+7rG\nqaWlhXPnzr30uKKiIg4ePCjkGl/tsztVCzw/XZuamgonJ6e3LtuxY0c4Ojpi9OjRWLBgAUxMTLjn\n3NzcMGPGDHzzzTfvs7sMwzDMJ+SzG3ECwLBhw5CSksL9v0uXLrhw4QKA5/N3BHN5BBYvXozFixe/\n1M6UKVMwZcqU99tZhmGYfyNWq5ZhGIZhWu9Tvq0YC5wMwzDMh/cJV3lngZNhGIb54D7huMkCJ8Mw\nDPPhva/pKB8CC5wMwzDMB8eucTIMwzBvJCku2u5t1jc2v32hVmhoZBXShMECJ8MwDPPhfcIXOVng\nZBiGYT64TzhussDJMAzDfHgsOYhhGIZhhMCSgxiGYRhGGJ9wyb3Prsj79evXMXbsWK4m7dixY2Fk\nZITQ0FDMmjVLqLb27NnznnrJMAzDfKo+uxHnsGHDMGzYMO7/J0+exIULFyAhISF0W7t378bMmTPb\ns3sMwzDMJ+6zG3G2lJWVhZ07d2Lz5s0QERFBZWUlZs6cCQcHB6xevZpb7uLFi3B2doazszO2bNkC\nANiyZQvq6uowbtw4/Pjjjx9pCxiGYT5PPPx/glCr/33sTv/PZzfiFGhsbMTixYuxdOlSaGhogM/n\n4/79+wgICEDnzp0xffp0BAYGom/fvtiyZQv8/PwgLy+PadOm4caNG1i0aBGOHj0KPz+/j70pDMMw\nn51POTnosx1xbtu2DT169ICDgwP3WO/evdGlSxfweDw4OTnh7t27uH//PiwtLaGoqAgRERE4Ozsj\nJiYGAEDEqmkwDMO8D0KPNtuSTPSefJYjzsjISFy7dg3+/v5vXI7H44HH47EAyTAM84F9ygUQPrsR\n59OnT7F8+XJs3LgR0tLSLzyXkJCAvLw8NDc3IyAgAGZmZujVqxeio6NRXl6OpqYmXLp0CRYWFgAA\nCQkJNDU1fYzNYBiGYf6hPrsR519//YXS0lIu+YeIwOPx4Onpid69e8PLywt8Ph9WVlYYPnw4AGDx\n4sX46quvAABDhgzBkCFDAABubm5wdnaGiYkJNm3a9FG2h2EY5rP0CQ85P7vA6enpCU9Pz1c+5+jo\n+MrHR40ahVGjRr30+KJFi7Bo0aJ27R/DMAwjiJvCJgf9M3x2gZNhGIb55/uUa9V+dtc4GYZhmH8+\nXhv/tUZoaCgcHBwwcuRI7N27t727zgInwzAM8xG8p8jZ3NwMLy8veHt74+LFi7h06RIyMjLatess\ncDIMwzCfjYSEBOjo6KBLly4QFxeHk5MTbty40a7rYNc424FgykphQcFH7gnDMP8mDY3tMwe9sPD5\nb9eHnH5XVFgIYdN9nr/mzQoLC9GpUyfu/xoaGrh//76w3XsjFjjbwZMnTwAA077+8iP3hGEYpu2e\nPHkCHR2d97oOOTk5KCgotPn3UkFBAXJycu3cK+GwwNkOevbsiaNHj0JNTQ2ioqIfuzsMwzBCaWpq\nwpMnT9CzZ8/3vi5FRUUEBgaisrKyTa+Xk5ODoqLia5/X0NBAfn4+9//CwkKoq6u3aV2vwyNWb45h\nGIb5TDQ1NcHBwQEHDx6EmpoaXF1dsXXrVujr67fbOtiIk2EYhvlsiIqKYuXKlfDw8AARYcKECe0a\nNAE24mQYhmEYobDpKAzDMAwjBBY4GYZhGEYILHAyDMMwjBBY4GQYhmEYIbDAybSL9q4FyTDv06eQ\nEynoY3v29VPY7k8BC5wfUV1dHdLS0gAAubm5yMvLey/red9fltraWqxduxarVq1qtzY/xy+4YJuy\ns7M/bkde4X3u7/fVdlvbFdzcHgCioqLavP6ampr3VqKupqaG62NNTc07t1daWgoA4PF4SE5Ofuf2\n/u1Y4PyIHj16hODgYHh5eWHx4sXvpepQyx+JgoIClJSUvPDcu2puboaUlBS2bt2K7OxsbN269Z3b\nBMD1+fr164iIiBD69YJta2xsRHNzs9Cvex8/9jweDxEREVixYgUePXrU7u23VcvPSExMDO7evYvi\n4uJ2b7uhoaFd2vx7u2fOnIGfn1+rXyt43dGjR/Hzzz+/UGWmtUJCQjBnzhysX78eFy5cEPr1b1JX\nV4e//voLMTExOHXqFFavXo2mpqZ3+kxGRETgu+++w4kTJ/DHH3/g6dOn7djjfx9WAOEj0tTURGlp\nKU6dOoWvv/4aHTt2BPA8GImIvPsxTcsflwMHDsDf3x+dO3dGv3794OnpCR6P98IybSHoZ1RUFLp3\n746LFy+iqakJP/74Y5vau3//PsrKymBpaQkJCQlcvHgR3377rdDt8Hg83LhxAwEBAVBSUoK7uzu6\ndu3aqtdFRkYiOjoaXbt2RZ8+fdClS5e2bMpLMjMzcfz4cXz33XfQ1NRst/dZQPBeJiQkQFRUFDwe\nD8bGxm99neD9379/P0JCQtClSxdUVFTg+++/h4mJyTv3BwB8fX0RERGBfv36wdLSEn369Glzuy37\nHBUVhXPnzmHnzp1Cvf727ds4ffo0jhw5AhUVFaSmpkJNTQ0KCgpvPYC9desWtm/fDnd3dzQ2NiI5\nORnOzs7c8+/6nZKUlESfPn0wdepUaGho4OTJk+98UO3k5IR9+/Zh/fr1uHLlChQUFFBfXw8JCYl3\navffSnT16tWrP3Yn/m0EXywxMTEoKSlBRUUFVVVVKCwshImJCXg8HmpqaiAuLv5O6xF8eePj4xEY\nGAgvLy+Ymppi165dKCkpgYWFRbsEzwsXLmDbtm1YsGABevbsiZCQECQlJcHW1lbotkJDQ3Ho0CF0\n6tQJurq6uHr1KszNzaGmpsaNHFvT14yMDGzcuBFOTk6or6/HH3/8ASsrKygrK7/xddHR0VizZg2M\njIxw/fp1FBYWQlRUFJqamkJvS0tNTU24fPkyIiIiIC4uDgsLC4iKir7zvhcQBOGgoCD8+uuvkJSU\nxJkzZyAmJobu3bu/9fUPHjyAv78/vL29kZiYiCdPnmDq1KlobGxs84+2YLtiY2Nx4cIFODo6oqys\nDGFhYVBUVETnzp3b1K5AQkICdu7cCSUlpRcC16v8fT8XFhZCXFwc+fn5uHbtGrZv346EhAQYGhq+\n8TMSHh6OuXPn4pdffsHw4cNRXFyM48ePo7KyEvHx8TA1NW2X91NcXBw1NTVIS0uDsbExdHR0XtiG\n5ubmt67n79vc2NgIHo8HPz8/fPHFF+/8+/JvxgLnR8Dj8RAVFYV79+5BWloaY8eOxdOnTxETE4O6\nujo0NDQgMDAQBgYG7/zhfvjwIZYuXQodHR2MHTsWampqsLCwwJ49e/Do0SPY2Ni88xc9JSUFxsbG\nGDZsGLp27YpevXph//794PP5rQ6egh8CExMTSEpK4ujRo9DX1wefz4eCggL09PRQWVmJkpISyMvL\nv7Gt5ORk7NixA1ZWVvjyyy9hYWGB2tpabNu2Debm5lBRUXnl63JycrBlyxZMmTIFX375JUxNTZGb\nm4vc3FxYWFgIvV8EP1wlJSUQFRVFv379ICUlhZycHNTV1UFfX/+dD1xKS0vR3NwMSUlJZGZmYuPG\njdixYwcKCgoQFRWFhw8fgsfjwcjI6JV9E6iqqkJWVhZCQ0ORlpaG7du3Q0xMDLdv30bHjh0hJta2\nk1NBQUGYN28e5s+fDwcHB6irq6OmpgahoaGQlZWFlpZWq9v6e5/V1NRQVlaGzMxMqKmpQUND45VB\nvuXr/Pz88PjxYxgaGuLmzZsoKCjA8OHDsXDhQkREREBOTu61Bxr5+fnYtWsXlJSUkJ+fD0NDQ2zY\nsAFmZmbo168ftmzZgmfPnsHKykrIvfSiyMhIREREwMPDA1ZWVli6dCnU1NTQo0cPhISEQF5eHjIy\nMm9so+U2R0REgM/no3fv3nB3d0dsbCx27dqFiRMnIigoCCkpKa06uGL+HwucH5DgwxwbG4uFCxdC\nSUkJR44cQXNzMyZMmIC6ujpcv34du3btgqurK7p16/ZO60tLS0OPHj0gIiKCqKgo9OjRA8rKylBV\nVYWZmRmOHTsGe3t7SElJtfqH+1U/8unp6di9ezdGjx4NWVlZKCsrIzExEWlpabCzs2vVl1xwyjIm\nJgaDBw9GU1MT9u7diwcPHiA3Nxe3bt2Cn58fIiMjYWVlBWlp6Te2d/36dRQXF8PCwgIyMjLo168f\nysvLsWXLFkyYMOGFAxLBNiUlJSEyMhIZGRkYMmQI1NXVoaioiL1798LOzk6oWxkJ2gwKCsLq1asR\nFRWFkJAQzJgxA48fP0ZaWhrKy8vRo0ePNgfNmpoanD17Fp06deJOMVpYWODJkyfYsWMHtm/fjoaG\nBhw6dAhSUlLcadeW72FVVRUAQFlZGQEBAcjIyMCmTZsgLy+PU6dOYf/+/XB0dHzj/n7Vdgvo6ekh\nJCQE4eHhmDhxIhQVFaGsrIySkhLcvXsX1tbWrQrKLdu9cOECYmJikJaWBnd3d5SUlCAyMhIdOnR4\nZfBseSr6woULcHZ2hra2NgYPHozhw4dDU1MTISEhCAgIwNSpU6GgoPDKPjx+/BhhYWFYsmQJsrKy\nsHDhQnh4eGDOnDnQ0dGBubk5QkNDYW9vL9Qo/e/7LDk5GdHR0SgpKcHQoUNhYmICLy8v5OTkwNvb\nG87Ozq/t49+32dvbG4cPHwafz0dMTAz4fD6WLFmCsLAw7Nu3D2FhYZgyZcpbz8Qwf0PMB5WQkEAb\nN26k0NBQIiJKTk4mBwcHOnr0KBERVVVVUXp6+juvJzs7m5YtW0ZHjhwhIiIfHx/69ttvKT4+nhoa\nGoiIqL6+Xqg2m5ubub8vXbpEvr6+dO/ePSIi2rFjB40ePZru379PJ0+epDlz5lBJSYlQ7fv4+NA3\n33xDOTk5RER05coVmjhxIl25coWKi4uprKyMysvLX9uv5ORkio2NpZycHKqtraW5c+fS5s2bqbi4\nmFtW0HbL1z158oTbJ0lJSbRq1SraunUrVVdXE5/Pp3HjxlF+fn6rtqGxsZH7+/79+zRx4kR6/Pgx\n/fXXX2Rvb09NTU1UU1NDPj4+tHr1aioqKhJqH/3d06dPqbCwkH777Td69uwZERGdPHmSjh8/TkRE\nZ8+eJS8vL+59avke7t+/n2bPnk0zZsyg0tJSiomJoeXLl9OCBQto48aNNGrUKHr48GGr+9Ky7ejo\naAoODqbS0lIiIvLw8KBp06Zxz+fm5r7yvXybo0eP0vjx48nX15c8PDxoxowZRPT8s7No0SKKjo7m\nls3OzqbExEQiInr8+DFNnTqViJ7vs6CgINq7dy8REQUGBpK7uzs9ePDgrevfuXMnubq6Ul5eHi1b\ntozmz5/PPefr60szZsyguro6obeLiCg2Npb7Ozg4mFauXEkHDx4kIqKHDx/S6dOnKTs7u9XtlZaW\nkqenJ1VXVxMRUUxMDHl5edHt27eJiCg8PJwKCgra1Nd/Ozbi/EDof0eVp0+fRkBAALp37w4DAwNo\naGjA3Nwcq1evRl1dHaytrdvl6E9eXh41NTV48OAB8vLy8NVXX6GsrAw+Pj4wMTGBurq60NeuWiZ6\n+Pn5QUtLC0eOHEFFRQXc3d1BRLh69SoSExOxYMECoU7DxcXF4cCBA9ixYwc0NDQAAN26dQOPx8Oh\nQ4egr6+PHj16QEpK6pX9Cg4Oxrp161BQUIBLly7h6dOnWLRoEc6cOYPU1FQYGxtDRkbmhSN1Ho+H\nkJAQrFq1CpmZmbhz5w7Gjh3Ljb4OHDiAqKioVifJlJaWYt++fdDU1IS8vDxKS0uhra2N/Px8HD9+\nHLt27YKioiKys7NhZ2cHAwMDLiFMWILPk6SkJO7fv4/4+HikpaXBxMQEjx49wuHDhwEAu3btwty5\nc9G3b19um4Hnp+9OnTqF5cuXIz8/Hxs3bsTs2bNhaWkJUVFRyMvLw9PTs1UJVQItR3aHDh3Cw4cP\nERMTg+LiYqxYsQIXLlzA0aNH4erqCnl5+Ve+l3/X8lpeQ0MDfHx8MGfOHDg6OsLFxQUBAQGIi4vD\nvHnzkJ2dDSsrK8jKyqKyshK+vr54+PAhVFRUoK6uDh8fHyQmJiIkJAR5eXm4ePEigOeJM/b29tDW\n1n5p/eXl5WhqauKSaIyNjZGamopOnTrB1dUVQUFBuH79OmpqauDn54effvqp1fd+pBYjzcLCQuzb\ntw9xcXEYMGAAdHV10dzcjAMHDqC8vBwWFhYwMzN7430o/37ds7a2Fr6+vtDV1YWuri7U1dURFxeH\n7OxsDBgwAFpaWh/9htCfKhY43zPBl6OgoACysrKwtLSEpKQkgoKCuFOn6urqsLa2hoqKyjtncF66\ndAkJCQkwMTFB9+7dUV1djbi4OJSVlWHSpEmor6+HsbExOnTo0Kb2k5KScOXKFezevRuJiYlITk6G\nhIQE8vPz8eWXX2LUqFFwdHTkgl9rZWRk4OHDh3B1dQXwPJFBREQExsbGUFZWRvfu3V95bZOIUF1d\njV9++QU//vgjvvnmG5ibm2P//v2QkpLCV199hVOnTsHCwgJKSkovvDYmJga//PILtmzZgoKCAhw7\ndgzp6emYMmUKunXrhoqKCnTq1AmTJ0/m1vWm06qZmZm4f/8+kpKS0LVrV9TX12Pt2rVISkrCoUOH\noKKigsjISPz+++8YOHCg0Puo5TbzeDwUFRVBUlIS2traUFNTQ3x8PFJTUzFlyhRISkqisLAQEyZM\ngLW19Quvj4yMxJEjR2BqaoqRI0fC1tYWjx8/xsaNG+Hi4gIzMzMYGxu/8Uf6dYqLi+Ht7Q0fHx+M\nGzcOcnJyiIyMhKKiIjw9Pblkr9Z8/qjFKfyUlBRoaGjg+vXr6Ny5M3ebKCMjI8TGxmLIkCEwMzOD\nrKwsiAiSkpLQ0tJCUlIS0tPTYWZmhkGDBqGwsBBubm4YP3481NXVkZWVhUGDBkFWVval9VdUVGDu\n3LnIyspCbW0tunbtCnFxcdy7dw8RERFwcnKCnZ0dzp8/jyNHjmD37t2tvlbYMqP66NGjuHz5MiZM\nmIDIyEgkJyfDysoKXbt2xd27d9HQ0ICBAwdCUlKyVfsqKSkJ9fX1UFVVhZKSEiIiIiArKwtNTU1u\nvviAAQMgIiLSLolM/0YscL5nglHNmjVrkJeXh9OnT2PhwoXIysrC1atXoa2tDVVVVairq6NLly5C\nJ4rk5OSgsbERDQ0NXOLJ9u3bIS8vD0NDQ+jr6yMmJgYBAQEQFxeHm5ubUEHz7/1RVFRE//79cffu\nXfj5+eHEiRPIzs7GyZMnQUTo2bMnxMTE3rgNr9pGSUlJREdHQ1VVFRoaGhATE4O/vz9CQ0O5Ecqr\nNDY2QkpKCpcvX8bw4cOhpKQEeXl5SEtLIzExEcOHD4eDgwNUVVVfWHdeXh4qKyvxxRdf4PHjx9yI\n8OTJk4iNjcXkyZMhJSWFhIQEpKenw9TU9K1TRwTXRPl8Pu7du4eRI0dCTk4ON27cQN++fXHnzh38\n/vvvmDlz5jtN8xBcO12wYAEePnyIpKQkjBkzBkpKSoiLi8Pdu3fh5uaGgQMHQk9P76WRiGASfFFR\nEXR0dKCqqoqBAwciMzOTSxoRLPc2Ld/L5uZm1NXVwdfXF6amptDQ0ICamhqioqJQWFgICwsLjBkz\nptVBU9Du8ePHMXv2bAwZMgSqqqpYvXo1LCwsoKGhgaCgIERHR2PkyJEQExNDfn4+91kJDAxEZGQk\nt/6+fftixIgRUFFRweHDh+Hr64v58+e/NllMUlISZmZmaGhowPr16/H06VM0Nzdj/PjxOHHiBMTE\nxGBsbIwhQ4bAzc3tlSPW1xFs261bt3D27Fn88ssv0NHRgbq6OsLCwhAUFITKykrExMRgyZIlUFNT\ne21bWVlZ+P3332FnZ4dTp05h69atuHXrFjIyMiAiIgJtbW1s3LgR6enpOHv2LFasWAE1NTUWNN8B\nC5zv2YMHD7hRTU5ODuLj4+Hi4gIbGxukpqbi0qVLGDp0KHcqSJgPc2hoKJYuXYrk5GQEBgaid+/e\nMDU1hba2Nnbu3AkpKSkYGRmhuLgYTU1NcHNze2uiTkstf7wiIyPx+PFj1NbWQltbG/fv30d5eTmG\nDRsGPp+P5uZmTJs2DbKysq0OmseOHeMyCIcMGYKcnBzExcUhLCwMubm5OHDgAObOnfvSSFHQRlZW\nFq5cuYLevXsjOzsbe/fuhZOTEyQkJJCeno6YmBgMHToUYmJiEBER4V4XHh6OPXv2YMSIEejcuTP2\n7NmDyZMno1+/fsjOzkZ4eDhsbGxgbGwMeXl52NjYvHJE8qpt0tDQgIaGBpKTkxEZGQkPDw8oKyvj\nzp07yMnJwbRp0zB48OB3yqTNyMjAxYsXMXXqVC4hJTY2FuPHj4eCggLi4+PRrVs3KCkpvTASuXnz\nJnegNWHCBERFRSE3NxdKSkpQVVWFnZ0dRo4c+db38FXbfebMGRQVFcHY2Bj19fWIiYmBuro6Onbs\nCD6fj6KiIlhbW4PH47WqbcEyhw4dwvXr12FjYwMNDQ0MGzYMHTp0wO+//46EhATcuHEDXl5e0NDQ\nQGhoKBYtWgRHR0fEx8djx44dOHjwIIyMjPD48WOkpqZCXV0dYmJiOHDgAFavXo0ePXq8sR8KCgow\nNDTkPp/Xrl3DuXPnoKWlhfLycgwcOBASEhKtPuV5584d+Pv7w8LCAqWlpTh69CgSExPxxRdfQEZG\nBsrKyujTpw/u3r2LtLQ0LFy4EHp6em9sLz8/HwUFBTh//jwePnwIHx8f9OvXD01NTUhPT8ewYcMw\nYsQIaGpqYtq0adDR0WlVX5k3+FAXU/+tUlNT6cSJExQWFkbjx4/nklOSkpKIiIjP57ep3ZCQEBo/\nfjzdvXuX0tPTaevWreTr6/vC8xYWFrRw4UIaNmwYZWZmtnkbvL29ydXVlebNm0cLFy4kb29vKi8v\npwEDBtD3339Pw4cPFzqhycfHh9zd3Sk1NZUsLCxozZo1RPQ8qWTr1q20efNmSktLe+l1ggSU8PBw\nmjVrFjk4ONCZM2eotraWfvvtNxoxYgTt2bOHRo4cSSEhIUT0PDFEkCCRlpZGixcvpqioKCIiqqur\no9WrV9Px48fp+vXr5OnpSVlZWULvo6CgINq0aRNt2LCBKioqKD09nTZs2ECbNm3ikqRaJg61RVNT\nExUWFpKtrS0tXLiQiIgaGhooIyODFi9eTKtXryYi4pKEiP5/fx05coTGjh1LW7duJQcHB9q7dy/V\n1dXRmjVraP369ZSamvrC8q3tj6BtFxcX7rOclpZGPj4+NGLECFq3bh3Z29u3+vMhaJOIKCMjg5yc\nnKiwsJBOnTpFP//8M/dcVlYWPXr0iEtuCQ0NJUdHRy4J6tq1a+Th4cEtHxcXR+PGjaMVK1ZQXl6e\n0IlxRP///m3dupUmTpxIFhYWL+zrt8nPz6effvqJkpKSKD4+noieJzD95z//oY0bN9KTJ09eWL62\ntvaN7YWHh1OvXr1oxIgRdO/ePVqxYgWNGDGCe57P59P8+fPpxo0bre4j0zoscL4nBQUFVFBQQHl5\neWRra0t2dnZUU1NDRESRkZFtyjolev7DVl9fTxMnTqQ5c+Zwj1+9epXWrVtH5eXlXLs5OTkUC1DO\ndgAAIABJREFUGBj4QiapsJ48eUJTpkyhyspKqq+vp6SkJJo/fz5FRERQUVERnTt3rlXtFxQUcBmk\nxcXFtGjRIiovLydvb2/6/vvvycnJiRYsWMAt/6Ygc+/ePRoxYgRFRkbS5s2badWqVVwW6bVr1ygw\nMJALjA0NDTRp0iQKDw+nhoYG8vLyojFjxtDp06e5IHH16lVatmwZTZo0iS5fvsytp7VBJCUlhRwd\nHens2bP0n//8h1xdXamwsJD4fD55eXnRL7/8QjU1NS8EhXdx/vx5Gjp0KIWFhRHR82CTnp5O8+bN\n4wJUXl4eVVVVEdHz/T1lyhTuufLycrK3tyd/f38qLCykX375RajPYmRkJPdZzs/PJzc3N0pPT6eG\nhgYKDAyk48ePU2xsLMXHx9PNmzdb/flrub99fHy47RNs8/r164mIyM/Pj65evco9d+vWLbK2tqa5\nc+dy21hSUkILFiyggIAAbrmff/6Z1qxZ06bv3d/7V1xc/FKge5sHDx6Qh4cHxcbG0sqVK8nT05OI\nnh9cr1+/nrZs2dLqLOvQ0FAaO3YsnT17lpYuXUpEzw80PDw8uINQIqI1a9bQrl27Xuo/827Yqdp2\nRP87dRUfH49NmzahuLgYtra20NLSQlpaGuTl5cHn87F582Z8/fXXbbrOxePxICoqCltbWxw7dgyP\nHz+GtbU1jh49ioCAAMTExMDX1xcNDQ1QU1ODlZXVW+d8/V3La2LPnj3DyZMnMWLECCgoKEBOTg7Z\n2dl4+vQpBgwYAAMDg7e2L6jHe/bsWTx79gy6urpwcHBAcnIyjhw5Ah8fH1haWmLNmjUoKCiAvb39\nC6f0+Hw+kpOTuSzdoKAgyMnJwd3dHTY2Nnj69ClOnz4NALC3t4ehoSGXZNXY2IiLFy/CwcEBampq\n6NWrF548eYLS0lIoKChAQ0MD+vr6sLGxwejRo2FsbMy9j687pVhaWori4mIoKCggISEB3t7esLOz\ng7u7O4YPH46srCzs3bsX06dPh5KSElf5qC2nZlt+piIiIiAjIwMLCwuoqqri119/Rffu3aGtrQ1F\nRUVu7mlxcTH27duH7Oxs7v0JDg6Gra0tFBQUICUlBU1NTSQmJmLEiBGwtrYWKrvywoUL0NbWhoyM\nDOTl5ZGVlYVz584hLCwMDx48QGVlJZ49e4ZRo0ZBT0+v1Z8/wf7x9/fH+vXrUVNTg5EjR3KP5+Tk\noKSkBLt378bkyZOhoqKCiIgIrF27FgsXLoSCggLu3r0LKSkp6Ovro7y8HImJiVwFqJs3b2L58uVt\nTspqWaxCRkZGqMseAKCqqoqCggIcPnwYK1euRFJSEvz9/TFlyhRoaGggKioK2dnZMDc3f+NnJSws\nDOvWrcPatWsxZMgQbNu2Daamplym/p07d+Dr64u6ujrcvHkTs2fPhpKSErum2Y5Y4GxHgkSgP/74\nA5qamggKCoK4uDjMzc1hZGSEkydPorS0FO7u7rC3txf6Opdg+ebmZnTo0AF2dnb4888/cfr0aRAR\nTp8+DTs7O+66krA/iGlpaZCSkoKkpCQXPOXk5PD48WMEBATAzMyMu4aWl5eHgQMHvvWaVXBwMLZs\n2YLffvsNlpaWCAwMRHNzM8zNzVFYWIiSkhIMHDiQq3U7adIkKCoqvtBmZmYmxMTEICcnB0lJSTQ2\nNuLq1avQ1dVFx44duSowFRUVUFdXR6dOnZCTkwMAkJWVxbVr1zB8+HB06NAB0tLSMDIywp07d8Dn\n8yEjI4OOHTtCXFy8VdeZ6+rqcPbsWXTt2hUdOnRAdXU1zp49i/r6epibm0NaWhoDBgzA7du3YWZm\nBn19/Zeu0QpDMNVm7dq1UFVVxZ49eyAhIYExY8ZAXV0dy5cvh5GREXR0dLiiDlJSUigvL0d2djby\n8vLQu3dvJCcnY//+/Rg/fjxEREQQFhbGXf8S1LV9G8Hnz9zcHLm5uRg7diyXgSwpKYnx48dj4sSJ\nyMvLQ0pKCoYOHdqqdktLSyEiIgIxMTEcPHgQfn5+mDt3LoqKijBs2DAQEfLz8/Gf//wHmZmZ+P33\n37niIGVlZbC3t4ednR0UFBSQnp6OjIwMKCsrw9bWFmpqasjOzkZxcTF++OGHN14vbO37IYy/T2cx\nMjLCgwcP0KlTJ0yYMAHBwcEIDAzE5MmToa2tDXNz8zdeT29sbMStW7cwceJE7jrmtWvXYGBgAF1d\nXSgrK8PIyAhBQUHIycnBhg0boKur+y6bzLwCC5ztqKysDJs3b8asWbPw9ddfQ1dXF9evX8fTp0/h\n4uICZ2dn2NnZQVdXt81BE3ieml9WVgYdHR04OTnh2rVr6NGjB2xtbSEhIQFDQ0NYWFi8tTRdS/X1\n9di5cyeuXr3Kpb43NDRAVFQU3bt3576EpaWl8Pf3x/Lly6GiovLGbRC02dDQAA8PD3Tq1AmioqII\nDg7GsGHDUFFRgcjISFy/fh2nTp3C0qVLX/qSExE6d+6MDh06wNnZGcrKyrCxsUF+fj4yMzNRVVWF\nxsZGXLlyBbKysnj06BFsbW2RlJQEd3d3TJo0CeHh4TA2NuYyE6WlpdG/f3/cuHED+fn56NWr1xtT\n/VsSExNDt27dQETYt28fzM3NYWdnh4sXL3KZzfn5+fD19cXo0aPbNKWjJT6fjz/++APbtm2DtLQ0\nAgICUF9fj2fPnsHFxQWdO3fmphpkZ2ejtLQUysrKMDAwQENDA+Li4lBUVARPT08kJydj3759SEhI\nQHBwMFasWAFVVVWhE4GA5+XuMjIysGPHDkyZMgV9+/aFvLw8/P39cezYMSxbtuy12aotPXr0CKdO\nnUK/fv1QXV2NxMREzJ07F/3798fJkyfh7OwMHo8HcXFxKCoqYubMmS9U1NLQ0ECnTp3Q3NwMZWVl\ndOzYEenp6UhJSYG8vDx69eqFgQMHwtrautXzK9uLMNNZwsLC4Orq+tZRrIiICExMTLibBIiKiiIn\nJweVlZXo168feDwe7ty5AxMTE3h4eLR5njDzZixwvoPMzEyEh4ejQ4cO3GgmOjoaoqKiMDExga6u\nLmpra7F3714oKSnB0NCQG8kJe+TacnL5wYMHcevWLcTFxUFGRgbTp0/Hrl27kJqaCjs7OwAQqrhB\nRkYG1NTUYGBggJSUFNy8eRNWVlaQkpJCU1MT5OTkuHmmOjo6+Prrr9965J6eng41NTX06dMHeXl5\nuHz5MoYOHYrLly8DAIYMGcLV3+zZsyd3xN1Syx9rCQkJ6OnpYevWrdDR0YGtrS1KSkpw6tQprohB\n586dkZ6ejoEDB0JXVxeGhoaYNWsWnj17BlFRUcTFxSEvLw+ZmZncgYe5uXmri40LDiQEWbvx8fHI\nzMyEubk5LCws4Ovri5s3byI/Px/Tpk1D375925Q92/LMgpKSEnr16oXy8nKsX78eJ06cwLNnz7Bz\n507Iyspi3Lhx3F12hgwZgoCAAEhLSyMpKQmjR49GRUUF8vPzkZWVhblz56J79+7Q19eHm5tbq0df\nLbchNjYWSUlJUFVVhZOTE3dANX78eNTV1eHSpUv44YcfWj2fUV5eHgYGBuDz+UhJSYGjoyNUVFRQ\nXFyMw4cPw9XVFWfPnsWGDRuwYsWK175Xgv4pKiqiY8eOyMrKQlxcHOTl5bkDtg9NmOks/fr1a/XZ\noZbTogR3w4mPj8eoUaNw7tw5/Pnnn5g6deo7F9FnXo8FzjYiIuzduxdbtmxBYWEhoqOjYWZmhuLi\nYlRVVYGI0KVLF4iJiSEuLg7h4eGwtLRs1VH439cj+FHIysrCvn37cOTIEQwaNAji4uIICgpCv379\n4OTkhCNHjmDIkCGtrisKPB8VLlu2DOHh4Rg3bhx69OiB+Ph4BAUFwdLSkqvucubMGTQ1NcHR0fGt\noyhBm2FhYRg3bhy6d++OhIQE/Prrr6iurn7hnp1KSkpQV1d/5XUwQTF8Pz8/PHv2DJaWljA1NcWK\nFStgaGiIMWPGwMHBAU5OTkhLS8OmTZuwaNEi7hqWjo4ODA0N4e3tjU6dOkFSUhKpqam4e/cuQkND\nMXToUPTs2fOt+yg3NxciIiKQlpbmCjN07NgRysrKSE5ORkpKCiwtLTFw4ECEhoaid+/eGD9+PLcN\nwhC83wkJCfD394exsTFX8aWkpAQuLi4gIqSnp8PNzY2rMiUtLQ0zMzOcOHECtra2ePDgAc6dO4ei\noiLU1tbi4cOHePr0KQYNGgRtbe1WXXf8+7Veb29veHt7IzMzE7du3UJlZSVmzpwJPp+PVatWYdq0\nadzpUWG2VUJCAiEhIVwBc1VVVSgqKuLevXvcfOe1a9e2ujiIoqIiVFRUUFhYCBsbG6G+D+2tvaez\ntCR4X2RlZZGbm4uamhocOHAAv/32G1cggnlPPlga0mfo9u3bNGnSJOLz+TRr1izaunUrrVixgpYv\nX05eXl60cOFCcnBwoJycHFq/fv0LWYKtUVlZyf0tqEnq7OzMTa0oKiqihQsXkp+fHxERV2+1tQRZ\nnhUVFTRt2jTasGEDET2fvrFmzRpatmwZET2vS2tlZUUpKSltbrOgoIB+/PFHLgOw5bKvEx0dTc7O\nzrRhwwZauHAh/fTTT5Sbm0vR0dFkaWlJ58+fJ6LnU0r++9//vnL6CtHztP0RI0a0eTpIWFgYmZub\n09OnT7n1CcTFxdHGjRtp8+bNVFhYSElJSTRu3Dg6efJkm7Now8PDydPTk4yMjMjLy4uqqqqooKCA\nXFxcuM+UoN7o392+fZscHByorq6O8vPz6ezZszR9+nSysLAgJycnqqioaHU/Wk7ZKCoqoqlTp3LZ\ntFevXqW1a9dy06q8vLxaPbVKkN3Z1NREkZGRNGnSJGpqaqKTJ0/S0qVLKSgoiIiIlixZQjY2Nq99\nX4Xp/z/Bu05neZ28vDwyMDCgESNGtEuda+bt2IjzHWhra+PmzZsoKyvDmjVrkJ+fj7/++gtlZWXQ\n09ODuLg4d4d5Hx8ffP31162+7tjQ0IATJ06guLgYd+/ehY+PD1xdXZGSkoKUlBSYmJhASUkJqamp\nqKmpgZmZmdCngAXLXr9+nbszS15eHhwdHWFoaIikpCSsX78ewcHB8Pb2hqGhYZvafPToERwdHdG7\nd28kJibi9OnTGDx48BtvopuRkYG1a9fihx9+wJdffokePXqgqqoKd+/exRdffAF9fX0oKChAU1MT\noqKi3KnkV9HS0oK2tjYmTZoENzc3SElJCXUKVUtLC4aGhvjuu+/g4uICWVlZ1NfXcyPPpqYm5Ofn\no1u3btyp5+7duwudzQw8L5e2fPlyrFu3DmPHjsWFCxeQl5cHa2trDBo0CFVVVZg4ceJLZfQEtLW1\noampie+++w6TJ0+GqakpBg8ejMmTJ3OZxa0RFhaGP/74A3w+H1VVVejevTv++usvaGpqQkdHB/r6\n+rh58ybS09Nha2uLQYMGCZ09y+Px0KVLFzx48ADFxcWYMGEC8vPzERUVhebmZpiYmGD27NlCVeRp\n6WOcnn0TwffT2toaQ4YMgbu7+ztfAweeJ4NVVFRg2bJlbKT5gbDA2UaCH14tLS1kZGRAUVERGzdu\nxMyZMzF69GiUlJRgzJgxAIAVK1Zg27ZtQmX0iYqKQlFREd9++y0SEhKwa9cuSEtLo0OHDkhLS8Pu\n3btRVlaGM2fOYNGiRW1ONw8ICMBvv/2GxYsXo2/fvggLC0NsbCycnJzQrVs3PHr0CMuXL29V0Gxt\nm9nZ2TA2Nn4pe7BlMBMU4S4sLMSoUaOgpKSE5uZmnDt3jptyoqmp+dapIwK6urro0aMHysvLoamp\nKfS+0tHRgY6ODr7//nuMGTOGq64THR2NiIgIuLm5QUdHB83NzdDQ0BAqMaulnJwcPHr0CF9++SU0\nNDTQv39/rFu3DqWlpXB2doapqelbT1nq6upCW1sbP/zwA5egJJg60hqhoaFcCbeKigrExsaiY8eO\nUFBQQE5ODqSkpKChoYHi4mJUVlbCwsLireUI/+7MmTPYunUrd+NnwT0yLSwskJKSguzsbK7g/ufi\nXaezvI6oqChsbGy4spLMB/BRx7ufgeLiYvLw8KBevXpxk/CJiDudSkRCT5Ru2fbmzZvJ3t6eOx3b\n1NREtbW15OfnRydOnKCMjIx36v/58+fJ29ubiJ6f6s3KyiJnZ2euSktbTm++rk1BZZs3tSkoakD0\n/DZh33//PW3atImIiNLT02ncuHGUl5cndJ9aepeJ4MHBwWRvb09Ez2/1ZGlpSYGBge3Wl9zcXJo/\nfz4lJSVxn6G9e/eSk5MTHThwQKi2r127Ri4uLkKdMi4rKyMDAwOu2kx+fj798MMPFBwcTFlZWbR9\n+3aaOHEi/fTTTzRs2LBW33ZMUIxBICAggAYPHkwHDx6kdevW0cSJE+nw4cMv9INh/qnYiPMdycjI\nQE9PDykpKfj+++8hKyuL5uZmSEhIcBm0bTmyFNz42N3dHU5OTli5ciUAoG/fvggNDYWpqSmsrKza\nPEfw/v37AIDq6mr89ttvXIEDRUVFpKSkIDMzE4MGDRIqaaE92hQXF8fSpUtRU1PD3XD40KFDOH78\nOOLj4zFr1qx3KpAOCJ+w05Lu/27RNGbMGFy+fBleXl4YPnz4O2XP3rp1C9euXUNiYiJsbGxQUFCA\nq1evorq6GtnZ2bhy5Qrc3d25aTwtb8L9Jl27doWzs3Orp9oAz0/79ezZE5s3b4aLiwtUVFRw7do1\nKCgoYODAgTAwMICpqSmUlJTg6enZqjmCISEhOHnyJHr27Im7d+8iJSUFDg4OiI2NhZ6eHiwsLBAQ\nEIDAwEB069YNXbt2bdUtxxjmY2GBsx0oKysjISEBYmJi0NfX505btXWeJvB8/t6dO3dQUFDAZWz+\n97//RWpqKg4dOgRnZ+c2Xx8pKCjA0aNHkZGRwf2wenl5wcDAAGFhYUhMTMTmzZuFygBuS5stt7m4\nuBi1tbVQVVXFuHHjsGbNGpSUlGDs2LHo1asXHj16BFVVVXz11Vev3F8fkq6uLvr27Qtra+s2B03g\n/+9ysm3bNjg4OODUqVOIiIjA4sWLwePx8ODBA4SHh2PRokUQFxdHTEwMRo8eDTExsVav403XkV9H\nV1cXmpqamDNnDrKysrj5iOLi4pCSkoK6ujr09fVbdeo3KCgIW7duxfjx49G9e3fw+Xxs2bIFsrKy\nMDQ0hL+/P1dgn4jg5OTU5lveMcyHwgJnOxAVFYWamhpkZGTaPHdK8MMbExODzp07Q0tLC4qKioiJ\niUF2djaGDx/OjTZmz579Tnc4kJOTg4iICLKzs3H//n1MnDgR8vLyuHr1KlJTU4W+CXVb2iwtLcWR\nI0fQrVs3NDY2wsvLC2JiYlBTU4OqqirGjBmDJUuWcBP9NTQ0cPPmTeTm5qJ///4fvXyYlpYW9PX1\nhQ6a+fn5ePjwITp37oyKigocOHAAK1euRFFREeLi4iAtLY3z58/ju+++w6BBg7jShJs2bcLq1as/\n2IR2XV1d6Ovr45dffsHhw4chLy+Puro6oYL2kydPsGHDBqxcuRLW1tYgInTt2hXGxsbw9/dH586d\nERsbCx6PB0dHRwwcOLBdkmUY5n1jgbOdCCqYCKu4uJg7lVtZWYlt27Zxt9nq3LkzpKWl4e3tjby8\nPPTt2xempqZtytYEnt+f8PTp0xg4cCB0dHTA4/GQkpKCjIwMuLq6YvTo0XBwcBCqlmdb20xKSkJU\nVBQyMjJgbW2Nuro6hIeHQ0JCAkpKSlBRUUFdXR28vb0xZswYLpPT3Nz8H3XX+tYGTSJCVVUVXFxc\ncPv2bejp6aF79+7o3bs3amtrsX79emzfvh22trbYsWMHQkJCMHbsWIiJiSE3Nxfjx4+HgYHBe96a\nF2lpaaFXr15YvHgxHBwchB4JNjY24tq1axg8eDA6dOiAPXv2YPv27UhOTuayZnNzc3Hr1i24uroK\ndUqZYT4mFjg/ooyMDK70XEFBAUxNTaGrq4vU1FSEhIRg0KBB0NLSQnJyMurq6jBo0CChrv38fTTU\n2NgIX19fFBYWwtLSElpaWsjNzYWfnx8aGhrQq1cvoW9C3dY21dTU0LFjR8TFxSE9PR2TJ09GY2Mj\ngoKCUFVVBT6fj/j4eGzcuBF6enoQFRWFurr6PypoCkMw0b+srAw1NTVISEiAlJQU+vTpg7KyMjx+\n/BjOzs5ISUmBnJwcvvzyS+5ATFdXV+jCGe1FV1cXGhoaWLlyJdzc3LhtaQ1JSUmUlpbixIkT2LZt\nG1eIfujQoeDz+TAwMMDcuXMxYsQINtJkPikscH5E9fX1iI+Ph4mJCYKCghAZGQkVFRUYGxvj8ePH\nOHToEKqqqhAeHo5ly5YJVWuzZYB78uQJqquruSLShw8fRk5ODqytrVFYWIiqqipMnz4dcnJyrQ6a\nbWlTUIFHUlISoqKiUFZWxp9//onCwkLk5+dj4sSJXHWfgIAATJw4Ef37939p3Z8aQak+AGhqakJJ\nSQmcnJxw7tw5iImJwcjICMeOHUN8fDz++OMPeHh4oH///v+YbW6ZZCTsPOEePXpAX18fffv2xfTp\n09G7d2906tQJ165d4wqSt/bG2QzzT8EjIvrYnfg3W79+PQoLC7F582ZcvnwZ165dQ1FREZYtW4aD\nBw9CVVUVrq6ub71T/et4e3sjIiIC5eXlcHNzg5ubG7KysjBr1ixoaWmBz+dj9+7dQk2cbmub4eHh\nmDdvHqKjo8Hj8fDdd99BS0sLTk5OuHTpEpSUlPDNN99AWloalZWVkJOT+8cEj7bKyMjAnj178MUX\nX8DKygpEhMWLF6NLly7o3bs3Tp48iVmzZqF79+5IT0+HiIgI+vTp87G7/V5dvnwZ+/btw7Zt29pc\n3IBhPiY24vxIBAHB0tIS169fR//+/VFfX4/jx4+jb9++iIqKgqqqKmbPng1NTU2h2wWAEydOIDAw\nEAcPHuTu0ykhIQF7e3u4urqiS5cumDZt2lt/vNqrTUEFnunTpyM0NBQ9e/bE4sWLoaGhwdX0TUxM\nRP/+/SEhIdGmYvj/NBkZGdiwYQMePnzIXf91c3MDn8/H4MGDIScnh/3790NVVRUDBgz4rO9mUVRU\nhFOnTuHgwYPYvHkzunbt+rG7xDBtwkacHxERoaGhATt37kRubi6SkpKwePFiDBs2DJmZmVBRUREq\nEahlgCstLUVOTg7U1dURGBiI2NhYTJ06FZ6enpg6dSrmzJnz0dqMiIjA9OnTkZSUxFVTAYA7d+5w\nUx0+JzExMZgxYwa2bduGe/fu4c6dOygsLMQff/wBY2NjXL58Gbq6uujVq9fH7up7VVtbizt37kBP\nT++dssIZ5qP7IGUWmDfKyMggGxsb2r59e7u0d+zYMfLw8KDq6moqLS0lT09Prvjz4sWLydXVVahi\n3++jzeDgYBo+fDiVlJQI1Y9PVWhoKDk4OFB9fT3Fx8fTn3/+SeHh4UQkfHF+hmE+rtZPymLem65d\nu2LRokXIy8tDTU2N0LdBevLkCVe8OzIyEgEBAfj9998hLS0NcXFxaGlp4fLly+jQoQOamprw+++/\nv3Vqwftos6XBgwdDREQEo0ePxuXLl9s8xeZTYWtriyVLlmDMmDE4efIkevfujYaGBgAQam4kwzAf\nn3CVmZn3pk+fPkhKShL6dcHBwZg9ezZKSkpQUVGBuLg4ZGZmIjY2FsDzH+X+/fujoaEBly5dwqxZ\ns9463/R9tPkqtra2+PXXX/HgwQOhX/spsrOzw7JlyzBy5Eg8ffq01aXzGIb5Z2HXOP9BhB1thoaG\nYvfu3Zg1axYGDRrEtXH48GHk5uZi9OjRsLS05Javrq5+a93c99Fma9Annj0rjODgYEhLS7+wHxmG\n+XSwEec/iDBBs7y8HJ6envDw8MCgQYPA5/OxZMkSEBFGjhwJfX19XL58GWFhYdxr3hbg3kebrfVv\nCZrA85GnpaUl2DErw3yaWOD8RCkqKmL37t3YsWMHHjx4gFWrVsHQ0BAyMjLQ0dHB0KFD0bFjR4SE\nhKC2tvajtcm83r/pYIFhPifsVO0nLjQ0FJ6enli4cCE8PT3R2NjIJZvk5eVBVlZW6HJm76NNhmGY\nzwULnJ+BsLAweHl54dSpU+jQoQMaGhreOfHkfbTJMAzzOWCnaj8DAwYMwLJlyzBhwgSUl5e3S4B7\nH20yDMN8DtgEss/E4MGD0dDQgGnTpuHMmTPtUq7ufbTJMAzzqWOnaj8zVVVVkJWV/ce3yTAM86li\ngZNhGIZhhMCucTIMwzCMEFjgZBiGYRghsMDJMAzDMEJggZNhGIZhhMACJ8MwDMMIgQVOhgFgb2+P\nUaNGwcXFBc7OzggICGi3dtPT0wEAM2fORG5u7huXv379Ou7fv9+mdfn5+WHevHlv7cebGBoaoqam\nRqj15uXlwcrKSqjXMMynjBVAYJj/+fPPP6Gvr4+UlBRMmjQJNjY2L9XkbW5uhohI6483WxaM2LNn\nz1uXv3HjBnr27IlevXq1vuOvWd+HfD0rjMH8m7DAyTD/I5jSbGRkBFlZWTx69AhBQUE4f/48ZGVl\nwefzsWnTJqioqMDLywsFBQWora3F6NGj4enpCQCIiYnBmjVrwOPx0L9//xduHWZvb4+9e/eiW7du\nKCwsxLp165CdnQ0ejwcnJycYGxvj5s2biIiIwOnTpzF16lS4uLjA398fx44dQ1NTEzp06ICff/4Z\nenp6aGhogJeXFyIjI6GkpAQjI6NWbaePjw8CAgLQ1NQECQkJrF69GoaGhtw+2L9/P27cuIG6ujos\nWLAAI0aMAAAkJCRg8+bNqKqqAgDMmzcPgwcPbrf9zzCfDGIYhoYMGUJpaWlERBQREUFmZmb07Nkz\nOnv2LJmamlJubi637LRp0yg6OpqIiOrr68nd3Z3Cw8Oprq6ObG1tuecCAgLI0NCQa7flOr766is6\ncOAA12ZZWRkRES1dupSOHDnCPR4dHU2enp5UX19PREQhISE0adIkIiI6dOgQeXh4UFNssT53AAAD\nMklEQVRTE9XU1NAXX3xB8+bNe+v2lZaWco+Hh4eTm5sb938DAwPauXMnERFlZmaShYUFlZSUUEVF\nBY0dO5aePHlCRERFRUU0aNAgevbsGT169IisrKyE2NsM82ljI06G+Z958+ZBUlIScnJy+PPPPyEn\nJwcAMDMzg6amJgCgpqYGUVFRKCsr40aT1dXVyMjIgLKyMqSlpWFubg4AcHR0xKpVq15aT3V1Ne7d\nuwdfX1/usdfdpi0oKAipqalwc3MDEYGI8OzZMwBAVFQUxo0bBxEREUhJSWHMmDGIjY1963bev38f\ne/fuxdOnT8Hj8cDn8194fsKECQAAPT099OzZE/Hx8RAREcGjR4/w7bffctstKioKPp/PbjHH/Ouw\nwMkw/yO4xvl3MjIy3N/Nzc3g8Xg4c+bMS9c6U1NTX3rt66798Xg8ENFbrw0SEcaPH4+5c+e2ZhPe\nqqGhAT/88AOOHz8OQ0NDFBUVvXS6lVqcXm75t6GhIQ4fPvxSm3l5ee3SN4b5VLCsWob5H2pF2WZZ\nWVmYm5tj9+7d3GMFBQUoKSmBnp4e6urqcPfuXQDAlStXUFFR8VIbMjIyMDU1xcGDB7nHysrKuPYr\nKyu5x+3t7eHv74/CwkIAzwN3UlISAMDKygrnzp1DU1MTamtrcfHixbf2v66uDs3NzdDQ0AAAHD16\n9KVlzp49CwDIzs5GSkoK+vTpA1NTU2RnZyMyMpJbrmX2b2v2HcN8LtiIk2EgXFbo5s2b8euvv2LM\nmDEgIsjJyeHXX3+FiooKtmzZgtWrV0NERAT9+/dH586dX7mOjRs3Yu3atfDz84OoqChGjx6NGTNm\nwMXFBcuWLcOVK1e45KAFCxZg9uzZaG5uRkNDAxwcHGBiYgI3NzekpqZi1KhRUFJSQu/evVFcXPzG\n7ZOTk8O8efMwfvx4KCkpYeTIkS8t19jYiHHjxqG2thZeXl5QVlYGAOzatQv//e9/sX79etTX10Nb\nW5s7gGBZtcy/Cbs7CsMwDMMIgZ2qZRiGYRghsMDJMAzDMEJggZNhGIZhhMACJ8MwDMMIgQVOhmEY\nhhECC5wMwzAMIwQWOBmGYRhGCP8HYSrcdywuRLkAAAAASUVORK5CYII=\n"
     },
     "output_type": "display_data",
     "metadata": {}
    }
   ],
   "source": [
    "plot_confusion_matrix(svm_ngram_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Agent       1.00      1.00      1.00        29\n",
      "    AutoRun       1.00      0.90      0.95        20\n",
      "  FraudLoad       1.00      1.00      1.00        12\n",
      "  FraudPack       1.00      1.00      1.00        10\n",
      "    Hupigon       1.00      1.00      1.00        12\n",
      "       Krap       1.00      1.00      1.00        10\n",
      "     Lipler       1.00      1.00      1.00        17\n",
      "    Magania       1.00      1.00      1.00        14\n",
      "       None       0.99      1.00      0.99       473\n",
      "     Poison       1.00      0.67      0.80         3\n",
      "    Swizzor       1.00      1.00      1.00       168\n",
      "       Tdss       0.83      0.71      0.77         7\n",
      "         VB       0.98      1.00      0.99       122\n",
      "      Virut       1.00      1.00      1.00        15\n",
      "       Zbot       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       0.99      0.99      0.99       926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(ngrams_Y_valid, ngrams_Y_valid_predict, target_names=p2.MALWARE_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "fpr, tpr, thresholds = roc_curve(X_valid, model.decision_function(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "\n",
    "def make_roc(name, clf, ytest, xtest, ax=None, labe=5, proba=True, skip=0):\n",
    "    initial=False\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "        initial=True\n",
    "    if proba: # for classifiers like logistic regression\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.predict_proba(xtest)[:,1])\n",
    "    else: # for classifiers like SVM\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.decision_function(xtest))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    if skip:\n",
    "        l=fpr.shape[0]\n",
    "        ax.plot(fpr[0:l:skip], tpr[0:l:skip], '.-', alpha=0.3,\n",
    "                label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    else:\n",
    "        ax.plot(fpr, tpr, '.-', alpha=0.3,\n",
    "                label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    label_kwargs = {}\n",
    "    label_kwargs['bbox'] = dict(\n",
    "        boxstyle='round,pad=0.3', alpha=0.2,\n",
    "    )\n",
    "    if labe!=None:\n",
    "        for k in xrange(0, fpr.shape[0],labe):\n",
    "            #from https://gist.github.com/podshumok/c1d1c9394335d86255b8\n",
    "            threshold = str(np.round(thresholds[k], 2))\n",
    "            ax.annotate(threshold, (fpr[k], tpr[k]), **label_kwargs)\n",
    "    if initial:\n",
    "        ax.plot([0, 1], [0, 1], 'k--')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title('ROC')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (anaconda)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}